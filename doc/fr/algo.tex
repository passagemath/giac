\documentclass[a4paper,11pt]{article}
%\textwidth 11,8 cm
%\textheight 17 cm
\textheight 23 cm
%\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{makeidx}
\usepackage{times}
%\usepackage{mathptmx}
%Uncomment next line for pdflatex and use includegraphics with eps file
% for latex2html don't use the option [width=\textwidth]
% check that xfig files are exported magnif 100%
%\usepackage{graphicx}
\usepackage{pst-plot}
\usepackage{ifpdf}
\ifpdf
 \usepackage[pdftex,colorlinks]{hyperref}
\else
 \usepackage[ps2pdf,
            breaklinks=true,
            colorlinks=true,
            linkcolor=red,
            citecolor=green
            ]{hyperref}
\fi
%HEVEA\htmlfoot{Retour \`a la page principale de \ahref{http://www-fourier.ujf-grenoble.fr/\~parisse/giac_fr.html}{Giac/Xcas}.}
%HEVEA\htmlhead{Retour \`a la page principale de \ahref{http://www-fourier.ujf-grenoble.fr/\~parisse/giac_fr.html}{Giac/Xcas}.}


%\def\@evenhead{\thepage\hfill{\footnotesize\textit{\leftmark}}}
%\def\@oddhead{\footnotesize{\textit{\rightmark}}\hfill\thepage}
%\usepackage{hp}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[francais]{babel}
\usepackage{latexsym}

\newtheorem{thm}{Théorème}
\newtheorem{lemma}{Lemme}
\newtheorem{example}{Exemple}


\newcommand{\R}{{\mathbb{R}}}
\newcommand{\C}{{\mathbb{C}}}
\newcommand{\Z}{{\mathbb{Z}}}
\newcommand{\N}{{\mathbb{N}}}
\newcommand{\Q}{{\mathbb{Q}}}
\newcommand{\tr}{\mbox{tr\,}}


\title {Algorithmes de calcul formel}
\author{B. Parisse\\Institut Fourier\\UMR 5582 du CNRS
\\Université de Grenoble I}

\date{}

\makeindex

\begin{document}

\maketitle

\begin{abstract}
Ce document d\'ecrit une partie des algorithmes de calcul formel 
utilis\'es pour le logiciel de calcul formel Giac/Xcas, cf.\\
\verb|http://www-fourier.ujf-grenoble.fr/~parisse/giac_fr.html|
\end{abstract}

\tableofcontents

%\printindex

\pagebreak

\section{Calculer sur ordinateur}

\subsection{Problèmes spécifiques au calcul formel}

\subsubsection{Calcul exact et approché, types, évaluation.}
Dans les langages de programmation traditionnel (C, Pascal,...), il existe 
déjà des types permettant une représentation 
exacte des données (type entier) ou une représentation approchée 
(type flottant). Mais ces types de donnée de base 
occupent une taille fixe en mémoire, le type entier est donc
limité à un intervalle d'entiers (par exemple $[0,2^{32}-1]$ pour un entier
non signé sur une machine utilisant un processeur 32 bits) alors que le 
type flottant peut représenter des nombres réels, mais est 
limité à une précision en nombre de digits de la mantisse et de l'exposant 
(par exemple 12 chiffres significatifs et un 
exposant compris entre -499 et 499). 

En calcul formel, on souhaite pouvoir calculer rigoureusement d'une part, 
et avec des param\`etres dont la valeur n'est 
pas connue d'autre part ; il faut donc s'affranchir de ces limites~: 
\begin{itemize}
\item pour les entiers relatifs, on utilise des entiers de 
{\em précision arbitraire}
dont la taille en mémoire est dynamique (déterminée pendant l'exécution et non
à la compilation),
\item pour les nombres complexes, on utilise un couple de nombres réels,
\item pour les rationnels, on utilise un couple d'entiers relatifs,
\item pour les irrationnels algébriques (par exemple $\sqrt{2}$), 
on utilise un polyn\^ome irréductible dont ils sont racines,
\item pour les param\`etres ($x,y,z,t...$), on utilise un type 
structuré contenant un champ de type chaine de caract\`eres pour 
repr\'esenter le nom du param\`etre et
un champ pour attribuer une valeur à (ou une hypoth\`ese sur) ce param\`etre,
\item pour les nombres transcendants (par exemple $\pi$), on est obligé
d'introduire un paramètre auquel on attribue une valeur numérique, 
qui ne sera utilisée qu'au moment où on veut une 
approximation numérique d'une expression contenant ce nombre transcendant,
on parle de constante,
\item lorsqu'on a besoin d'une approximation numérique d'un nombre,
on peut utiliser des conversions de ces types en un type flottant. On peut 
aussi pour lutter contre les erreurs 
d'arrondi utiliser des nombres flottants étendus dont la précision est 
dynamique ou même des intervalles de flottants étendus,
\item il faut aussi
un nouveau type, appelé expression ou symbolique, permettant d'appliquer
une fonction qu'on ne peut évaluer directement sur les objets pr\'ec\'edents,
par exemple $\sin(x)$. Il
doit s'agir d'une op\'eration de clôture, au sens où appliquer une fonction \`a
un objet symbolique ne nécessite pas la création d'un nouveau type
(en général on renvoie un objet symbolique).
\end{itemize}

Enfin, il faut pouvoir \'evaluer un objet (en particulier symbolique)~:
par exemple évaluer $\sin(x)$ lorsqu'on assigne une valeur \`a $x$. 
Dans cet exemple, on voit qu'il faut d'abord remplacer $x$ par
sa valeur avant de lui appliquer la fonction sinus. C'est le mécanisme
général de l'évaluation, mais il y a quelques exceptions où
on souhaite empêcher l'évaluation d'un ou plusieurs arguments
d'une fonction avant l'évaluation de la fonction. Par exemple si on 
veut calculer la valeur numérique d'une intégrale par des méthodes
de quadrature, on ne souhaitera pas rechercher une primitive de la 
fonction à intégrer. Dans le jargon, on parle alors de ``quoter'' un argument 
(l'origine du terme vient probablement de la notation \verb|'| du langage 
Lisp). Certaines fonctions doivent toujours quoter leurs arguments
(par exemple la fonction qui permet de purger le contenu d'un paramètre),
on parle parfois d'autoquotation.


\subsubsection{Forme normale et reconnaissance du 0.}
Une fois défini ces types de base représentant les nombres d'un système de 
calcul formel, il faut pouvoir comparer ces 
nombres, en particulier décider si deux représentations distinctes 
correspondent au m\^eme nombre ou, ce qui revient au 
m\^eme, par soustraction décider quand un nombre est nul. 
Par exemple $4/2$ et 2 représentent le m\^eme nombre. 
Lorsqu'on dispose d'un algorithme permettant de représenter un nombre 
d'une manière unique, on parle de forme normale. 
C'est par exemple le cas pour les nombres rationnels, la forme normale 
usuelle est la fraction irréductible de 
dénominateur positif. C'est aussi le cas pour les fractions rationnelles 
de polynômes à coefficients entiers représentées par une fraction 
irréductible, avec au dénominateur un coefficient de plus haut degré
positif.
Malheureusement, il n'est pas toujours possible de trouver une forme normale
pour diverses raisons théoriques ou pratiques~: 
\begin{itemize}
\item on ne connaît pas toujours le statut de certaines constantes
(par exemple la constante d'Euler),
\item il n'existe pas d'algorithmes permettant de déterminer
s'il existe des relations algébriques entre constantes,
\item il n'existe pas forcément une seule forme plus simple, par exemple~:
\[ \frac{(\sqrt{2}+1)x+1}{x+\sqrt{2}+1}=\frac{x+\sqrt{2}-1}{(\sqrt{2}-1)x+1} \]
Ce cas se présente fréquemment avec les extensions algébriques.
\item en pratique il peut être trop coûteux d'utiliser une forme
normale, par exemple le polynôme $\frac{x^{1000}-1}{x-1}$ possède 1000 monômes
\end{itemize}
En résumé, au mieux on a une forme normale, au pire on risque de ne pas 
reconnaître un zéro, entre les deux on peut ne
pas avoir de forme normale mais être capable de reconnaître à coup sûr 
une expression nulle (par contre, si le système 
de calcul formel détermine qu'une expression est nulle, alors elle l'est).

Il n'existe pas d'algorithme solution
pour le problème de la reconnaissance du zéro pour une classe 
d'expressions "assez générale". Heureusement, 
dans la plupart des cas pratiques on sait résoudre ce problème, en
se ramenant le plus souvent au cas des polynômes et fractions rationnelles.
Par exemple, pour simplifier une expression trigonométrique,
on remplace les fonctions trigonométriques $\sin(x), \cos(x), \tan(x)$
par leur expression en fonction de $t=\tan(x/2)$, on est ainsi ramené
à une fraction rationnelle en $t$ que l'on écrit sous forme normale.

Les polynômes ont un r\^ole central dans tout syst\`eme de calcul formel
puisque sauf dans les cas les plus simples (fractions d'entiers par exemple), 
la simplification d'expressions
fait appel \`a un moment ou \`a un autre \`a des calculs
de PGCD de polyn\^omes. Le PGCD de polynômes est un algorithme 
très sollicité auquel nous consacrerons une section. En effet,
l'application brutale de l'algorithme d'Euclide pose des problèmes
d'efficacité ce qui a obligé à inventer des méthodes plus efficaces.
Anticipons rapidement sur un exemple qui montre l'un des problèmes
majeurs des algorithmes de calcul formel, l'explosion en taille
(ici des coefficients des restes successifs).
Voici donc les restes successifs lorsqu'on applique l'algorithme
d'Euclide pour calculer le PGCD de $P(x)=(x+1)^{7}-(x-1)^{6}$ avec
sa d\'eriv\'ee (les deux polyn\^omes sont premiers entre eux)~:
\begin{eqnarray*}
7\* (x+1)^{6}-6\* (x-1)^{5} &&\\
\frac{162}{49} \* x^{5}+\frac{-390}{49} \* x^{4}+\frac{1060}{49} \* x^{3}+\frac{-780}{49} \* x^{2}+\frac{474}{49} \* x+\frac{-78}{49}&&\\
\frac{157780}{729} \* x^{4}+\frac{-507640}{2187} \* x^{3}+\frac{290864}{729} \* x^{2}+\frac{-101528}{729} \* x+\frac{28028}{729}&&\\
\frac{1}{49} \* (\frac{1400328}{2645} \* x^{3}+\frac{-732888}{2645} \* x^{2}+\frac{1133352}{3703} \* x+\frac{-732888}{18515})&&\\
\frac{1}{2187} \* (\frac{2161816376832}{4669921} \* x^{2}+\frac{-555436846944}{4669921} \* x+\frac{301917024864}{4669921})&&\\
\frac{1}{907235} \* (\frac{469345063045455}{129411872} \* x+\frac{-47641670106615}{129411872})&&\\
\frac{5497465490623352995840}{209648836272383412129}
\end{eqnarray*}
Le lecteur voulant tester d'autres exemples pourra utiliser le programme 
\verb|Xcas| (cf. l'appendice) suivant~:
\begin{verbatim}
pgcd(a):={
  local b,r,res;
  b:=diff(a,x);
  res:=NULL;
  for (;b!=0;){
    res:=res,b;
    r:=rem(a,b);
    a:=b;
    b:=r;
  }
  return(res);
}
\end{verbatim}

\subsubsection{Valeur générique des variables et hypothèses}
Lorsqu'on utilise un symbole sans lui affecter de valeurs en mathématiques 
on s'attend à une discussion en fonction du 
paramètre représenté par ce symbole. Ce qui nécessiterait de créer un 
arborescence de calculs (on retrouve ici les problèmes 
d'explosion évoqués dans la section précédente). 
La plupart des systèmes de calcul formel contournent la difficulté en 
supposant que le paramètre possède une valeur 
générique (par exemple la solution de $(t^2-1)x=t-1$ sera $x=1/(t+1)$) ou 
choisissent une branche pour les fonctions 
possédant un point de branchement (par exemple pour résoudre $x^2=t$ 
en fonction de $t$). Certains systèmes demandent de 
manière interactive à l'utilisateur si la variable est par exemple positive 
ou différente de 1 mais cela s'oppose à un 
traitement automatique. 
On peut aussi anticiper ce type de décision en faisant des hypothèses
sur une paramètre, la plupart des systèmes de calcul formel actuel
proposent cette possibilité.

\subsection{Structures de données}
On a vu plus haut qu'on souhaitait manipuler des entiers de taille non 
fixe, des réels de précision fixe ou non, des
fractions, des nombres complexes, des extensions algébriques, des 
paramètres, des expressions symboliques. La plupart des syst\`emes
proposent un type générique qui recouvre ces divers types de scalaire.
On peut par exemple utiliser un type structuré comportant un champ
type et la donnée ou un pointeur sur la donnée (avec dans ce cas un 
pointeur sur un compteur de références de la donnée
pour pouvoir la détruire dès qu'elle n'est plus référencée\footnote{Certains
systèmes de calcul formel (calculatrices par exemple) utilisent d'ailleurs des
méthodes spécifiques pour gérer le problème de la fragmentation de
la mémoire, appelés ``garbage collector''. Ce type de méthode
est intégré dans des langages comme Lisp ou Java, en C/C++ on trouve
des libraries pour cela, par exemple GC de Boehm, incluse dans la
distribution de GCC.}). 
En programmation orientée objet, on utiliserait plutôt un
type abstrait dont dérivent ces différents scalaires et le polymorphisme.

Il faut aussi un type pour les vecteurs, les matrices et les
listes. Il faut prendre garde \`a la m\'ethode utilis\'ee
par le syst\`eme lorsqu'on modifie un \'el\'ement
d'un vecteur, matrice ou liste~: soit on effectue une copie de tout
l'objet en modifiant l'\'el\'ement, soit on modifie l'\'el\'ement
de l'objet original. La premi\`ere m\'ethode (par valeur) est
plus ais\'ee \`a comprendre pour un d\'ebutant mais
la seconde m\'ethode (par r\'ef\'erence) est bien plus efficace.

On peut se poser la question de savoir s'il faut inclure 
ces types dans le type générique ; en général la 
réponse est affirmative, une des raisons étant que les 
interpréteurs qui permettront de lire des données dans un 
fichier texte sont en général basé sur le couple de logiciels
\verb|lex(flex)/yacc(bison)| qui ne peut compiler qu'à destination d'un 
seul type. Ceci permet également d'unifier en un seul type symbolique 
les fonctions ayant un ou plusieurs arguments en 
voyant plusieurs arguments comme un vecteur d'arguments. 
Les fonctions sont le plus souvent elle-même incluses dans le 
type générique permettant ainsi à l'utilisateur de saisir des 
commandes ou programmes fonctionnels (on peut
utiliser une fonction comme argument d'une commande).

Pour des raisons d'efficacit\'e, les syst\`emes de calcul formel
utilisent souvent des repr\'esentations particuli\`eres pour les polyn\^omes
dont on a dit qu'ils jouaient un r\^ole central.
Pour les polyn\^omes \`a une variable,
on peut utiliser la liste des coefficients du polyn\^ome, on parle
alors de repr\'esentation dense. On peut aussi d\'ecider de ne stocker
que les coefficients non nuls, on parle alors de repr\'esentation creuse
(on stocke alors un couple form\'e par le coefficient et le degr\'e
du mon\^ome correspondant). Pour les polyn\^omes \`a plusieurs variables,
on peut les consid\'erer comme des polyn\^omes \`a une variable \`a
coefficients polynomiaux, on parle alors de repr\'esentation r\'ecursive.
On peut aussi d\'ecider de ne pas briser la sym\'etrie entre les
variables (pas de variable principale), on parle alors de repr\'esentation
distribu\'ee, le plus souvent les repr\'esentation distribu\'ees
sont creuses car les repr\'esentations
denses n\'ecessitent tr\`es vite beaucoup de coefficients. Les m\'ethodes
de repr\'esentation creuses sont parfois aussi utilis\'ees pour les
matrices ayant beaucoup de coefficients nuls.

Voyons maintenant plus précisément sur quelques exemples de logiciels
de calcul formel r\'epandus quelles structures de données sont
utilisées. Plusieurs \'el\'ements entrent en compte dans les choix faits~:
\begin{itemize}
\item le(s) profil(s) d'utilisation (enseignement, ing\'eni\'erie,
calcul intensif, recherche)
\item les ressources disponibles (m\'emoire, puissance du processeur...)
\item la facilit\'e d'impl\'ementation (choix du langage, outils
disponibles en particulier d\'ebuggueurs, ...)
\item l'histoire du syst\`eme (un syst\`eme conçu avec les outils
disponibles aujourd'hui est forc\'ement diff\'erent d'un syst\`eme 
conçu il y a 20 ans)
\end{itemize}
Nous allons d'abord parler des calculatrices formelles HP
et TI (le lecteur pourra facilement les tester grâce aux \'emulateurs gratuits
pour PC). Ce sont des systèmes plutôt destinés à l'enseignement, soumis 
\`a de fortes contraintes en termes de taille m\'emoire, et destinés
à traiter des petits problèmes.
Puis nous pr\'esenterons des syst\`emes pour ordinateur où les ressources
(par exemple m\'emoire) sont moins limit\'ees ce qui permet 
d'utiliser des langages de programmation de plus haut niveau.

\subsubsection{Calculatrices formelles HP}
Les langages utilis\'es pour programmer ces calculateurs sont l'assembleur
et le RPL (Reverse Polish Lisp) adapt\'e \`a l'\'ecriture de code
en m\'emoire morte tr\`es compact.

Le type générique est implémenté avec un champ type appelé prologue (qui est
en fait un pointeur sur la fonction chargée d'évaluer ce type d'objet)
suivi de la donnée elle-même (et non d'un pointeur sur la donnée, on
économise ainsi la place mémoire du compteur de référence).

Le type entier en précision arbitraire est codé par le nombre de digits 
(sur 5 quartets\footnote{un quartet=un demi octet}) suivi du signe sur un 
quartet et de la représentation BCD (en base 10) de la valeur absolue de 
l'entier. Le choix de la représentation BCD a été fait pour optimiser 
les temps de conversion en chaîne de caractères pour l'affichage. La mémoire
vive disponible est de 256K, c'est elle qui limite la taille des entiers 
et non le champ longueur de l'entier. Il n'y a pas de type spécifique 
pour les rationnels (on utilise un objet
symbolique normal). 

Les fonctions internes des HP49/50/40 utilisent 
le type programme pour représenter les entiers de Gau\ss\ (complexes
dont la partie réelle et imaginaire est entière).
Les nombres algébriques ne sont pas implémentés, sauf les racines carrées
(représentée de manière interne par le type programme). 
Il y a un type spécifique prévu pour les flottants en précision arbitraire, 
mais l'implémentation des opérations sur ces types
n'a pas été intégrée en ROM à ce jour. 

Les types listes, programmes et objet symbolique sont composés du prologue
(champ type) suivi par la succession d'objets situés en
mémoire vive ou de pointeurs sur des objets situés en mémoire en lecture 
seule (ROM) et se terminent par un pointeur sur une
adresse fixe (appelée \verb|SEMI|). Ces types sont eux-m\^emes des 
objets et peuvent donc \^etre utilis\'es de mani\`ere
r\'ecursive. La longueur des types listes, programmes, symboliques 
n'est stockée nulle part, c'est le délimiteur final
qui permet de la connaître, ce qui est parfois source d'inefficacité.
On utilise de manière interne les listes pour représenter les 
polyn\^omes denses (avec 
représentation récursive pour les polyn\^omes à plusieurs variables). 

Les calculatrices HP4xG utilisent une pile\footnote{Plus pr\'ecis\'ement deux
piles, la pile de donn\'ee et la pile g\'erant le flux d'ex\'ecution. Cette
derni\`ere n'est pas visible par l'utilisateur}, c'est-à-dire une liste
de taille non fixée d'objets. On place les objets sur la pile,
l'exécution d'une fonction prend ces arguments sur
la pile et renvoie un ou plusieurs résultats sur la pile (ce qui est
une souplesse du RPN comparé aux langages où on ne peut renvoyer
qu'une valeur de retour). Il faut donc
donner les arguments avant d'appeler la fonction correspondante. Par
exemple pour calculer $a+b$ on tapera \verb|a b +|. C'est
la syntaxe dite polonaise inversée (RPN). Un avantage de cette syntaxe
est que le codage d'un objet symbolique par cette syntaxe est évidente,
il suffit de stocker la liste précédente \verb|{a b +}|.
Les objets symboliques sont donc représenté par une suite d'objets écrit
en syntaxe polonaise inversée. L'\'evaluation d'un objet symbolique se fait
dans l'ordre polonaise invers\'e~: les arguments sont \'evalu\'es
puis les fonctions leur sont appliqu\'es. Pour des raisons d'efficacit\'e, 
on repr\'esente souvent les objets composites (listes, symboliques) par 
leurs composants plac\'es sur la pile (appel\'e meta-objets).

Une rigidité de la syntaxe polonaise est
que les fonctions ont toujours un nombre fixe d'arguments\footnote{Sauf si
on utilise comme dernier argument le nombre d'arguments de la fonction ou 
si on utilise (cf. infra) un tag de début de liste d'arguments}, par
exemple l'addition a toujours 2 arguments, ainsi
$a+b+c$ est obtenu par $(a+b)+c$ ou par $a+(b+c)$
c'est-à-dire respectivement \verb|a b + c +| ou \verb|a b c + +| ce qui
brise parfois artificiellement la symétrie de certaines opérations. En
polonaise inversée, le système doit de plus jongler avec l'autoquote puisque
les arguments sont évalués avant l'opérateur qui éventuellement demanderait
à ne pas évaluer ses arguments. \`A noter l'existence d'une commande 
\verb|QUOTE| permettant \`a  l'utilisateur de quoter une sous-expression.

Les hypothèses sur des variables réelles sont regroupées dans une liste
stockée dans la variable globale \verb|REALASSUME|, on peut supposer
qu'une variable est dans un intervalle. Il n'y a pas à ce jour
de possibilité de supposer qu'une variable est entière (ni à fortiori
qu'une variable à une valeur modulo un entier fixé), bien qu'il ait été
décidé de réserver la variable globale \verb|INTEGERASSUME| à cet effet.
Il n'y a pas de possibilité de faire des hypothèses ayant une portée
locale.

\subsubsection{Calculatrices formelles TI}
Le langage utilis\'e pour programmer ces calculatrices est le langage C
(on peut aussi \'ecrire du code en assembleur pour ces calculatrices).
On retrouve ici les diff\'erents types de donn\'ees regroup\'e en un
type g\'en\'erique qui est un tableau d'octets (aussi appelé quantum). 
Le champ type
est appel\'e tag dans la documentation TI. Contrairement \`a ce qui
pr\'ec\`ede, ce champ type est plac\'e en m\'emoire \`a la fin de l'objet,
ce qui est possible car la longueur d'un objet est toujours indiqu\'ee
au d\'ebut de l'objet. Ceci est fait afin de faciliter l'évaluation (cf.
infra).

Les entiers en précision arbitraire sont codés par un tag parmi deux (pour
différencier le signe), un octet pour la longueur, puis la valeur
absolue de l'entier (en base 256). Ils sont donc limités par le
champ longueur à 255 octets, le plus grand entier représentable est
\footnote{Toutefois une adaptation du logiciel utilisant comme
quantum de base par exemple 32 bits porterait cette limite
à $65536^{65535}-1$} $(256^{255}-1)$.
Il existe un tag spécifique pour les rationnels, pour les constantes 
réelles et entières qui apparaissent par exemple en r\'esolvant une \'equation.
Il existe des tags utilisés de manière interne, par exemple
pour les nombres complexes. 
Il n'y a pas de tag prévu pour les flottants en précision arbitraire.
ni pour les nombres algébriques (racines carrées par 
exemple).

Les listes sont codées par la succession de leurs éléments. En principe
elles ne peuvent pas contenir des listes (sauf pour repr\'esenter
une matrice).
Quelques fonctions utilisent les listes pour représenter des polynômes 
denses à une variable, mais probablement pas pour représenter de manière
récursive des polynômes à plusieurs variables (puisque le type liste
n'est en principe pas récursif).

Comme les HP, les TI utilisent une pile (non visible par
l'utilisateur) appelée expression stack
afin de traduire un expression math\'ematique sous forme d'un texte
en un objet symbolique cod\'e exactement comme ci-dessus en syntaxe
polonaise. Toutefois, la pr\'esence du champ longueur
permet d'\'evaluer un objet symbolique sans perdre en efficacit\'e
en partant de l'op\'erateur
final et en redescendant ensuite sur ces arguments, c'est la stratégie
adoptée. C'est pour cela que le tag d'identification
se trouve à la fin de l'objet. L'utilisation de cette méthode
facilite grandement l'autoquotation (on peut toutefois regretter
que le système n'ait pas prévu d'instruction permettant à l'utilisateur 
d'emp\^echer l'évaluation d'une sous-expression).

On ne peut pas faire d'hypothèse globale sur un paramètre par
contre on peut faire des hypothèses de type appartenance à un intervalle 
ayant une portée locale.

\subsubsection{Maple, MuPAD, Mathematica, ...}
Ces syst\`emes ont un noyau ferm\'e, au sens o\`u l'utilisateur n'a pas
acc\`es du tout, ou en tout cas pas facilement, aux structures de donn\'ees
de base. Je ne dispose donc pas d'information sur les structures de donn\'ees
utilis\'ees par le noyau (pour MuPAD, on pourrait sans doute en savoir
plus en achetant de la documentation sur la programmation des
modules dynamiques).

L'interaction système-utilisateur se fait quasiment toujours en utilisant le
langage de programmation propre au syst\`eme, langage interpr\'et\'e
par le noyau du syst\`eme (ce qui ralentit l'exécution). Ces langages 
utilisateurs sont essentiellement
non typ\'es~: on travaille avec des variables du type générique sans pouvoir
accéder aux types sous-jacents. On ne bénéficie en g\'en\'eral pas des
v\'erifications faites lors de la compilation avec un langage typé,
de plus ces systèmes ne sont pas toujours fourni avec de bon outils de 
mise au point. Enfin ces langages ne sont pas standardisés d'un
système à l'autre et il est en général impossible
d'utiliser ces systèmes comme des librairies depuis un langage
de programmation traditionnel. Leur intérêt principal réside donc
dans une utilisation interactive en profitant de la librairie de 
fonctions accessibles.

\subsubsection{Giac/xcas}
Il s'agit du système de calcul formel que j'implémente actuellement sous 
forme d'une biblioth\`eque C++ (ce qui
permettra aux programmes tiers d'utiliser beaucoup plus facilement du 
calcul formel qu'avec les syst\`emes pr\'ec\'edents). L'objectif est 
d'avoir un syst\`eme facile \`a programmer directement en C++, proche 
du langage utilisateur, lui-m\^eme compatible avec Maple ou MuPAD, 
tout cela sans trop perdre en performances comparativement aux
librairies sp\'ecialis\'ees \'ecrites en C/C++. Ce qui explique un choix 
de type g\'en\'erique (\verb=gen=) non orient\'e objet, avec un champ type 
et soit une donn\'ee imm\'ediate (pour les nombres flottants par exemple), 
soit un pointeur vers un objet du type correspondant au champ type pour 
les donn\'ees de taille non fixe (on pourrait donc se
contenter du langage C, mais le langage C++ permet de red\'efinir 
les op\'erateurs sur des types utilisateurs ce qui
am\'eliore consid\'erablement la lisibilit\'e du code source). 
Les donn\'ees dynamiques ne sont pas dupliqu\'ees, Giac
utilise un pointeur sur un compteur de r\'ef\'erence pour d\'etruire 
ces donn\'ees lorsqu'elles ne sont plus r\'ef\'erenc\'ees.

Les entiers en pr\'ecision arbitraire sont h\'erit\'es de la biblioth\`que
GMP (\'ecrite en C) du projet GNU. Les flottants en pr\'ecision arbitraire
utiliseront aussi GMP (plus précisément MPFR).
Il y a un type fraction, structure C compos\'e d'un champ num\'erateur
et d'un champ d\'enominateur, et un type nombre complexe.

Les listes, vecteurs, matrices utilisent le type paramétré \verb|vector<>|
de la librairie standard C++ (Standard Template Library).
Les objets symboliques sont des structures compos\'es d'un champ sommet
qui est une fonction prenant un argument de type \verb|gen|
et renvoyant un r\'esultat
de type \verb|gen|, et d'un champ feuille qui est de type \verb|gen|.
Lorsqu'une fonction poss\`ede plusieurs arguments, ils sont rassembl\'es
en une liste formant le champ feuille de l'objet symbolique.
Les programmes sont aussi des objets symboliques, dont le champ
sommet est la fonction évaluation d'un programme.
Les listes sont aussi utilis\'ees pour repr\'esenter vecteurs, matrices
et polyn\^omes en une variable en repr\'esentation dense, on peut
y acc\'eder par valeur (\verb|:=|) ou par r\'ef\'erence
(\verb|=<|). Les polyn\^omes
en repr\'esentation creuse ou en plusieurs ind\'etermin\'ees sont \'egalement
disponibles.

L'évaluation d'un objet symbolique se fait en regardant d'abord si
la fonction au sommet doit évaluer ou non ses arguments (autoquote),
on évalue les arguments si nécessaire puis on applique la fonction.

Une hypthèse sur un paramètre est une valeur spéciale
affectée au paramètre, valeur ignorée par la routine d'évaluation.

\subsection{Algorithmes et complexité.}
On va présenter dans la suite quelques algorithmes que l'on peut
considérer comme classiques dans le domaine du calcul formel. Avant 
d'implémenter ce type d'algorithmes, on a besoin des algorithmes de base
en arithmétique. Le lecteur trouvera en appendice une brève présentation
de certains de ces algorithmes, mes références en la matière sont le livre
de Henri Cohen, et les livres de Donald Knuth (cf. appendice).

La plupart des problèmes posés en calcul formel nécessitent des
calculs dont la taille croit de manière exponentielle voire
doublement exponentielle en fonction de la taille des données et
ce même si le résultat est lui aussi de taille petite. Un
exemple est la réduction des systèmes de plusieurs équations polynomiales
(bases de Groebner).
Dans certains cas, l'application de théories mathématiques
parfois sophistiquées permet de réduire la complexité (par exemple,
M. Van Hoeij a découvert récemment qu'un algorithme très utilisé en théorie des
nombres, l'algorithme LLL, permettait d'améliorer la complexité d'une des
étapes de la factorisation des polynomes à coefficients entiers sur les
entiers). Heureusement, dans de nombreux cas, on peut r\'eduire la
complexit\'e (donc le temps de calcul) par des adaptations au
probl\`eme d'une m\^eme id\'ee \`a condition de faire des
hypoth\`eses sur les donn\'ees (autrement dit en abandonnant la volont\'e
d'impl\'ementer un algorithme tr\`es g\'en\'erique, ou tout au moins
en sp\'ecialisant des algorithmes g\'en\'eriques).

Par exemple lorsqu'on travaille
avec des entiers (ou des polyn\^omes \`a coefficients entiers, ou
des matrices \`a coefficients entiers...) on utilise souvent des algorithmes
modulaires et $p$-adiques. Comme le calcul exact n\'ecessite
presque toujours de calculer avec des entiers, ces m\'ethodes
ont un r\^ole central en calcul formel, nous les pr\'esentons donc
maintenant bri\`evement. Dans les prochaines sections, nous utiliserons
ce type de m\'ethode, par exemple pour le calcul de PGCD ou la factorisation
de polyn\^omes \`a coefficients entiers.

Les m\'ethodes modulaires consistent \`a r\'eduire un probl\`eme dans 
$\Z$ \`a son \'equivalent dans $Z/n\Z$ pour une ou 
plusieurs valeurs de $n$, nombre premier. Le calcul dans $\Z/n\Z$
a l'avantage de se faire avec des entiers dont la taille est bornée.
Ensuite \`a l'aide d'estimations 
\`a priori sur la taille des solutions 
\'eventuelles du probl\`eme initial, on reconstruit la solution au problème
initial avec le th\'eor\`eme des restes chinois. 

Par exemple, on peut calculer un d\'eterminant d'une matrice
\`a coefficients entiers en cherchant ce d\'eterminant dans $\Z/n\Z$
pour plusieurs premiers $n$, dont le produit est plus grand qu'une 
estimation \`a priori de la taille du d\'eterminant 
(donnée par exemple par l'inégalité d'Hadamard, cf. Cohen, p. 50). 

Les m\'ethodes $p$-adiques commencent de mani\`ere identique par un 
calcul dans $\Z/n\Z$, on augmente ensuite la
pr\'ecision de la solution en la \og liftant\fg de $\Z/n^k \Z$ vers 
$\Z/n^{k+1}\Z$ ou vers $\Z/n^{2k}\Z$ (lift
lin\'eaire ou lift quadratique), on s'arr\^ete lorsque $k$ est assez grand 
(\`a l'aide d'estimations \`a priori) et on
reconstruit alors la solution initiale. L'\'etape de \og lift\fg est en 
g\'en\'eral un lemme de Hensel dont on verra quelques exemples dans les
prochains articles. L'algorithme
commun au lemme de Hensel et au th\'eor\`eme des restes chinois est 
l'identit\'e de B\'ezout, que l'on retrouve 
d'ailleurs un peu partout (par exemple pour le calcul de primitives). 

Illustrons cette méthode sur un exemple simple, la recherche de 
racines rationnelles d'un polyn\^ome $P(X)=a_d X^d + \cdots + a_0$ 
\`a coefficients entiers ou polynomiaux, avec $a_d$ et $a_0$ non nuls. 
L'algorithme g\'en\'erique (assez connu) consiste 
\`a chercher les diviseurs de $a_0$ et de $a_d$ et \`a tester toutes 
les fractions de ces diviseurs, on montre en effet 
ais\'ement que si $X=p/q$ fraction irr\'eductible est racine de $P$ 
alors $q$ divise $a_d$ et $p$ divise $a_0$. Cet 
algorithme est tr\`es inefficace si $a_d$ ou $a_0$ est un grand entier 
(car on ne sait pas forc\'ement le factoriser) ou 
s'il a beaucoup de facteurs premiers (la liste des diviseurs \`a tester 
est alors tr\`es grande). 

Lorsque les coefficients de $P$ sont entiers, la recherche pr\'ec\'edente 
revient \`a trouver un facteur \`a
coefficients entiers $qX-p$ de $P$, on peut donc r\'eduire le probl\`eme 
modulo un entier premier $n$ qui ne divise pas $a_d$~: si un tel facteur 
existe dans $\Z$ alors ce facteur (r\'eduit modulo $n$) est un facteur 
de $P$ dans $\Z/n\Z$
donc $P$ admet une racine dans $\Z/n\Z$ (puisque $q$ est inversible 
modulo $n$ car on a choisi $n$ premier ne divisant pas $a_d$). On
\'evalue maintenant $P$ en les $n$ \'el\'ements de $\Z/n\Z$. S'il n'y a pas 
de 0, alors $P$ n'a pas de racine rationnelle. S'il y a des racines, on va 
les lifter de $\Z/n^k\Z$ dans $\Z/n^{2k}\Z$.

On suppose donc que pour $k\geq 1$, il existe un entier $p_k$ tel que
\[ P(p_k)=0 \pmod{n^k} \]
Il s'agit de trouver un entier $x$ tel que $p_{k+1}=p_k+n^k \* x$
vérifie
\[ P(p_{k+1})=0 \pmod{n^{2k}} \]
On applique la formule de Taylor \`a l'ordre 1 pour $P$ en $p_k$, le
reste est nul modulo $n^{2k}$, donc~:
\[ P(p_k)+ n^k \* x P'(p_k)=0 \pmod{n^{2k}} \]
soit finalement~:
\[ x=-\frac{P(p_k)}{n^k} \* ( P'(p_k) \pmod{n^k}) ^{-1} \]
On reconnaît au passage la méthode de Newton, pour qu'elle fonctionne 
il suffit que $P'(p_k) \neq 0 \pmod n$ ce qui
permet de l'inverser modulo $n^k$ (et c'est ici qu'intervient 
l'identit\'e de B\'ezout). En pratique quand on factorise
un polyn\^ome, on commence par retirer les multiplicités, 
on peut donc supposer que $P$ est sans facteur multiple dans
$\Z$. Ceci n'entraîne pas forcément qu'il le reste dans $\Z/n\Z$ 
ce qui crée une contrainte supplémentaire sur le choix
de $n$, à savoir que $P$ et $P'$ restent premier entre eux dans $\Z/n\Z$ 
(il existe forcément de tels $n$, par exemple
$n$ premier plus grand que le plus grand entier intervenant dans le calcul 
du PGCD de $P$ et $P'$ dans $\Z$).

Reste donc à revenir dans $\Z$ à partir d'une racine $p_k$ dans $\Z/(n^k \Z)$
(où on peut choisir $k$). 
On va maintenant utiliser la repr\'esentation modulaire sym\'etrique~:
on prend comme représentant modulaire d'un entier $z$ dans $\Z/n^k\Z$
l'unique entier congru \`a $z$ modulo $n$ qui est strictement compris entre
$-n^k/2$ et $n^k/2$ (si $n$ est pair, la deuxi\`eme in\'egalit\'e
est choisie large).

Si $qX-p$ est un facteur de $P$, alors $a_dX-\frac{a_d}{q}p$ est encore 
un facteur de $P$ (le quotient de $P$ par $a_dX-\frac{a_d}{q}p$
est \`a coefficients rationnels mais le facteur est \`a coefficients entiers). 
Si on a choisi $k$ tel que $n^k>2|a_d a_0|$, l'\'ecriture en représentation
modulaire symétrique de $a_dX-\frac{a_d}{q}p$ est inchang\'ee,
en effet on a des estimations à priori sur les entiers $p$ et $q$~: 
$|q|\leq |a_d|$ et $|p| \leq |a_0|$ puisque $q$ 
divise $a_d$ et $p$ divise $a_0$. 
Comme $a_dX-\frac{a_d}{q}p$ est \'egal \`a $a_d(X-p_k)$ dans $\Z/(n^k \Z)$,
il nous suffit d'écrire en repr\'esentation modulaire 
sym\'etrique $a_d(X-p_k)=a_d X-p'$.
Pour conclure, on sait que $a_d X-p'$ est un multiple entier de $qX-p$.
On divise donc le facteur $a_d X-p'$ par le pgcd de $a_d$ et $p'$ et on
teste la divisibilité de $P$ par ce facteur réduit.

{\bf Exemple}\\
Consid\'erons le polyn\^ome $2 X^3-X^2-X-3$ qui est sans facteur carr\'e.
On ne peut pas choisir $n=2$ car on r\'eduirait le degr\'e, pour $n=3$,
on a $P'=X-1$ qui est facteur de $P$, pour $n=5$, $P'=6X^2-2X-1$,
on v\'erifie que $P$ et $P'$ sont premiers entre eux (par exemple
avec \verb|GCDMOD| sur une HP49 o\`u on aura fix\'e la variable \verb|MODULO|
\`a 5).

On teste ensuite les entiers de -2 \`a 2 sur $P$. Seul -1 est racine
modulo 5 ($P(-1)=-5$), on va maintenant lifter $p_1=-1$. 

L'estimation \`a priori est $2|a_d||a_0|=12$ donc $k=2$ ($5^2=25>12$), 
une it\'eration suffira. On a $P'(-1)=7$, l'inverse de $P'(-1) \pmod 5$
est -2 donc:
\[ x= -\frac{P(-1)}{5} (-2) = -(-1) \* (-2)=-2 \]
et $p_2=-1+5\times(-2)=-11$ est racine de $P$ dans $\Z/25\Z$.
On calcule ensuite $a_d(X-p_k)=2(X+11)=2X+22=2X-3$ en repr\'esentation
sym\'etrique, le PGCD de 2 et -3 est 1 donc on teste le facteur
$2X-3$, ici il divise $P$ donc $P$ admet un unique facteur entier
de degr\'e 1 qui est $2X-3$.


\section{Quelques algorithmes d'arithmétique de base.}
\begin{itemize}
\item Les algorithmes de multiplication et division dit rapides
des entiers et polyn\^omes (Karatsuba, FFT, ...). Cf. par exemple Knuth.
ou pour les entiers la documentation de GMP.
\item Au lieu de la division euclidienne, on utilise très souvent la
pseudo-division pour les polynômes~: étant donné deux polyn\^omes $A$
et $B$ de degrés $a$ et $b$ à coefficients dans un anneau contenu dans un corps
(par exemple $\Z$), on multiplie $A$ par une puissance du coefficient
dominant $B_b$ de $B$, plus précisément par $B_b^{a-b+1}$, ce qui permet 
d'effectuer la division par $B$ sans que
les coefficients sortent de l'anneau.
\[ B_b^{a-b+1} A= B Q + R \]
On utilise cette méthode lorsqu'on peut multiplier les polyn\^omes par
des constantes sans changer le problème (par exemple pour l'algorithme
d'Euclide).
\item L'algorithme d'Euclide est un algorithme \og générique\fg de calcul
de PGCD. Il n'est en général pas utilisé tel quel. Pour les entiers 
on utilise une variation adaptée à la
représentation binaire des entiers (cf. Cohen ou le manuel de GMP version 4 
pour plus de détails). Nous décrirons des
algorithmes de PGCD plus efficaces pour les polynômes dans le prochain article.
\item l'identité de Bézout, aussi appelée PGCD étendu. \'Etant donné
deux entiers ou deux polyn\^omes $a$ et $b$ on calcule $u$, $v$ et
$d$ tels que $au+bv=d$. On écrit la matrice~:
\[ \left( \begin{array}{lll}
a & 1 & 0 \\
b & 0 & 1
\end{array} \right) \]
où on remarque que pour chaque ligne le coefficient de la 1ère colonne 
est égal à $a$ multiplié par le coefficient de la
2ème colonne additionné à $b$ multiplié par le coefficient de la 
3ème colonne. Ce qui reste vrai si on effectue des
combinaisons linéaires de lignes (type réduction de Gau\ss). 
Comme on travaille dans les entiers ou les polyn\^omes, on remplace la
réduction de Gau\ss\ des matrices à coefficients réels par une combinaison 
linéaire utilisant le quotient {\em euclidien\/} $q$
de $a$ par $b$. On obtient alors le reste $r$ en 1ère colonne~:
\[ L_3=L_1-qL_2 \quad \left( \begin{array}{lll}
a & 1 & 0 \\
b & 0 & 1 \\
r & 1 & -q
\end{array} \right) \]
et on recommence jusqu'à obtenir 0 en 1ère colonne.
L'avant-dernière ligne obtenue est l'identité de Bézout (la dernière
ligne donne le PPCM de $a$ et $b$). Si l'on veut l'inverse de $a$ modulo
$b$ on remarque qu'il n'est pas utile de calculer les coefficients
appartenant à la 3ème colonne. Enfin, les lignes intermédiaires
peuvent servir à reconstruire une fraction d'entier représentée
par un entier de $\Z/n\Z$ lorsque le numérateur et le dénominateur
sont de valeur absolue inférieure à $\sqrt{n/2}$.
\item Le théorème des restes chinois. Si on connaît $x=a \pmod m$
et $x= b \pmod n $ avec $m$ et $n$ premiers entre eux,
on détermine $c$ tel que
$x=c \pmod{m\times n}$ ($c=a+mu=b+nv$ et on applique
Bézout pour trouver $u$ et $v$, on en d\'eduit $c$).
\item Les tests de pseudo-primalité. Il est essentiel d'avoir une
méthode rapide permettant de générer des nombres premiers pour appliquer
des méthodes modulaires et $p$-adiques. On utilise par exemple le
test de Miller-Rabin, qui prolonge le petit théorème de Fermat
(si $p$ est premier, alors $a^p=a \pmod p$).
\end{itemize}

\subsection{Pour en savoir plus.}
Sur des aspects plus th\'eoriques~:
\begin{itemize}
\item Knuth: TAOCP (The Art of Computer Programming), volumes 1 et suivants
\item Henri Cohen: A Course in Computational Algebraic Number Theory
\item Davenport, Siret, Tournier: Calcul formel: Syst\`emes et algorithmes 
de manipulations  alg\'ebriques
%\item quelques articles en ligne dont un article sur l'\'evaluation:\\
%\verb|http://www.cs.berkeley.edu/~fateman/algebra.html|
\end{itemize}

Sur des aspects plus pratiques, quelques r\'ef\'erences en ligne, 
la plupart sont accessibles  gratuitement~:
\begin{itemize}
\item le code source de Giac disponible à l'URL~:\\
\verb|http://www-fourier.ujf-grenoble.fr/~parisse/giac.html|
\item le code source de GiNaC, cf.~:
\verb|http://www.ginac.de|
\item le site \verb|http://www.hpcalc.org| pour les calculatrices HP,
on y trouve tout, de la documentation, des \'emulateurs de
calculatrices HP, des outils de d\'eveloppement pour Windows
et Unix/Linux, ... Pour ce qui concerne cet article, je conseille de lire\\
\verb|http://www.hpcalc.org/hp48/docs/programming/rplman.zip|
\item le site \verb|http://www.ticalc.org|, on y trouve le portage
tigcc du compilateur C de GNU, des \'emulateurs, etc. Des informations de 
cet article ont leur source dans le guide du
d\'eveloppeur TI89/92\\
\verb|http://education.ti.com/|
\item la librairie du système \verb|MuPAD| (archivée dans le fichier
\verb|lib.tar| des distributions Unix, pour une installation
par d\'efaut, ce fichier
se trouve dans le r\'erpertoire \verb|/usr/local/MuPAD/share/lib|),  
cf. \verb|www.sciface.com| pour obtenir une licence
d'utilisation.
\item en Maple, il est possible de
décompiler une instruction \verb|Maple| avec la commande\\
\verb|eval(instruction);|\\
après avoir tapé\\
\verb|interface(verboseproc=2);|
\item le source du plus ancien système de calcul formel \verb|maxima|
(devenu logiciel libre) pour les personnes famili\`eres du langage Lisp\\
\verb|http://sourceforge.net/projects/maxima|\\
de m\^eme pour le syst\`eme Axiom
\item le source de librairies plus spécialisées (GMP, GP-PARI, Singular,
NTL, Zen, ALP, GAP, CoCoA, ...), rechercher ces moms sur google.
\end{itemize}

\pagebreak

\section{Exercices  sur types, calcul exact et approch\'e, 
algorithmes  de  bases}
Pour t\'el\'echarger et installer Xcas sur votre ordinateur, suivre
les instructions donn\'ees sur\\
\verb|http://www-fourier.ujf-grenoble.fr/~parisse/giac_fr.html|\\
Pour lancer {\tt xcas} sous Unix, ouvrir un fen\^etre terminal et
taper la commande\\
\verb|  xcas & |\\
Lors de la premi\`ere ex\'ecution, vous devrez choisir entre
diff\'erents types de syntaxe (compatible C, maple ou TI89). Vous
pouvez changer ce choix \`a tout moment en utilisant le menu
Configuration->mode (syntaxe).

%Pour lancer maple, taper {\tt xmaple} \`a la place de {\tt xcas}.

L'aide en ligne est accessible en tapant \verb|?nom_de_commande|.
Dans Xcas, vous pouvez aussi taper le d\'ebut d'un
nom de commande puis la touche de tabulation (\`a gauche du A sur
un clavier francais), s\'electionner la commande dans la boite
de dialogues puis cliquer sur Details pour avoir une aide plus
compl\`ete dans votre navigateur. Pour plus de d\'etails sur
l'interface de Xcas, consultez le manuel (Aide->Interface).
Si vous n'avez jamais utilis\'e de logiciel de calcul formel,
vous pouvez commencer par lire le tutoriel (menu Aide->Debuter en
calcul formel->tutoriel) et faire certains des exercices 
propos\'es (des corrig\'es sous forme de sessions Xcas sont 
dans Aide->Debuter en calcul formel->solutions)

Il peut \^etre interessant de tester ces exercices
en parall\`ele avec Xcas et des calculatrices
formelles....
\begin{enumerate}
\item Utiliser la commande {\tt type} ou {\tt whattype} ou \'equivalent
pour déterminer la représentation
utilisée par le logiciel pour représenter
une fraction, un nombre complexe, un flottant en précision machine, 
un flottant avec 100 décimales, la variable $x$, l'expression $\sin(x)+2$,
la fonction {\tt x->sin(x)}, une liste, une séquence, un vecteur,
une matrice. Essayez d'accéder aux parties de
l'objet pour les objets composites (en utilisant {\tt op} par exemple).

\item Comparer le type de l'objet \verb|t| si on effectue
la commande \verb|t[2]:=0;| apr\`es avoir purg\'e \verb|t|
ou apr\`es avoir affect\'e \verb|t:=[1,2,3]|~?

\item Comparer l'effet de l'affectation dans une liste et dans un
  vecteur ou une matrice sur votre logiciel (en Xcas, on peut utiliser
\verb|=<| au lieu de \verb|:=| pour stocker par r\'ef\'erence).

\item Voici un programme qui calcule la base utilis\'ee
pour repr\'esenter les flottants. 
\begin{verbatim}
Base():={
  local A,B;
  A:=1.0; B:=1.0;
  while (evalf(evalf(A+1.0)-A)-1.0=0.0) { A:=2*A;};
  while (evalf(evalf(A+B)-A)-B<>0) { B:=B+1;}
  return B;
} :;
\end{verbatim}
Testez-le et expliquez.

\item Déterminer le plus grand r\'eel positif $x$ de la forme 
$2^{-n}$ ($n$ entier)
tel que $(1.0+x)-1.0$ renvoie 0 sur PC avec la pr\'ecision par
d\'efaut puis avec \verb|Digits:=30|.

\item Calculer la valeur de $a:=\exp(\pi \sqrt{163})$ avec 30 chiffres
significatifs, puis sa partie fractionnaire. Proposez une commande
permettant de décider si $a$ est un entier.

\item 
D\'eterminer la valeur et le signe de la fraction rationnelle 
\[ F(x,y)= \frac{1335}{4} y^6 + x^2 (11x^2 y^2-y^6 -121y^4-2) + 
\frac{11}{2} y^8 + \frac{x}{2y}\]
en $x=77617$ et $y=33096$ en faisant deux calculs, l'un en mode approché et 
l'autre en mode exact. Que pensez-vous de ces résultats?
Combien de chiffres significatifs faut-il pour obtenir un r\'esultat
raisonnable en mode approch\'e?

\item \`A quelle vitesse votre logiciel multiplie-t-il des
grands entiers (en fonction du nombre de chiffres)? 
On pourra tester le temps de calcul du produit
de $a(a+1)$ o\`u $a=10 000!$, $a=15000!$, etc. 

\item Comparer le temps de calcul de $a^n \pmod m$ par la fonction
\verb|powmod| et la méthode prendre le reste modulo $m$ après avoir 
calculé $a^n$.\\
Programmez la méthode rapide et la méthode lente.\\
Que se passe-t-il si on essaie d'appliquer l'algorithme de la
puissance rapide pour calculer $(x+y+z+1)^{32}$~? Calculer le nombre
de termes dans le d\'eveloppement de $(x+y+z+1)^n$ et expliquez.

\item D\'eterminer un entier $c$ tel que $c=1 \pmod 3$, 
$c=3 \pmod 5$, $c=5 \pmod 7$ et $c=2 \pmod 11$.

\item Programmation de la m\'ethode de Horner\\
Il s'agit d'évaluer efficacement un polynôme 
\[ P(X) = a_n X^n + ... + a_0 \]
en un point.
On pose $b_0=P(\alpha )$ et on \'ecrit~:
\[ P(X)-b_0=(X-\alpha )Q(X) \]
o\`u~:
\[ Q(X) = b_n X^{n-1} + ... +b_2 X + b_1 \]
On calcule alors par ordre d\'ecroissant $b_n$, $b_{n-1}$, ..., $b_0$.
\begin{enumerate}
\item
Donner $b_n$ en fonction de $a_n$ puis pour $i\leq n-1$, $b_i$
en fonction de $a_i$ et $b_{i+1}$. Indiquez le d\'etail des calculs
pour $P(X)=X^3-2X+5$ et une valeur de $\alpha $ non nulle.
\item \'Ecrire un fonction \verb|horn| effectuant ce calcul:
on donnera en arguments le polyn\^ome sous forme de la
liste de ces coefficients (dans l'exemple \verb|[1,0,-2,5]|) et la
valeur de $\alpha $ et le programme renverra $P(\alpha )$.
(On pourra aussi renvoyer les coefficients de $Q$).
\item
En utilisant cette fonction, écrire une fonction qui calcule
le développement de Taylor complet d'un polynôme en un point.
\end{enumerate}

\item Algorithmes de base~: \'ecrire des programmes impl\'ementant
\begin{enumerate}
\item le pgcd de 2 entiers
\item l'algorithme de B\'ezout
\item l'inverse modulaire en ne calculant que ce qui est n\'ecessaire
dans l'algorithme de B\'ezout
\item les restes chinois
\end{enumerate}

\end{enumerate}

\pagebreak

\section{Le PGCD}
Comme on l'a remarqué dans le premier article, l'algorithme d'Euclide est
inefficace pour calculer le pgcd de deux polynômes à coefficients entiers. On
va présenter ici les algorithmes utilisés habituellement par les systèmes de
calcul formel: sous-résultant (PRS), modulaire (GCDMOD), $p$-adique (EEZGD) et
heuristique (GCDHEU). Le premier est une adaptation de l'algorithme d'Euclide
et s'adapte à des coefficients assez génériques. Les trois autres ont en
commun d'évaluer une ou plusieurs variables du polynôme (dans ce dernier cas
il est nécessaire de bien distinguer le cas de polynômes à plusieurs
variables) et de reconstruire le pgcd par des techniques distinctes, la
plupart du temps ces algorithmes fonctionnent seulement si les coefficients
sont entiers.

Soit donc $ P$ et $Q$ deux polynômes à coefficients dans un corps. Le
pgcd de $P$ et $Q$ n'est défini qu'à une constante près. Mais lorsque les
coefficients de $P$ et $Q$ sont dans un anneau euclidien comme par exemple
$\mathbb{Z}$ ou
$\mathbb{Z}[ i ]$, on appelle pgcd de $P$ et $Q$ un polynôme $D$ tel
que $P / D$ et $Q / D$ soient encore à coefficients dans l'anneau, et que $D$
soit optimal, c'est-à-dire que si un multiple $\mu D$ de $D$ vérifie $P / \mu
D$ et $Q / \mu D$ sont à coefficients dans l'anneau, alors $\mu$ est
inversible. La première étape d'un algorithme de calcul de pgcd consiste donc
à diviser par le pgcd des coefficients entiers de chaque polynôme.

{\bf{Exemple}}: $P = 4 X^2 - 4$ et $Q = 6 X^2 + 12 X + 6$. Le polynôme
$X + 1$ est un pgcd de $P$ et $Q$ puisqu'il est de degré maximal divisant $P$
et $Q$ mais le pgcd de $P$ et $Q$ est $2 ( X + 1 )$. Remarquons qu'avec notre
définition $- 2 ( X + 1 )$ convient aussi. Par convention on appelera pgcd le
polynôme ayant un coefficient dominant positif.

{\bf{Définition}}: On appelle contenu $c ( P )$ d'un polynôme $P$ le
pgcd des coefficients de $P$. On définit alors la partie primitive de $P$:
pp$( P ) = P / c ( P )$. Si $c(P)=1$, on dit que $P$ est primitif.
On montre que~:
\[ D = \mbox{pgcd} ( P, Q ) = \mbox{pgcd} ( c ( P ), c ( Q )) \mbox{pgcd} (
   \mbox{pp} ( P ), \mbox{pp} ( Q )) \]

\subsection{Le sous-résultant.}

La première idée qui vient à l'esprit pour améliorer l'efficacité de
l'algorithme d'Euclide consiste à éviter les fractions qui sont créées par les
divisions euclidiennes. On utilise à cet effet la pseudo-division: au lieu de
prendre le reste $R$ de la division euclidienne du polynôme $P$ par $Q$, on
prend le reste de la division de $P q^{\delta + 1}$ par $Q$, où $q$ désigne le
coefficient dominant de $Q$ et $\delta$ la différence entre le degré de $P$ et
de $Q$.

{\bf{Exercice:}} En utilisant votre système de calcul formel préféré,
calculez les restes intermédiaires générés dans l'algorithme d'Euclide
lorsqu'on utilise la pseudo-division par exemple pour les polynômes $P ( x ) =
( x + 1 )^7 - ( x - 1 )^6$ et sa dérivée.

{\bf{Une solution avec giac/xcas}}:
\begin{verbatim}
// -*- mode:C++ -*- a,b 2 polynomes -> pgcd de a et b
pgcd(a,b):={ 
 local P,p,Q,q,R,g,h,d;
 // convertit a et b en polynomes listes et extrait la partie primitive   
 P:=symb2poly1(a);
 p:=lgcd(P); // pgcd des elements de la liste
 P:=P/p; 
 Q:=symb2poly1(b);
 q:=lgcd(Q);
 Q:=Q/q; 
 if (size(P)<size(Q)){ // echange P et Q
  R:=P; P:=Q; Q:=R; 
 } 
 // calcul du contenu du pgcd
 p:=gcd(p,q);
 g:=1;
 h:=1;
 while (size(Q)!=1){
  q:=Q[0]; // coefficient dominant
  d:=size(P)-size(Q);
  R:=rem(q^(d+1)*P,Q);
  if (size(R)==0) return(p*poly12symb(Q/lgcd(Q),x));
  P:=Q;
  Q:=R;
  // ligne suivante a decommenter pour prs 
  // Q:=R/(g*h^d);
  print(Q);
  // ligne suivante a decommenter pour prs 
  // g:=q; h:=q^d/h^(d-1);
 } 
 return(p);
}
\end{verbatim}
On s'aperçoit que les coefficients croissent de manière exponentielle. La
deuxième idée qui vient naturellement est alors à chaque étape de rendre le
reste primitif, donc de diviser $R$ par le pgcd de ces coefficients. Cela
donne un algorithme plus efficace, mais encore assez peu efficace car à chaque
étape on doit calculer le pgcd de tous les coefficients, on peut imaginer le
temps que cela prendra en dimension 1 et à fortiori en dimension supérieure.
L'idéal serait de connaitre à l'avance une quantité suffisamment grande qui
divise tous les coefficients du reste.

C'est ici qu'intervient l'algorithme du sous-résultant: après chaque
pseudo-division euclidienne, on exhibe un coefficient "magique" qui divise les
coefficients du reste. Ce coefficient n'est pas le pgcd mais il est
suffisamment grand pour qu'on évite la croissance exponentielle des
coefficients.



{\bf{Algorithme du sous-résultant}}

Arguments: 2 polynômes $P$ et $Q$ primitifs. Valeur de retour: le pgcd de $P$
et $Q$.

Pour calculer le coefficient "magique" on utilise 2 variables auxiliaires $g$
et $h$ initialisées a 1.

Boucle à effectuer tant que $Q$ est non nul:
\begin{itemize}
  \item on note $\delta =$degre($P$)-degre($Q$) et $q$ le coefficient dominant
  de $Q$
  
  \item on effectue la division euclidienne (sans fraction) de $q^{\delta + 1}
  P$ par $Q$, soit $R$ le reste
  
  \item Si $R$ est constant, on sort de l'algorithme en renvoyant 1 comme pgcd
  
  \item on recopie $Q$ dans $P$ puis $R / ( g h^{\delta} )$ dans $Q$
  
  \item on recopie $q$ dans $g$ et $h^{1 - \delta} q^{\delta}$ dans $h$.
\end{itemize}
Si on sort normalement de la boucle, $Q$ est nul, on renvoie donc la partie
primitive de $P$ qui est le pgcd cherché.

Pour tester l'algorithme avec {\tt{xcas}}, il suffit de décommenter les
deux lignes {\tt{Q:=R/(g*h\^{ }d);}} et {\tt{g:=q; h:=q\^{ }d/h\^{
}(d-1);}} ci-dessus.

La preuve de l'algorithme est un peu longue et par ailleurs bien expliqu\'ee
dans le 2ème tome de Knuth (The Art of Computer Programming, Semi-numerical
Algorithms), on y renvoie donc le lecteur intéressé. L'idée générale
(et l'origine du nom de l'algorithme) 
est de considérer la matrice de Sylvester des polynômes de
départ $P$ et $Q$ (celle dont le déterminant est appelé résultant de $P$ et
$Q$) et de traduire les pseudo-divisions qui permettent de calculer les restes
successifs du sous-résultant en opération de ligne sur ces matrices. On
démontre alors que les coefficients de $R$ divisés par $g h^{\delta}$ peuvent
être interprétés comme des déterminants de sous-matrices de la matrice de
Sylvester après réduction et c'est cela qui permet de conclure qu'ils sont
entiers.

Par exemple, supposons que $P=R_0$, $Q=R_1$, $R_2$... diminuent de 1 en degr\'e
\`a chaque division 
(c'est le cas g\'en\'erique dans le d\'eroulement de l'algorithme
d'Euclide). Dans ce cas, $\delta=1$, il s'agit par exemple
de montrer que le reste $R_3$ de $Q=R_1$ par $R_2$ est divisible par le
carr\'e du coefficient dominant de $Q=R_1$.
Voyons comment on obtient les coefficients de $R_3$
\`a partir de la matrice de Sylvester de $P$ et $Q$. 
Prenons la sous-matrice constitu\'ee des 2 premi\`eres lignes de $P$
et des 3 premi\`eres lignes de $Q$ et r\'eduisons-la sous forme
\'echelonn\'ee sans introduire de d\'enominateur. 
\[
\left( \begin{array}{ccccc}
p_n & p_{n-1} & p_{n-2} & p_{n-3} & ... \\
0 & p_n & p_{n-1} & p_{n-2} &  ... \\
q_{n-1} & q_{n-2} & q_{n-3} & q_{n-4} & ... \\
0 & q_{n-1} & q_{n-2} & q_{n-3} & ... \\
0 & 0 & q_{n-1} & q_{n-2} &  ...  
\end{array} 
\right)
\]
On effectue $L_1 \leftarrow q_{n-1} L_1 - p_n L_3$
et $L_2 \leftarrow q_{n-1} L_2 - p_n L_4$, ce qui correspond \`a
l'\'elimination du terme en $x$ du quotient de $P$ par $Q$
\[
\left( \begin{array}{ccccc}
0 & q_{n-1} p_{n-1} - p_n q_{n-2}  & ... & ... & ... \\
0 & 0 & q_{n-1} p_{n-1} - p_n q_{n-2} & ... &  ... \\
q_{n-1} & q_{n-2} & q_{n-3} & q_{n-4} & ... \\
0 & q_{n-1} & q_{n-2} & q_{n-3} & ... \\
0 & 0 & q_{n-1} & q_{n-2} &  ...  
\end{array} 
\right)
\]
on effectue ensuite 
\begin{eqnarray*}
L_1 & \leftarrow &q_{n-1} L_1 - (q_{n-1} p_{n-1} - p_n q_{n-2})  L_4 \\
L_2 & \leftarrow & q_{n-1} L_2 - (q_{n-1} p_{n-1} - p_n q_{n-2})  L_5
\end{eqnarray*} 
ce qui correspond \`a l'\'elimination du terme constant du quotient
de $P$ par $Q$, on obtient
\[
\left( \begin{array}{ccccc}
0 & 0 & r_{2,n-2} & ... & ... \\
0 & 0 & 0 & r_{2,n-2} &  ... \\
q_{n-1} & q_{n-2} & q_{n-3} & q_{n-4} & ... \\
0 & q_{n-1} & q_{n-2} & q_{n-3} & ... \\
0 & 0 & q_{n-1} & q_{n-2} &  ...  
\end{array} 
\right)
\]
si on enl\`eve les lignes 3 et 4, et les colonnes 1 et 2,
on obtient (apr\`es \'echanges
de lignes) une sous-matrice de la matrice de Sylvester de $Q$ et $R_2$
\[
\left( \begin{array}{ccc}
 q_{n-1} & q_{n-2} &  ... \\
 r_{2,n-2} & ... & ... \\
 0 & r_{2,n-2} &  ... 
\end{array} 
\right)
\]
On recommence les op\'erations de r\'eduction de cette sous-matrice
correspondant \`a la division euclidienne de $Q$ par $R_2$, on obtient
\[
\left( \begin{array}{ccc}
 0 & 0 & r_{3,n-3} \\
 r_{2,n-2} & ... & ... \\
 0 & r_{2,n-2} &  ... 
\end{array} 
\right)
\]
puis apr\`es suppression des colonnes 1 et 2 et des lignes 2 et 3
la ligne des coefficients de $R_3$.

Supposons qu'on se limite d\`es le d\'ebut de la r\'eduction \`a ne
garder que les colonnes 1 \`a 4 et une 5-i\`eme colonne parmi
les suivantes, on obtient \`a la fin de la r\'eduction
une matrice 1,1 qui contient
un des coefficients de $R_3$ (selon le choix de la 5-i\`eme colonne).
Donc ce coefficient est \'egal au d\'eterminant de la matrice 1,1
qui est \'egal, au signe pr\`es, au d\'eterminant de la matrice 3,3
dont il est issu par notre r\'eduction (en effet, dans la 2i\`eme
partie de la r\'eduction,
on a multipli\'e deux fois $L_1$ par $r_{2,n-2}$, mais on doit ensuite diviser 
le d\'eterminant par $r_{2,n-2}^2$ pour \'eliminer les colonnes 1 et 2).
Quant au d\'eterminant de la matrice 3,3, il se d\'eduit du
d\'eterminant de la matrice 5,5 par multiplication par $q_{n-1}^4$
(2 lignes ont \'et\'e multipli\'ees 2 fois par $q_{n-1}$) et division
par $q_{n-1}^2$ (\'elimination des colonnes 1 et 2). Au final,
tout coefficient de $R_3$ est \'egal au produit d'un d\'eterminant
5,5 extrait de la matrice de Sylvester de $P$ et $Q$ par $q_{n-1}^2$,
qui est justement le coefficient ``magique'' par lequel on divise le reste
de $R_1=Q$ par $R_2$ lors de l'algorithme du sous-r\'esultant.

\subsection{Le pgcd en une variable}.

\subsubsection{Le pgcd heuristique.}

On suppose ici que les coefficients sont entiers ou entiers de Gauss.
{\bf{On peut donc se ramener au cas où les polynômes sont primitifs.}}

L'idée consiste à évaluer $P$ et $Q$ en un entier $z$ et à extraire des
informations du pgcd $g$ des entiers $P ( z )$ et $Q ( z )$. Il faut donc un
moyen de remonter de l'entier $g$ à un polynôme $G$ tel que $G ( z ) = g$. La
méthode consiste à écrire en base $z$ l'entier $g$, avec une particularité
dans les divisions euclidiennes successives on utilise le reste symétrique
(compris entre $- z / 2$ et $z / 2$). Cette écriture donne les coefficients
d'un polynôme $G$ unique. On extrait ensuite la partie primitive de ce
polynôme $G$. Lorsque $z$ est assez grand par rapport aux coefficients des
polynômes $P$ et $Q$, si $\mbox{pp} ( G )$ divise $P$ et $Q$, on va montrer
que le pgcd de $P$ et de $Q$ est $D = \mbox{pp} ( G )$.

On remarque tout d'abord que $d : = D ( z )$ divise $g$. En effet $D$ divise
$P$ et $Q$ donc pour tout entier (ou entier de Gauss) $z$, $D ( z )$ divise $P
( z )$ et $Q ( z )$. Il existe donc une constante $a$ telle que
\[ g = a d \]
On a aussi $\mbox{pp} ( G )$ divise $D$. Il existe donc un polynôme $C$ tel
que :
\[ D = \mbox{pp} ( G ) C \]
Nous devons prouver que $C$ est un polynôme constant. On suppose dans la suite
que ce n'est pas le cas. Evaluons l'égalité précédente au point $z$, on
obtient
\[ d = \frac{g}{c ( G )} C ( z ) \]
Finalement
\[ 1 = \frac{a}{c ( G )} C ( z ) \]
La procédure de construction de $G$ nous donne une majoration de ces
coefficients par $| z | / 2$, donc de $c ( G )$ par $| z | / 2$, donc $C ( z
)$ divise un entier de module plus petit que $| z | / 2$, donc
\[ | C ( z ) | \leqslant \frac{| z |}{2} \]
On considère maintenant les racines complexes $z_1, \ldots ., z_n$ du polynôme
$C$ (il en existe au moins une puisqu'on a supposé $C$ non constant). On a:
\[ C ( X ) = c_n ( X - z_1 ) \ldots . ( X - z_n ) \]
Donc, comme $c_n$ est un entier (ou entier de Gauss) non nul, sa norme est
supérieure ou égale à 1 et :
\[ | C ( z ) | \geqslant \prod^n_{j = 1} ( | z | - | z_j | ) \]
Il nous reste à majorer les racines de $C$ pour minorer $| C ( z ) |$. Comme
$C$ divise $D$ il divise $P$ et $Q$ donc les racines de $C$ sont des racines
communes à $P$ et $Q$. On va appliquer le:

\begin{lemma}
  Soit x une racine complexe d'un polynôme $P = a_n X^n + \ldots . + a_0$.
  
  Alors~
  \[ \text{$| x | < \frac{| P |}{| a_n |} + 1, | P | = \max_{0 \leqslant i
     \leqslant n} ( | a_i | )$} \]
\end{lemma}

Application du lemme à $C(X)$~: on a $1/|c_n|\leq 1$
donc si on a choisi $z$ tel que $| z | \geqslant 2 \min ( | P |, | Q | ) + 2$,
alors pour tout $j$, $| z_j | < | z | / 2$ donc
\[ | C ( z ) | > \left( \frac{| z |}{2} \right)^n \]
qui contredit notre majoration de $| C ( z ) |$.

\begin{thm}
  Soit $P$ et Q deux polynômes à coefficients entiers. On
  choisit un entier z tel que $| z | \geqslant 2 \min ( | P |, | Q | ) + 2$,
  si la partie primitive du polynôme $G$ reconstruit à partir du pgcd de $P (
  z ) \mbox{et}$Q(z) par écriture en base $z$ (avec comme reste euclidien le
  reste symétrique) divise $P$ et $Q$ alors c'est le pgcd de $P$ et $Q$.
\end{thm}

Pour finir la démonstration du théorème, il nous faut encore montrer le lemme.
On a
\[ - a_n x^n = a_{n - 1} x^{n - 1} + \ldots . + a_0 \]
Donc
\[ | a_n | | x |^n \leqslant | P | ( 1 + \ldots . + | x |^{n - 1} ) = | P |
   \frac{| x |^n - 1}{| x | - 1} \]
Ici on peut supposer que $| x | \geqslant 1$, sinon le lemme est démontré,
donc $| x | - 1$ est positif et
\[ | a_n | ( | x | - 1 ) \leqslant | P | \frac{| x |^n - 1}{| x |^n}
   \Rightarrow | x | - 1 < \frac{| P |}{| a_n |} \]
Remarques
\begin{itemize}
  \item Le théorème publié par Char, Geddes et Gonnet 
  porte sur des coefficients entiers et
  c'est comme cela qu'il est utilisé par les systèmes de calcul formel (en
  commençant historiquement par Maple). Peu de systèmes l'utilisent pour les
  polynômes à coefficients entiers de Gauss. On peut d'ailleurs généraliser le
  théorème à d'autres types de coefficients, à condition d'avoir un anneau
  euclidien plongé dans $\mathbb{C}$ avec une minoration sur la valeur absolue
  des élements non nuls de l'anneau.
  
  \item Nous n'avons jusqu'à présent aucune certitude qu'il existe des entiers
  $z$ tels que la partie primitive de $G$ divise $P$ et $Q$. Nous allons
  montrer en utilisant l'identité de Bézout que pour $z$ assez grand c'est
  toujours le cas. Plus précisément, on sait qu'il existe deux polynômes $U$
  et $V$ tels que
  \[ P U + Q V = D \]
  Attention toutefois, $U$ et $V$ sont à coefficients rationnels, pour avoir
  des coefficients entiers, on doit multiplier par une constante entière
  $\alpha$, donc en évaluant en $z$ on obtient l'existence d'une égalité à
  coefficients entiers
  \[ P ( z ) u + Q ( z ) v = \alpha D ( z ) \]
  
  
  Donc le pgcd $g$ de $P ( z )$ et $Q ( z )$ divise $\alpha D ( z ) = \alpha
  d$. Comme $g$ est un multiple de $d$, on en déduit que $g = \beta d$, où
  $\beta$ est un diviseur de $\alpha$. Si on a choisi $z$ tel que
  \[ | z | > \text{ $2 | D | | \alpha |$} \]
  alors $| z | > 2 | D | | \beta |$ donc l'écriture symétrique en base $z$ de
  $g$ est $G = \beta D$. Donc la partie primitive de $G$ est $D$, le
  pgcd de $P$ et $Q$.
  
  
\end{itemize}
\begin{example}
  Si $P_0 = 6 ( X^2 - 1 )$ et $Q_0 = 4 ( X^3 - 1 )$.
  
  Le contenu de $P_0$ est 6, celui de $Q_0$ est 4.\\
  On a donc pgcd des contenus = 2, $P = X^2 - 1, Q = X^3 - 1$. La valeur
  initiale de $z$ est donc $2 \ast 1 + 2 = 4$. On trouve $P ( 4 ) = 15, Q ( 4
  ) = 63$. Le pgcd entier de 15 et 63 est 3 que nous écrivons symétriquement
  en base 4 sous la forme $3 = 1 \ast 4 - 1$, donc $G = X - 1$, sa partie
  primitive est $X - 1$. On teste si $X - 1$ divise $P$ et $Q$, c'est le cas,
  donc c'est le pgcd de $P$ et $Q$ et le pgcd de $P_0$ et $Q_0$ est $2 ( X - 1
  )$.
\end{example}

{\bf Algorithme gcdheu}\\
En arguments deux polynômes $P_0$ et $Q_0$ à coefficients entiers ou entiers
de Gauss. Retourne le pgcd de 
$P_0$ et $Q_0$ ou faux en cas d'échec.
\begin{enumerate}
  \item Calculer le contenu de $P_0$ et $Q_0$. Vérifier que les coefficients
  sont entiers de Gauss sinon retourner faux.
  
  \item Extraire la partie primitive $P$ de $P_0$ et $Q$ de $Q_0$, calculer le
  pgcd $c$ des contenus de $P_0$ et $Q_0$
  
  \item Déterminer $z = 2 \min ( | P |, | Q | ) + 2$.
  
  \item Début de boucle: initialisation du nombre d'essais à 1, test d'arrêt
  sur un nombre maximal d'essais, avec changement de $z$ entre deux itérations
  (par exemple $z \leftarrow 2 z$).
  
  \item Calculer le pgcd $g$ de $P ( z )$ et $Q ( z )$ puis son écriture
  symétrique en base $z$ dont on extrait la partie primitive $G$.
  
  \item Si $G \mbox{ne} \mbox{divise} \mbox{pas}$$P$ passer à l'itération
  suivante. De même pour $Q$.
  
  \item Retourner $c G$
  
  \item Fin de la boucle
  
  \item Retourner faux.
\end{enumerate}
On remarque au passage qu'on a calculé le quotient de $P$ par $G$ et le
quotient de $Q$ par $G$ lorsque la procédure réussit. On peut donc passer à la
procédure gcdheu deux paramètres supplémentaires par référence, les deux
polynômes que l'on affectera en cas de succès, ce qui optimise la
simplification d'une fraction de 2 polynômes.

\subsubsection{Le pgcd modulaire}

On part du fait que si $D$ est le pgcd de $P$ et $Q$ dans $\mathbb{Z}$ (ou
$\mathbb{Z} [ i ] )$ alors après réduction modulo un nombre premier $n$ qui ne
divise pas les coefficients dominants de $P$ et $Q$, $D$ divise le pgcd $G$ de
$P$ et $Q$ dans $\mathbb{Z} / n \mathbb{Z}$ (par convention, le pgcd dans
$\mathbb{Z} / n \mathbb{Z}$ est normalisé pour que son coefficient dominant
vaille 1). Comme on calcule $G$ dans $\mathbb{Z} / n \mathbb{Z}$, les
coefficients des restes intermédiaires de l'algorithme d'Euclide sont bornés,
on évite ainsi la croissance exponentielle des coefficients. Il faudra ensuite
reconstruire $D$ à partir de $G$.

On remarque d'abord que si on trouve $G = 1,$ alors $P$ et $Q$ sont premiers
entre eux. En général, on peut seulement dire que le degré de $G$ est
supérieur ou égal au degré de $D$. En fait, le degré de $G$ est égal au degré
de $D$ lorsque les restes de l'algorithme d'Euclide (calculé en effectuant des
pseudo-divisions, cf. l'exercice 1) ont leur coefficient dominant non
divisible par $n$. Donc plus $n$ est grand, plus la probabilité est grande de
trouver $G$ du bon degré.

Dans la suite, nous allons déterminer une borne $b$ à priori majorant 
les coefficients de
$D$. On utilisera ensuite la même méthode que dans l'algorithme modulaire de
recherche de racines évidentes: on multiplie $G$ dans $\mathbb{Z} / n
\mathbb{Z}$ par le pgcd dans $\mathbb{Z}$ des coefficients dominants $p$ et
$q$ de $P$ et $Q$. Soit $\tilde{D} = \mbox{pgcd} ( p, q ) G$ le résultat écrit
en représentation symétrique. Si $n \geqslant b \mbox{pgcd} ( p, q )$ et si
$G$ est du bon degré, on montre de la même manière que $D = \tilde{D}$. Comme 
on ne connait pas le degré de $D$, on est obligé de tester si $\tilde{D}$ 
divise $P$
et $Q$. Si c'est le cas, alors $\tilde{D}$ divise $D$ donc $\tilde{D} = D$
puisque $\mbox{degre} ( \tilde{D} ) = \mbox{degre} ( G ) \geqslant
\mbox{degre} ( D )$. Sinon, $n$ est un nombre premier malchanceux pour ce
calcul de pgcd ($\mbox{degre} ( G ) \geqslant \mbox{degre} ( D )$), il faut
essayer un autre premier.

{\bf{Remarque:}} On serait tenté de dire que les coefficients de $D$
sont bornés par le plus grand coefficient de $P$. C'est malheureusement faux,
par exemple $( X + 1 )^2$ dont le plus grand coefficient est 2 divise $( X + 1
)^2 ( X - 1 )$ dont le plus grand coefficient (en valeur absolue) est 1.

Soit $P = \sum p_i X^i$ un polynôme à coefficients entiers. On utilise la
norme euclidienne
\begin{equation}
  | P |^2 = \sum | p_i |^2
\end{equation}
On établit d'abord une majoration du produit des racines de norme supérieure à
1 de $P$ à l'aide de $| P |^{}$. Ensuite si $D$ est un diviseur de $P$, le
coefficient dominant $d$ de $D$ divise le coefficient dominant $p$ de $P$ et 
les racines de $D$ sont aussi des racines de $P$. On pourra donc déterminer une
majoration des polynômes symétriques des racines de $D$ et donc des
coefficients de $D$.

\begin{lemma} \label{lemme:A}
  Soit $A = \sum_{j = 0}^a a_j X^j$ un polynôme et $\alpha \in \mathbb{C}$.
  Alors
  \[ \text{$| ( X - \alpha ) A | = | ( \overline{\alpha} X - 1 ) A |$} \]
\end{lemma}

Pour prouver le lemme \ref{lemme:A}, on développe les produits de polynômes. 
On pose $a_{-1} = a_{a + 1} = 0$ et on note $\Re$ la partie réelle.
\[ \text{$| ( X - \alpha ) A |^2 = \sum_{j = 0}^{a + 1}$} | a_{j - 1} - \alpha
   a_j |^2 = \sum_{j = 0}^{a + 1} | a_{j - 1} |^2 + | \alpha |^2 | a_j |^2 - 2
   \Re ( a_{j - 1} \overline{\alpha  a_j} ) \]
\[ \text{$| (  \overline{\alpha} X - 1 ) A |$}^2 = \sum_{j = 0}^{a + 1} | 
\overline{\alpha} a_{j - 1}
   - a_j |^2 = \sum_{j = 0}^{a + 1} | \alpha |^2 | a_{j - 1} |^2 + | a_j |^2 -
   2 \Re ( \overline{\alpha}  a_{j - 1}   \overline{a_j} ) \]
Les deux donnent bien le même résultat.

Soit $P ( X ) = p \prod ( X - \alpha_j )$ la factorisation de $P$ sur
$\mathbb{C}$. On introduit le polynôme
\[ \tilde{P} = p \prod_{j / | \alpha_j | \geqslant 1} ( X - \alpha_j )
   \prod_{j / | \alpha_j | < 1} (  \overline{\alpha_j} X - 1 ) \]
qui d'après le lemme a la même norme que $P$. La norme de $P$ majore donc le
coefficient constant de $\tilde{P} $ d'où:
\begin{equation}
  \label{mignotte} \text{$ \prod_{j / | \alpha_j | \geqslant 1} | \alpha_j |
  \leqslant \frac{| P |}{| p |}$}
\end{equation}
On remarque que (\ref{mignotte}) reste vraie si on considère les
racines $\delta_j$ de norme plus grande que 1 d'un diviseur $D$ de $P$ puisque
le produit porte alors sur un sous-ensemble. On écrit maintenant l'expression
des coefficients $d_j$ de $D$ à l'aide des racines $\delta_j$ de $D$:
\[ | d_{m - j} | = | d | \left| \sum_{\mbox{choix} \mbox{de} j \mbox{racines}
   \mbox{parmi} \mbox{les} m \mbox{racines} \mbox{de} D} \quad  \prod_{\delta_k \in
   \mbox{racines} \mbox{choisies}} \delta_k \right| \]
Pour majorer $| d_{m - j} |$, on commence par majorer $| \delta_k |$ par
$\beta_k = \max ( 1, | \delta_k | )$. On est donc ramené à majorer
\[ \sigma_{j, m} ( \beta ) = \sum_{\mbox{choix} \mbox{de} j \mbox{parmi} m
   \mbox{valeurs} \beta_k} \quad \prod_{\beta_k \in \mbox{choix}} \beta_k  \]
avec pour hypothèse une majoration de $M = \prod_{k = 1}^m \beta_k$ donnée par
la relation (\ref{mignotte}). Pour cela, on cherche le maximum de $\sigma_{j,
m} ( \beta )$ sous les contraintes $M$ fixé et $\beta_k \geqslant 1$.

On va montrer que le maximum ne peut être atteint que si l'un des $\beta_k =
M$ (et tous les autres $\beta_k = 1 )$. Sinon, quitte à réordonner supposons
que les $\beta_k$ sont classés par ordre croissant. On a donc $\beta_{m - 1}
\neq 1$, on pose $\widetilde{\beta_k} = \beta_k$ pour $k \leqslant m - 2$,
$\tilde{\beta}_{m - 1} = 1$ et $\tilde{\beta}_m = \beta_{m - 1} \beta_m$.
Comparons $\sigma_{j, m} ( \beta )$ et $\sigma_{j, \mbox{nm}} ( \tilde{\beta}
)$. Si le choix de $j$ parmi $m$ comporte $k = m - 1$ et $k = m$, le produit
est inchangé. Sinon on a la somme de deux produits, l'un contenant $k = m - 1$
et l'autre $k = m$. On compare donc $B ( \beta_{m - 1} + \beta_m )$ et $B ( 1
+ \beta_{m - 1} \beta_m )$ avec $B = \prod_{\beta_k \in \mbox{reste} \mbox{du}
\mbox{choix}} \beta_k$. Comme
\[ \text{$1 + \beta_{m - 1} \beta_m \geqslant \beta_{m - 1} + \beta_m$} \]
puisque la différence est le produit $(1-\beta_m)(1-\beta_{m-1})$ de deux
nombres positifs, on arrive à la contradiction souhaitée.

Ensuite on décompose les choix de $\sigma_{m, j}$ en ceux contenant $M$ et
des 1 et ceux ne contenant que des 1, d'où la majoration
\[ \sigma_{j, m} ( \beta ) \leqslant \left(\begin{array}{c}
     m - 1\\
     j - 1
   \end{array}\right) M + \left(\begin{array}{c}
     m - 1\\
     j
   \end{array}\right)  \]
et finalement
\begin{equation}
  | d_{m - j} | \leqslant | d | \left( \left(\begin{array}{c}
    m - 1\\
    j - 1
  \end{array}\right)  \frac{| P |}{| p |} + \left(\begin{array}{c}
    m - 1\\
    j
  \end{array}\right) \right) \label{pgcdd}
\end{equation}
On peut en déduire une majoration indépendante de $j$ sur les coefficients de
$D$, en majorant $| d |$ par $| p |$ (puisque $d$ divise $p$) et les
coefficients binomiaux par $2^{m - 1}$ (obtenue en développant $( 1 + 1 )^{m -
1}$). D'où le

\begin{thm}
  (Landau-Mignotte) Soit $P$ un polynôme à coefficients entiers (ou entiers de
  Gauss) et $D$ un diviseur de $P$ de degré $m$. Si $| P |$ désigne la norme
  euclidienne du vecteur des coefficients de $P$ et $p$ le coefficient
  dominant de $P$ alors les coefficients $d_j$ de $D$ satisfont l'inégalité
  \begin{equation}
    | d_j | \leqslant 2^{m - 1} ( | P | + | p | )
  \end{equation}
\end{thm}

Avec cette estimation, on en déduit que si $n$ est un premier plus grand que
\begin{equation}
  \text{$\min \left( 2^{\mbox{degre} ( P ) - 1} ( | P | + | p | ),
  2^{\mbox{degre} ( Q ) - 1} ( | Q | + | q | ) \right)$}, \label{pgcdbound}
\end{equation}
alors le pgcd trouvé dans $\mathbb{Z} / n \mathbb{Z}$ va se reconstruire en un
pgcd dans $\mathbb{Z}$ si son degré est le bon.

Malheureusement la borne précédente est souvent très grande par rapport aux
coefficients du pgcd et calculer dans $\mathbb{Z} / n \mathbb{Z}$ s'avèrera
encore inefficace (surtout si le pgcd est 1). Cela reste vrai même si on
optimise un peu la majoration (\ref{pgcdbound}) en repartant de (\ref{pgcdd}).

L'idée est donc de travailler modulo plusieurs nombres premiers plus petits et
reconstruire le pgcd des 2 polynômes à coefficients entiers à partir des pgcd
des polynômes dans $\text{$\mathbb{Z}$} / n \text{$\mathbb{Z}$}$ et du
théorème des restes chinois. En pratique on prend des nombres premiers
inférieurs à la racine carrée du plus grand entier hardware de la machine
(donc plus petits que $2^{16}$ sur une machine 32 bits) ce qui permet 
d'utiliser l'arithmétique hardware du processeur sans risque de débordement.

{\bf{Algorithme du PGCD modulaire en 1 variable:}}

En argument: 2 polynômes primitifs $P$ et $Q$ à coefficients entiers. Le
résultat renvoyé sera le polynôme pgcd.

Variable auxiliaire: un entier $N$ initialisé à 1 qui représente le produit
des nombres premiers utilisés jusqu'ici et un polynôme $H$ initialisé à 0 qui
représente le pgcd dans $\mathbb{Z} / N \mathbb{Z}$.

Boucle infinie :
\begin{enumerate}
  \item Chercher un nouveau nombre premier $n$ qui ne divise pas les
  coefficients dominants $p$ et $q$ de $P$ et $Q$
  
  \item Calculer le pgcd $G$ de $P$ et $Q$ dans $\mathbb{Z} / n \mathbb{Z}$.
  Si $G$=1, renvoyer 1.
  
  \item Si $H = 0$ ou si le degré de $G$ est plus petit que le degré
  de $H$, recopier $G$ dans $H$ et $n$ dans $N$, passer à la 6ème étape
  
  \item Si le degré de $G$ est plus grand que celui de $H$ passer à
  l'itération suivante
  
  \item Si le degré de $G$ est égal au degré de $H$, 
  en utilisant le théorème des restes chinois, calculer un polynôme
  $\tilde{H}$ tel que $\tilde{H} = H$ modulo $N$ et $\tilde{H} = G$ modulo
  $n$. Recopier $\tilde{H}$ dans $H$ et $n N$ dans $N$.
  
  \item Ecrire $\mbox{pgcd} ( p, q ) H$ en représentation symétrique. Soit
  $\tilde{H}$ le résultat rendu primitif. Tester si $\tilde{H}$ divise $P$ et
  $Q$. Si c'est le cas, renvoyer $\tilde{H}$, sinon passer à l'itération
  suivante.
\end{enumerate}
Finalement on n'a pas utilisé $b$, la borne de Landau-Mignotte. 
On peut penser que l'étape
6 ne devrait être effectuée que lorsque $N$ est plus grand que $\mbox{pgcd} (
p, q ) b$. En pratique, on effectue le test de l'étape 6 plus tôt parce que
les coefficients du pgcd sont rarement aussi grand que $b$. Mais pour éviter
de faire le test trop tôt, on introduit une variable auxiliaire $H'$ qui
contient la valeur de $H$ de l'itération précédente et on ne fait le test que
si $H' = H$ (ou bien sûr si on a dépassé la borne).

{\bf{Remarque}}:

L'algorithme ci-dessus fonctionne également pour des polynômes à plusieurs
variables.

{\bf{Exemple 1:}}

Calcul du pgcd de $( X + 1 )^3 ( X - 1 )^4$ et $( X^4 - 1 )^{}$. Prenons pour
commencer $n = 2$. On trouve comme pgcd $X^4 + 1$ (en effet $- 1 = 1$ donc on
cherchait le pgcd de $( X + 1 )^7$ et de $X^4 + 1 = ( X + 1 )^4$). On teste si
$X^4 + 1$ divise $P$ et $Q$, ce n'est pas le cas donc on passe au nombre
premier suivant. Pour $n = 3$, on trouve $X^2 - 1$. Donc $n = 2$ n'était pas un
bon nombre premier pour ce calcul de pgcd puisqu'on a trouvé un pgcd de degré
plus petit. On teste si $X^2 - 1$ divise $P$ et $Q$, c'est le cas ici donc on
peut arrêter, le pgcd cherché est $X^2-1$.

{\bf{Exemple} 2 :}

Calcul du pgcd de $( X + 1 )^3 ( X - 1 )^4$ et $( X^4 - 1 )^3$. 
Pour $n = 2$, on trouve un polynôme de degré 7.
Pour $n = 3$, on trouve $X^6 - 1$ donc $n = 2$ était une mauvaise réduction.
Comme $X^6 - 1$ ne divise pas $P$ et $Q$, on passe à $n = 5$. On trouve $X^6 +
2 X^4 - 2 X^2 - 1$. On applique le théorème des restes chinois qui va nous
donner un polynôme dans $\mathbb{Z} / 15 \mathbb{Z}$. On cherche donc un
entier congru à 2 modulo 5 et à 0 modulo 3, -3 est la solution (écrite en
représentation symétrique), donc le polynôme modulo 15 est $X^6 - 3 X^4 + 3
X^2 - 1 = ( X^2 - 1 )^3$. Ce polynôme divise $P$ et $Q$, c'est donc le pgcd de
$P$ et de $Q$.

\subsection{Le pgcd à plusieurs variables.}

\subsubsection{Le pgcd heuristique.}

On suppose comme dans le cas à une variable que les polynômes sont primitifs,
donc qu'on a simplifié les polynômes par le pgcd entier de leurs coefficients
entiers.

Le principe est identique à celui du PGCD à 1 variable, on évalue les deux
polynômes $P$ et $Q$ de $k$ variables $X_1, \ldots ., X_k$ en un $X_k = z$ et
on calcule le pgcd $g$ des 2 polynômes $P ( z )$ et $Q ( z )$ de $k - 1$
variables. On remonte ensuite à un polynôme $G$ par écriture symétrique en
base $z$ de $g$ et on teste si $\mbox{pp} ( G )$ divise $P$ et $Q$. Il s'agit
à nouveau de montrer que si $z$ est assez grand, alors $\mbox{pp} ( G )$ est
le pgcd cherché. On sait que $d = D ( z )$ divise $g$. Il existe donc un
polynôme $a$ de $k - 1$ variables tel que $g = a d$. On sait aussi que
$\mbox{pp} ( G )$ divise $D$, donc il existe un polynôme $C$ de $k$ variables
tel que $D = C \ast \mbox{pp} ( G ) .$ On évalue en $z$ et on obtient $d = C (
z ) g / c ( G )$, où $c ( G )$ est un entier, donc
\[ c ( G ) = a \ast C ( z ) \]
Comme $c ( G )$ est un entier, $a$ et $C ( z )$ sont des polynômes constants.
Comme précédemment, on a aussi $| C ( z ) | \leqslant | z | / 2$ puisque $| c
( G ) | \leqslant | z | / 2$.
\begin{itemize}
  \item Premier cas: si $C$ ne dépend que de la variable $X_k$. On continue le
  raisonnement comme dans le cas unidimensionnel.
  
  \item Deuxième cas: si $C$ dépend d'une autre variable, par exemple $X_1$.
  On regarde le coefficient de plus haut degre de $C$ par rapport a $X_1$. Ce
  coefficient divise le coefficient de plus haut degre de $P$ et de $Q$ par
  rapport a $X_1$. Comme $C ( z )$ est constant, on en deduit que le
  coefficient de plus haut degre de $P$ et $Q$ par rapport a $X_1$ est
  divisible par $X_k - z$ donc le coefficient de plus bas degre en $X_k$ de
  ces coefficients de plus haut degre est divisible par $z$, ce qui contredit
  la majoration de ce coefficient.
\end{itemize}


En pratique, cet algorithme nécessite le calcul récursif de pgcd sans
garantie de réussite. On l'évite donc s'il y a beaucoup de variables (la
limite est par exemple de 5 pour MuPAD).

\subsubsection{Le pgcd modulaire multivariables.}

Ici, on travaille modulo $X_n - \alpha_{}$, où $X_1, \ldots ., X_n$ désignent
les variables des polynômes. On considère donc deux polynômes $P$ et $Q$ comme
polynômes de la variables $X_n$ avec des coefficients dans $\mathbb{Z} [ X_1,
\ldots ., X_{n - 1} ]$. On évalue en $X_n = \alpha$, on obtient deux polynômes
en $n - 1$ variables dont on calcule le pgcd (récursivement).

Il s'agit de reconstruire le pgcd par interpolation. Tout d'abord, on a une 
borne évidente sur le degré du pgcd par rapport à la variable $X_n$, c'est le
minimum $\delta$ des degrés par rapport à $X_n$ des polynômes $P$ et $Q$. A
première vue, il suffit donc d'évaluer les polynômes
en $\delta + 1$ points $\alpha$.

Il faut toutefois prendre garde aux mauvaises évaluations et à la
normalisation des pgcd avant d'interpoler. En effet, si $D ( X_1, \ldots .,
X_n )$ désigne le pgcd de $P$ et $Q$ et $G ( X_1, \ldots ., X_{n - 1} )$ le
pgcd de $P ( X_1, \ldots ., X_{n - 1}, \alpha )$ et de $Q ( X_1, \ldots .,
X_{n - 1}, \alpha )$, 
on peut seulement dire $D ( X_1, \ldots ., X_{n - 1}, \alpha )$
divise $G$. Plusieurs cas sont donc possibles lorsqu'on évalue en un nouveau
point $\alpha$:
\begin{itemize}
  \item l'un des degrés de $G$ est plus petit que le degré du polynôme $D'$
  reconstruit par interpolation jusque là. Dans ce cas, toutes les évaluations
  qui ont conduit à reconstruire $D'$ étaient mauvaises. Il faut recommencer
  l'interpolation à zéro ou à partir de $G$ (si tous les degrés de $G$ sont
  inférieurs ou égaux aux degrés du $D'$ reconstruit).
  
  \item l'un des degrés de $G$ est plus grand que le degré du $D'$ reconstruit
  jusque là. Il faut alors ignorer $\alpha$.
  
  \item Tous les degrés de $G$ sont égaux aux degrés du $D'$ reconstruit
  jusque là. Dans ce cas, $G$ est un multiple entier du polynôme $D'$
  reconstruit jusque là et évalué en $X_n = \alpha$. Si on suppose qu'on a pu
  s'arranger pour que ce multiple soit 1, on ajoute le point $\alpha$ aux
  points d'évaluation précédents $\alpha_j$ en posant:
  \[ D' = D' + ( G - D' ) \frac{\prod_{\alpha_j} ( X_n - \alpha_j
     )}{\prod_{\alpha_j} ( \alpha - \alpha_j )} \]
\end{itemize}
On voit que les mauvaises évaluations se détectent simplement par les degrés.
Pour la normalisation, on utilise une petite astuce: au lieu de reconstruire
$\mbox{le} \mbox{pgcd} D$, on va reconstruire un multiple du pgcd $D$ (ce
multiple appartiendra à $\mathbb{Z} [ X_n ] )$. On voit maintenant $P$ et $Q$
comme des polynômes en $n - 1$ variables $X_1, \ldots ., X_{n - 1}$ à
coefficients dans $\mathbb{Z} [ X_n ]$. Alors lcoeff$(D)$, 
le coefficient dominant de $D$
(relativement à l'ordre lexicographique sur les variables $X_1,...,X_{n-1}$),
est un polynôme en $X_n$ qui divise le coefficient dominant de $P$ et de $Q$
donc divise le coefficient dominant du pgcd des coefficients dominants de $P$
et de $Q$. On va donc reconstruire le polynôme~:
\[ D' = D \frac{\Delta ( X_n )}{\mbox{lcoeff} ( D ) ( X_n )}, \Delta ( X_n ) =
   \mbox{pgcd} ( \mbox{lcoeff} ( P ) ( X_n ), \mbox{lcoeff} ( Q ) ( X_n )) \]
c'est-à-dire $D$ multiplié par un polynôme qui ne dépend que de $X_n$.

Revenons à $G$ en un point $\alpha$ de bonne évaluation. C'est un multiple
entier de $D ( X_1, \ldots ., X_{n - 1}, \alpha )$:
\[ G = \beta D ( X_1, \ldots ., X_{n - 1}, \alpha ) \]
Donc, comme polynômes de $X_1,...,X_{n-1}$ à coefficients dans 
$\mathbb{Z}[X_n]$ ou dans $\mathbb{Z}$,
$\mbox{lcoeff} ( G ) = \beta \mbox{lcoeff} ( D )_{| X_n = \alpha}$. Comme
$\mbox{lcoeff} ( D )$ divise $\Delta ( X_n )$, il en est de même en $X_n =
\alpha$ donc lcoeff$(G)$ divise $\beta \Delta(\alpha)$. 
On en déduit que $ \Delta ( \alpha) G$ qui 
est divisible par $ \Delta (\alpha) \beta$ est
divisible par $\mbox{lcoeff} ( G )$. On va donc considérer le polynôme
$ \Delta (\alpha) G  / \mbox{lcoeff} ( G )$ :
ses coefficients sont entiers et son coefficient dominant est  
$$\Delta ( \alpha) = \mbox{lcoeff}(D'( X_1, \ldots ., X_{n - 1}, \alpha ))$$
donc
\[ \Delta (\alpha) G  / \mbox{lcoeff} ( G )=
D'( X_1, \ldots ., X_{n - 1}, \alpha )\]

{\bf{Algorithme du pgcd modulaire à plusieurs variables (interpolation
dense)}}:

Arguments: 2 polynômes primitifs $P$ et $Q$ de $n$ variables $X_1, \ldots .,
X_n$ à coefficients entiers. Renvoie le pgcd de $P$ et $Q$.
\begin{enumerate}
  \item Si $n = 1$, renvoyer le pgcd de $P$ et $Q$ en une variable.
  
  \item Test rapide de pgcd trivial par rapport à $X_n$. On cherche des $n -
  1$-uplets $\alpha$ tels que $P ( \alpha, X_n )$ et $Q ( \alpha, X_n )$
  soient de même degré que $P$ et $Q$ par rapport à la variable $X_n$. On
  calcule le pgcd $G$ de ces 2 polynômes en une variable. Si le pgcd est
  constant, alors on retourne le pgcd des coefficients de $P$ et $Q$.
  
  \item On divise $P$ et $Q$ par leur contenu respectifs vu comme polynômes en
  $X_1, \ldots ., X_{n - 1}$ à coefficients dans $\mathbb{Z} [ X_n ]$, on note
  $C ( X_n )$ le pgcd des contenus. On calcule aussi le pgcd $\Delta ( X_n )$
  des coefficients dominants de $P$ et de $Q$.
  
  \item On initialise $D'$ le pgcd reconstruit à 0, $I ( X_n )$ le polynôme
  d'interpolation à 1, $\delta=(\delta_1,...,\delta_{n-1})$ 
  la liste des degrés partiels du pgcd par
  rapport à $X_1, \ldots ., X_{n - 1}$ au minimum des degrés partiels de $P$
  et $Q$ par rapport à $X_1, \ldots ., X_{n - 1}$, $e$ le nombre d'évaluation
  à 0 et $E$ l'ensemble des points d'interpolation à la liste vide.
  
  \item Boucle infinie:
  \begin{itemize}
    \item Faire $\alpha$=entier aléatoire n'appartenant pas à $E$ jusqu'à ce
    que
    \begin{eqnarray*}
      \text{degre($P ( X_1, \ldots ., X_{n - 1}, \alpha
      ))$=$\mbox{degre}_{X_n} ( P ( X_1, \ldots ., X_n )$} &  & \\
      \mbox{degre} ( Q ( X_1, \ldots ., X_{n - 1}, \alpha )) =
      \mbox{degre}_{X_n} ( Q ( X_1, \ldots ., X_n )) &  & 
    \end{eqnarray*}
    \item Calculer le pgcd $G ( X_1, \ldots ., X_{n - 1} )$ en $n - 1$
    variables de $P ( X_1, \ldots ., X_{n - 1}, \alpha )$ et $Q ( X_1, \ldots
    ., X_{n - 1}, \alpha )$.
    
    \item Si $\mbox{degre}_{} ( G )_i < \delta_i$ pour un indice au moins.
    Si $\mbox{degre} ( G ) \leqslant \delta$, on pose $\delta =
    \mbox{degre} ( G )$, $D' = G \frac{\Delta ( \alpha )}{\mbox{lcoeff} ( G
    )}$, $I = X_n - \alpha$, $e = 1$ et $E = [ \alpha ]$, sinon on pose $\delta
    = \min ( \delta, \mbox{degre} ( G )), D' = 0, I = 1, e = 0, E = [ ]$.
    On passe à l'itération suivante.

    \item Si $\mbox{degre} ( G ) > \delta$, on passe à l'itération suivante.
    
    \item Si $\mbox{degre} ( G ) = \delta$, on interpole:
    \begin{itemize}
      \item $G := G \frac{\Delta ( \alpha )}{\mbox{lcoeff} ( G )}$
      
      \item $D' := D' + \frac{I ( X_n )}{\prod_{\alpha_j \in E} ( \alpha -
      \alpha_j )} ( G - D' ( X_1, \ldots ., X_{n - 1}, \alpha ))$
      
      \item $I := I \ast ( X_n - \alpha )$
      
      \item $e := e + 1$ et ajouter $\alpha$ à $E$
      
      \item Si $e$ est strictement plus grand que le minimum des degrés
      partiels de $P$ et $Q$ par rapport à $X_n$, on pose $\tilde{D}$ la
      partie primitive de $D' $(vu comme polynôme à coefficients dans
      $\mathbb{Z} [ X_n ]$), on teste si $P$ et $Q$ sont divisibles par
      $\tilde{D}$, si c'est le cas, on renvoie $D = C ( X_n ) \tilde{D}$
    \end{itemize}
  \end{itemize}
\end{enumerate}
On observe que dans cet algorithme, on fait le test de divisibilite de
$\tilde{D}$ par $P$ et $Q$. En effet, même après avoir évalué en suffisamment
de points, rien n'indique que tous ces points sont des points de bonne
évaluation. En pratique cela reste extrêmement improbable. En pratique, on
teste la divisibilité plus tôt, dès que $D'$ n'est pas modifié par l'ajout
d'un nouveau point à la liste des $\alpha_j$.

Il existe une variation de cet algorithme, appelé SPMOD (sparse modular), qui
suppose que seuls les coefficients non nuls du pgcd en $n - 1$ variables sont
encore non nuls en $n$ variables (ce qui a de fortes chances d'être le cas).
L'étape d'interpolation est alors remplacée par la résolution d'un
sous-système d'un système de Vandermonde. Cette variation est intéressante si
le nombre de coefficients non nuls en $n - 1$ variables est petit devant le
degré. Si elle échoue, on revient à l'interpolation dense.

Notons enfin qu'on peut appliquer cette méthode lorsque les coefficients de
$P$ et $Q$ sont dans $\mathbb{Z} / n \mathbb{Z}$ mais il faut alors vérifier
qu'on dispose de suffisamment de points d'interpolation. Ce qui en combinant
avec l'algorithme modulaire à une variable donne un algorithme doublement
modulaire pour calculer le pgcd de 2 polynômes à coefficients entiers. C'est
cette méthode qu'utilise par exemple MuPAD (en essayant d'abord SPMOD puis
l'interpolation dense).

{\bf{Exemple:}}

Dans cet exemple, on donne $F$ et $G$ sous forme factorisée, le but étant de
faire comprendre l'algorithme. En utilisation normale, on n'exécuterait cet
algorithme que si $F$ et $G$ étaient développés.

$P = (( x + 1 ) y + x^2 + 1 ) ( y^2 + x y + 1 ), Q = (( x + 1 ) y +
x^2 + 1 ) ( y^2 - x y - 1 )$.

Prenons $x$ comme variable $X_1$ et $y$ comme variable $X_2$. Les coefficients
dominants de $P$ et $Q$ sont respectivement $y$ et $- y$ donc $\Delta = y$.

En $y = 0$, $P ( x, 0 ) = x^2 + 1$ n'est pas du bon degré.

En $y = 1$, $P ( x, 1 ) = ( x + x^2 + 2 ) ( x + 2 )$ et $Q ( x, 1 ) = ( x +
x^2 + 2 ) ( - x )$ sont du bon degré. Leur pgcd est $G = x^2 + x + 2$, $\Delta
( 1 ) = 1$, donc $D' = x^2 + x + 1$. On teste la divisibilité de $P$ par $D'$,
le teste échoue.

En $y = 2$, $P ( x, 2 ) = ( x^2 + 2 x + 3 ) ( 2 x + 5 )$ et $Q ( x, 2 ) = (
x^2 + 2 x + 3 ) ( - 2 x + 3 )$ donc $G = x^2 + 2 x + 3$, $\Delta ( 2 ) = 2$.
On interpole:
\[ D' = x^2 + x + 2 + \frac{y - 1}{2 - 1} ( 2 ( x^2 + 2 x + 3 ) - ( x^2 + x +
   2 )) = y ( x^2 + 3 x + 4 ) - ( 2 x + 2 ) \]
On teste la divisibilité de $P$ par $D'$, le test échoue.

En $y = 3$, $P ( x, 3 ) = ( x^2 + 3 x + 4 ) ( 3 x + 10 )$ et $Q ( x, 3 ) = (
x^2 + 3 x + 4 ) ( - 3 x + 8 )$ donc $G = x^2 + 3 x + 4$, $\Delta ( 3 ) = 3$.
On interpole:
\begin{eqnarray*}
  D' &= &y ( x^2 + 3 x + 4 ) - ( 2 x + 2 ) + \\
  & & \frac{( y - 2 ) ( y - 1 )}{( 3 - 2
  ) ( 3 - 1 )} \left( 3 ( x^2 + 3 x + 4 ) - ( 3 ( x^2 + 3 x + 4 ) - ( 2 x + 2
  )) \right)
\end{eqnarray*}
donc
\[ D' = y ( x^2 + 3 x + 4 ) - ( 2 x + 2 ) + \frac{( y - 2 ) ( y - 1 )}{2} ( -
   2 x - 2 ) = x^2 y + x y^2 + y^2 + y \]
On divise $D'$ par son contenu et on trouve $x^2 + x y + y + 1$ qui est bien
le pgcd de $P$ et $Q$.

\subsubsection{EZGCD.}

Il s'agit d'une méthode $p$-adique. On évalue toutes les variables sauf une,
on calcule le pgcd en une variable et on remonte au pgcd variable par variable
(EEZGCD) ou toutes les variables simultanément (EZGCD) par un lemme de Hensel.
Il semble qu'il est plus efficace de remonter les variables séparément.

Soit donc $F$ et $G$ deux polynômes primitifs dépendant des variables $X_1,
\ldots, X_n$ de pgcd $D$, on fixe une des variables qu'on appelera $X_1$ dans
la suite. Soient $\mbox{lcoeff} ( F )$ et $\mbox{lcoeff} ( G )$ les
coefficients dominants de $F$ et $G$ par rapport à $X_1$. On évalue $F$ et $G$
en un $n - 1$ uplet $b$ tel que le degré de $F$ et $G$ par rapport à $X_1$
soit conservé après evaluation en $b$. On suppose que $D_b ( X_1 ) =
\mbox{pgcd} ( F ( b ), G ( b ))$ a le même degré que $D ( b )$. On a donc
l'égalité:
\[ ( F \ast \mbox{lcoeff} ( F )) ( b ) = \left( D_b  \frac{\mbox{lcoeff} ( F (
   b ))}{\mbox{lcoeff} ( D_b )} \right) \ast \left( \frac{F ( b )}{D_b} 
   \frac{\mbox{lcoeff} ( F ) ( b )}{\mbox{lcoeff} ( \frac{F ( b )}{D_b} )}
   \right) \]
et de même en remplaçant $F$ par $G$.

Pour pouvoir lifter cette égalité (c'est-à-dire généraliser à plusieurs 
variables), il faut que $D_b$ et $\frac{F ( b )}{D_b}$
soient premiers entre eux. Sinon, on peut essayer de lifter l'égalité analogue
avec $G$. En général, on montre qu'il existe un entier $j$ tel que $D_b$ et
$\frac{F ( b ) + j G ( b )}{D_b}$ soient premiers entre eux. En effet, sinon
au moins un des facteurs irréductibles de $D_b$ va diviser $\frac{F ( b ) + j
G ( b )}{D_b}$ pour deux valeurs distinctes de $j$ et va donc diviser à la
fois $\frac{F ( b )}{D_b}$ et $\frac{G ( b )}{D_b}$ en contradiction avec la
définition de $D_b = \mbox{pgcd} ( F ( b ), G ( b ))$.  On lifte alors
l'égalité obtenue en remplaçant $F$ par $( F + k G )$ ci-dessus. Dans la
suite, on suppose qu'on peut prendre $j = 0$ pour alléger les notations.

On va aussi supposer que $b = 0$. Sinon, on fait un changement d'origine sur
les polynômes $F$ et $G$ pour que $b = 0$ convienne, on calcule le pgcd et on
lui applique la translation d'origine opposée.

On adopte ensuite la notation suivante: si $k$ est un entier, on dit qu'un
polynôme $P$ est un $O ( k )$ si la valuation de $P$ vu comme polynôme en
$X_2, \ldots ., X_n$ à coefficients dans $\mathbb{Z} [ X_1 ]$ est supérieure
ou égale à $k^{}$, ou de manière équivalente si
\[ P ( X_1, h X_2, \ldots ., h X_n ) = O_{h \rightarrow 0} ( h^k ) \]
L'égalité à lifter se réécrit donc:
\[ F \mbox{lcoeff} ( F ) = P_0 Q_0 + O ( 1 ) \] 
où $P_0 =$$D_b  \frac{\mbox{lcoeff} ( F ( b ))}{\mbox{lcoeff} ( D_b )}$ et
$Q_0 = \frac{F ( b )}{D_b}  \frac{\mbox{lcoeff} ( F ) ( b )}{\mbox{lcoeff} (
\frac{F ( b )}{D_b} )}$ sont premiers entre eux et de degré 0 par rapport aux
variables $X_2, \ldots ., X_n$. Cherchons $P_1 = O ( 1 )$ et $Q_1 = O ( 1 )$
de degré 1 par rapport aux variables $X_2, \ldots ., X_n$ tels que
\[ F \mbox{lcoeff} ( F ) = ( P_0 + P_1 ) ( Q_0 + Q_1 ) + O ( 2 ) \]
Il faut donc résoudre
\[ F \mbox{lcoeff} ( F ) - P_0 Q_0 = P_0 Q_1 + Q_0 P_1 + O ( 2 ) \]
On peut alors appliquer l'identité de Bézout qui permet de déterminer des
polynômes $P_1$ et $Q_1$ satisfaisant l'égalité ci-dessus (avec comme reste $O
( 2 )$ nul) puisque $P_0$ et $Q_0$ sont premiers entre eux. De plus, on
choisit $P_1$ et $Q_1$ tels que $\mbox{degre}_{X_1} P_1 \leqslant
\mbox{degre}_{X_1} ( F ) - \mbox{degre}_{} ( Q_0 ) = \mbox{degre} ( P_0 )$ et
$\mbox{degre}_{X_1} ( Q_1 ) \leqslant \mbox{degre} ( Q_0 )$ et
$\mbox{lcoeff}_{X_1} ( P_0 + P_1 ) + O ( 2 ) = \mbox{lcoeff}_{X_1} ( Q_0 + Q_1
) + O ( 2 ) = \mbox{lcoeff}_{X_1} ( F )$. On tronque ensuite $P_1$ et $Q_1$ en
ne conservant que les termes de degré 1 par rapport à $X_2, \ldots ., X_n$.

On trouve de la même manière par récurrence $P_k$ et $Q_k$ homogènes de degré
$k$ par rapport à $X_2, \ldots ., X_k$, de degré par rapport à $X_1$
respectivement inférieur aux degrés de $Q_0$ et de $P_0$ et tels que
\begin{equation}
  F \mbox{lcoeff} ( F ) = ( P_0 + \ldots . + P_k ) ( Q_0 + \ldots . + Q_k ) +
  O ( k + 1  ) \label{ezgcd}
\end{equation}
et $\mbox{lcoeff} ( F ) = \mbox{lcoeff}_{X_1} ( P_0 + \ldots . + P_k ) + O ( k
+ 1 ) = \mbox{lcoeff}_{X_1} ( Q_0 + \ldots . + Q_k ) + O ( k + 1 )$.

Si on est bien en un point de bonne évaluation et si $k$ est plus grand que le
degré total (par rapport aux variables $X_2, \ldots ., X_n$) du polynôme
 $F \mbox{lcoeff} ( F )$ on va vérifier que $P_0 + \ldots . + P_k = D
\frac{\mbox{lcoeff} ( F )}{\mbox{lcoeff} ( D )}$. En effet, si on a deux
suites de polynômes $P$ et $P'$ et $Q$ et $Q'$ satisfaisant (\ref{ezgcd}) avec
les même termes de degré zéro $P_0$ et $Q_0$, alors en prenant la différence,
on obtient:
\[ ( P_0 + P_1 \ldots  + P_k ) ( Q_0 + Q_1 \ldots  + Q_k ) = ( P_0 + P_1'
   \ldots  + P_k' ) ( Q_0 + Q_1' \ldots  + Q_k' ) + O ( k + 1 ) \]
On égale alors les termes homogènes de degré $j$, pour $j = 1$, on obtient
$P_0 ( Q_1 - Q_1' ) = Q_0 ( P_1 - P_1' )$, donc $Q_0$ divise $Q_1 - Q_1'$ qui
est de degré strictement inférieur au degré de $Q_0$ par rapport à $X_1$ (car
on a l'inégalité large et les termes de plus haut degré sont égaux),
donc $Q_1 = Q_1'$ et $P_1 = P_1'$. On montre de la même manière que $Q_j =
Q_j'$ et $P_j = P_j'$. L'écriture est donc unique, c'est donc l'écriture en
polynôme homogène de degré croissant de $D \frac{\mbox{lcoeff} ( F
)}{\mbox{lcoeff} ( D )}$ que l'on reconstruit.

Cet algorithme permet donc de reconstruire $D$, il suffit de tester à chaque
étape si $P_0 + \ldots . + P_k$ divise $F \mbox{lcoeff} ( F )$. On appelle
cette méthode de remontée lemme de Hensel linéaire. Il existe une variante
dite lemme de Hensel quadratique qui consiste à passer de $O ( k )$ à $O ( 2 k
)$. Elle nécessite toutefois un calcul supplémentaire, celui de l'identité de
Bézout à $O ( 2 k )$ près pour les polynômes $P_0 + \ldots . + P_{k - 1}$ et
$Q_0 + \ldots . + Q_{k - 1}$. Ce calcul se fait également par lifting.

{\bf{Algorithme EZGCD (Hensel linéaire)}}

Arguments: 2 polynômes $F$ et $G$ à coefficients entiers et primitifs. Renvoie
le pgcd de $F$ et $G$ ou false.
\begin{enumerate}
  \item Evaluer $F$ et $G$ en $( X_2, \ldots ., X_n ) = ( 0, \ldots ., 0 )$,
  vérifier que les coefficients dominants de $F$ et de $G$ ne s'annulent pas.
  Calculer le pgcd $D_b$ de $F ( 0 )$ et de $G ( 0 )$. Prendre un autre point
  d'évaluation au hasard qui n'annule pas les coefficients dominants de $F$ et
  de $G$ et vérifier que le pgcd a le même degré que $D_b$. Sinon, renvoyer
  false (on peut aussi faire une translation d'origine de $F$ et de $G$ en un
  autre point mais cela diminue l'efficacité de l'algorithme).
  
  \item On note $\mbox{lcF}$ et $\mbox{lcG}$ les coefficients dominants de $F$
  et de $G$ par rapport à $X_1$.
  
  \item Si $\mbox{degre} ( F ) \leqslant \mbox{degre} ( G )$ et $\mbox{degre}
  ( D_b ) = \mbox{degre} ( G )$ et $F$ divise $G$ renvoyer $F$
  
  \item Si $\mbox{degre} ( G ) < \mbox{degre} ( F )$ et $\mbox{degre} ( D_b )
  = \mbox{degre} ( F )$ et $G$ divise $F$ renvoyer $G$
  
  \item Si $\mbox{degre} ( F ) = \mbox{degre} ( D_b )$ ou si $\mbox{degre} ( G
  ) = \mbox{degre} ( D_b )$ renvoyer false
  
  \item Boucle infinie sur $j$ entier initialisé à 0, incrémenté de 1 à chaque
  itération: si $\mbox{pgcd} ( D_b, \frac{F ( 0 ) + j G ( 0 )}{D_b} ) = C$
  constant, alors arrêter la boucle
  
  \item Lifter l'égalité $( F + j G ) ( \mbox{lcF} + j \mbox{lcG} ) ( 0 ) =
  \left( D_b  \frac{( \mbox{lcF} + j \mbox{lcG} ) ( 0 )}{\mbox{lcoeff} ( D_{b
  )}} \right) \ast \ldots .$ par remontée de Hensel linéaire ou quadratique.
  Si le résultat est false, renvoyer false. Sinon renvoyer le premier polynôme
  du résultat divisé par son contenu vu comme polynôme en $X_1$ à coefficients
  dans $\mathbb{Z} [ X_2, \ldots ., X_n ]$.
\end{enumerate}
{\bf{Remontée de Hensel linéaire}}:

Arguments: $F$ un polynôme, $\mbox{lcF}$=lcoeff$(F)$ 
son coefficient dominant, $P_0$ un
facteur de $F ( 0 )$ ayant comme coefficient dominant $\mbox{lcF} ( 0 )$ et
dont le cofacteur $Q_0$ est premier avec $P_0$.

Renvoie deux polynômes $P$ et $Q$ tels que $F \mbox{lcF} = P Q$ et $P ( 0 ) =
P_0$ et $\mbox{lcoeff} ( P ) = \mbox{lcoeff} ( Q ) = \mbox{lcF}$.
\begin{enumerate}
  \item Soit $G = F \mbox{lcF}$, , $Q_0 = G ( 0 ) / P_0$, $P = P_0$, $Q =
  Q_0$.
  
  \item Déterminer les deux polynômes $U$ et $V$ de l'identité de Bézout
  (tels que $P_0 U + Q_0 V = d$ où $d$ est un entier).
  
  \item Boucle infinie avec un compteur $k$ initialisé à 1, incrémenté de 1 à
  chaque itération
  \begin{itemize}
    \item Si $k > \mbox{degre}_{X_2, \ldots ., X_n} ( G )$, renvoyer false.
    
    \item Si $P$ divise $G$, renvoyer $P$ et $G / P$.
    
    \item Soit $H = G - P Q = O ( k )$. Soit $u = U \frac{H}{d}$ et $v = V
    \frac{H}{d}$, on a $P_0 u + Q_0 v = H$
    
    \item Remplacer $v$ par le reste de la division euclidienne de $v$ par
    $P_0$ et $u$ par le reste de la division euclidienne de $u$ par $Q_0$. La
    somme des deux quotients est égale au quotient euclidien de $H$ par $P_0
    Q_0$, c'est-à-dire au coefficient dominant de $H$ divisé par le produit
    des coefficients dominants de $P_0$ et $Q_0$ (qui sont égaux) donc on a
    l'égalité:
    \[ P_0 u + Q_0 v = H - \frac{\mbox{lcoeff} ( H )}{\mbox{lcoeff} ( P_0
       )^2} P_0 Q_0 \]
    \item Soit
    $\alpha = ( \mbox{lcoeff} ( F ) - \mbox{lcoeff} ( P )) / \mbox{lcoeff} (
    P_0 )$ et $\beta = ( \mbox{lcoeff} ( F ) - \mbox{lcoeff} ( Q )) /
    \mbox{lcoeff} ( P_0 )$.
    On ajoute $\alpha P_0$ à $v$, ainsi $\mbox{lcoeff} ( P_{} + v ) =
    \mbox{lcoeff} ( F ) + O ( k + 1 )$ et $\beta Q_0$ à $u$, ainsi
    $\mbox{lcoeff} ( Q_{} + u ) = \mbox{lcoeff} ( F ) + O ( k + 1 )$ 
    
    Remarque: on montre alors que $\alpha + \beta = \frac{\mbox{lcoeff} ( H
    )}{\mbox{lcoeff} ( P_0 Q_0 )} + O ( k + 1 )$ donc $P_0 u + Q_0 v = H + O (
    k + 1 )$ en utilisant les propriétés :
    \[ \text{$\mbox{lcoeff} ( F ) = \mbox{lcoeff} ( P ) + O ( k ) =
       \mbox{lcoeff} ( Q ) + O ( k ) = \mbox{lcoeff} ( P_0 ) + O ( 1 )$} \]
    \item Réduire $u$ et $v$ en éliminant les termes de degré strictement
    supérieur à $k$ par rapport à $X_2, \ldots ., X_n$. S'il reste un
    coefficient non entier, renvoyer false
    
    \item Remplacer $P$ par $P + v$ et $Q$ par $Q + u$, passer à l'itération
    suivante.
  \end{itemize}
\end{enumerate}
{\bf{Exemple}}:

$F = (( x + 1 ) y + x^2 + 1 ) ( y^2 + x y + 1 ), G = (( x + 1 ) y + x^2 + 1 )
( y^2 - x y - 1 )$

On a $F ( 0, y ) = ( y + 1 ) ( y^2 + 1 )$ et $G ( 0, y ) = ( y + 1 ) ( y^2 - 1
)$, le pgcd est donc $D_b = ( y + 1 )$. On remarque que $D_b$ est premier avec
le cofacteur de $F$ mais pas avec le cofacteur de $G$. Si on évalue en un
autre point, par exemple $x = 1$, on trouve un pgcd $D_1$ de même degré, donc
0 est vraissemblablement un bon point d'évaluation (ici on en est sûr puisque
le pgcd de $F$ et $G$ se calcule à vue...). On a $\mbox{lcoeff} ( F ) = x +
1$, on va donc lifter $G = (( x + 1 ) y + x^2 + 1 ) ( y^2 + x y + 1 ) ( x + 1
) = P Q$ où $P_0 = ( y + 1 )$ et $Q_0 = ( y^2 + 1 )$.

On calcule les polynômes de l'identité de Bézout $U = ( 1 - y )$ et $V = 1$
avec $d = 2$, puis à l'ordre $k = 1$:
\[ H = G - P_0 Q_0 = ( 2 y^3 + 2 y^2 + 3 y + 1 ) x + O ( 2 ) \]
donc $u = \mbox{reste} ( U H / d, Q_0 ) = x y$ et $v = \mbox{reste} ( V H / d,
P_0 ) = - x$.

Donc $Q_1 = x y + \alpha Q_0$ avec $\alpha = ( x + 1 - 1 ) / \mbox{lcoeff} (
P_0 ) = x$ et $Q_0 + Q_1 = ( y^2 + 1 ) ( x + 1 ) + x y$. De
même, $P_1 = - x + \beta P_0$, avec $\beta = ( x + 1 - 1 ) / \mbox{lcoeff} (
P_0 ) = x$ donc $P_0 + P_1 = ( y + 1 ) ( x + 1 ) - x$. On remarque que $P_0 +
P_1$ et $Q_0 + Q_1$ sont bien à $O ( 2 )$ près les facteurs de $F
\mbox{lcoeff} ( F )$:
\[ P = ( x + 1 ) y + x^2 + 1 = P_0 + P_1 + O ( 2 ), \ Q = ( x +
   1 ) ( y^2 + x y + 1 ) = Q_0 + Q_1 + O ( 2 ) \]
Une deuxième itération est nécessaire. On calcule
\[ \text{$H = G - ( P_0 + P_1 ) ( Q_0 + Q_1 ) = ( 2 y^2 + y + 1 ) x^2 + O ( 3
   )$} \]
puis $\mbox{reste} ( U H / d, Q_0 ) = y x^2$ et $\mbox{reste} ( V H / d, P_0 )
= x^2$. Ici les coefficients $\alpha$ et $\beta$ sont nuls car $\mbox{lcoeff}
( F )$ n'a pas de partie homogène de degré 2. On trouve alors $P = P_0 + P_1 +
P_2$ et $Q = Q_0 + Q_1 + Q_2$. Pour calculer le pgcd, il suffit de calculer la
partie primitive de $P$ vu comme polynôme en $y$, ici c'est encore $P$ car le
contenu de $P$ est 1 (remarque: pour $Q$ le contenu est $x + 1$).\\
On trouve donc $P$ comme pgcd.

\subsection{Quel algorithme choisir?}

Il est toujours judicieux de faire une évaluation en quelques $n - 1$ uplets
pour traquer les pgcd triviaux. (E)EZGCD sera efficace si (0,...,0) est un
point de bonne évaluation et si le nombre de remontées nécessaires pour le
lemme de Hensel est petit donc pour les pgcd de petit degré, GCDMOD est aussi
efficace si le degré du pgcd est petit. Le sous-résultant est efficace pour
les pgcd de grand degré car il y a alors peu de divisions euclidiennes à
effectuer et les coefficients n'ont pas trop le temps de croitre. SPMOD est
intéressant pour les polynômes creux de pgcd non trivial creux. GCDHEU est
intéressant pour les problèmes relativement petits.

Avec des machines multiprocesseurs, on a probablement intérêt à lancer en
parallèle plusieurs algorithmes et à s'arrêter dès que l'un deux recontre le
succès.

\subsection{Pour en savoir plus.}
Parmi les références citées dans le premier article, ce sont les livres de
Knuth, H. Cohen, et Davenport-Siret-Tournier qui traitent des algorithmes de
pgcd. On peut bien sûr consulter le source de son système de calcul formel
lorsqu'il est disponible~:
\begin{itemize}
\item pour MuPAD sur un système Unix, depuis le
répertoire d'installation de MuPAD (en général {\tt /usr/local/MuPAD})
après avoir désarchivé le fichier {\tt lib.tar} du répertoire {\tt share/lib} 
par la commande \\{\tt cd share/lib \&\& tar xvf lib.tar}\\ 
on trouve les  algorithmes de calcul de PGCD dans le répertoire \\
{\tt share/lib/lib/POLYLIB/GCD}
\item Pour l'algorithme EZGCD, je me suis inspiré de l'implémentation de 
Singular (logiciel libre disponible à {\tt www.singular.uni-kl.de})
\end{itemize}
Sur le web on trouve quelques articles en lignes sur le
sujet en cherchant les mots clefs GCDHEU, EZGCD, SPMOD sur un moteur de 
recherche, il y a par exemple une description un peu différente du pgcd
heuristique sur:\\
{\tt www.inf.ethz.ch/personal/gonnet/CAII/HeuristicAlgorithms/node1.html}\\
et un article de comparaison de ces algorithmes 
par Fateman et Liao (dont la référence bibliographique est
Evaluation of the heuristic polynomial GCD.
in: ISSAC pages 240--247, 1995). Quelques autres références~:
\begin{itemize}
\item K.O.Geddes et al "Alg. for Computer Algebra", Kluwer 1992.
\item pour GCDHEU Char, Geddes, Gonnet, 
Gcdheu: Heuristic polynomial gcd algorithm based on integer gcd computation,
in: Journal of Symbolic Computation, 7:31--48, 1989.
\item pour SPMOD "Probabilistic Algorithms for Sparse Polynomials",
in: Symbolic \& Algebraic Comp. (Ed E.W.Ng), Springer 1979, pp216,
\end{itemize}


\section{Le résultant}
Il s'agit d'un point de vue d'algèbre linéaire sur le PGCD. Considérons
deux polynômes $A$ et $B$ de degrés $p$ et $q$ et de pgcd $D$ et 
l'identité de Bézout correspondante~:
\begin{equation} \label{eq:bezout}
 A U + B V =D
\end{equation}
avec degré$(U)<q$ et degré$(V)<p$.
Imaginons qu'on cherche $U$ et $V$ en oubliant qu'il s'agit d'une
identité de Bézout, en considérant simplement qu'il s'agit d'un
problème d'algèbre linéaire de $p+q$ équations (obtenues en développant
et en identifiant chaque puissance de $X$ de 0 à $p+q-1$) 
à $p+q$ inconnues (les $p$ coefficients de $V$ et les $q$ coefficients de $U$)
On sait que $A$ et $B$ sont premiers entre eux si et seulement si ce problème
d'algèbre linéaire a une solution pour $D=1$. Donc si le déterminant
du système est non nul, alors $A$ et $B$ sont premiers entre eux.
Réciproquement si $A$ et $B$ sont premiers entre eux, le système a
une solution unique non seulement avec comme second membre $1$ mais avec
n'importe quel polynôme de degré inférieur $p+q$, donc le
déterminant du système est non nul.

{\bf Définition:} \\
On appelle résultant de $A$ et $B$ le déterminant de ce système 
(\ref{eq:bezout}). Il s'annule si et seulement si $A$ et $B$
ne sont pas premiers entre eux (ont au moins une racine commune).
On appelle matrice de Sylvester la transposée de la matrice du système
(les inconnues étant par ordre décroissant les coefficients de $U$
et $V$)
\[ M(A,B)=\left( \begin{array}{cccccccc}
a_a   & a_{a-1} & \ldots & \ldots & a_0 & 0   & \ldots & 0 \\
0     & a_a     & \ldots & \ldots & a_1 & a_0 & \ldots & 0 \\
\vdots &        &        &      &     &  &      & \vdots \\
0     & 0       & \ldots &     &     &    &    & a_0 \\
b_b   & b_{b-1} & \ldots & b_0  & 0 &  0 & \ldots & 0 \\
\vdots &        &        &      &     &    &    & \vdots \\
0     &   0     & \ldots &    &      &     &   & b_0 
\end{array}
\right) \]
(cette matrice contient $b=$degré$(B)$ lignes de coefficients
du polynôme $A$ et $a=$degré$(A)$ lignes de coefficients du
polynôme $B$)

{\bf Lien avec l'algorithme du sous-résultant (calcul de PGCD)}\\
On peut calculer le déterminant avec la suite des restes de divisions
euclidiennes de la manière suivante, on part de la pseudo-division
de $A$ par $B$~:
\[ b_b^{a-b+1} A=BQ+R \]
on effectue alors sur chaque ligne contenant les coefficients de $A$
la manipulation de ligne correspondante, c'est-à-dire multiplier
la ligne par $b_b^{a-b+1}$ et soustraire ($q_0$ fois la ligne
de $B$ terminant dans la même colonne+$q_1$ fois la ligne
de $B$ terminant une colonne avant+...). Toutes les lignes
contenant les coefficients de $A$ ont été remplacées par des lignes 
contenant les coefficients de $R$. Ces lignes contiennent $k$ zéros initiaux
avec $k \geq 1$, ce qui permet de réduire le déterminant à celui
de la matrice de Sylvester de $R$ et $B$ (à un coefficient multiplicatif
près qui vaut $b_b^k$ par rapport au précédent donc
$b_b^{k-b(a-b+1)}$ par rapport au déterminant de départ). 
On échange ensuite $R$ et $B$ ce qui change
éventuellement le signe et on continue en faisant les
divisions euclidiennes de l'algorithme du sous-r\'esultant (cf.
Knuth o\`u on utilise la matrice de Sylvester pour prouver que
l'algorithme du sous-r\'esultant est correct). Rappelons que
le sous-résultant définit les suites $A_k$ ($A_0=A, A_1=B$),
$d_k$ le degré de $A_k$, $\delta_k=d_k-d_{k+1}$,
$g_k$ ($g_0=1$, si $k\neq 0$, $g_k$ coefficient dominant de $A_k$) 
$h_k$ ($h_0=1$, $h_{k+1}=h_k^{1-\delta_k} g_{k+1}^{\delta_k}$) et
\[ g_k^{\delta_{k-1}+1} A_{k-1} = A_k Q_{k+1} + 
g_{k-1} h_{k-1}^{\delta_{k-1}} A_{k+1} \]
\begin{thm}
Le résultant est égal au signe près au coefficient $h_k$ où $k$
correspond au reste $A_k$ constant (en supposant que le résultant
soit non nul).
\end{thm}

{\bf Preuve}\\
La transcription de l'égalité précédente sur les
résultants donne par la méthode ci-dessus~:
\begin{eqnarray*}
 g_k^{(\delta_{k-1}+1)d_k}\mbox{Res}(A_{k-1},A_k)
&=& 
g_k^{d_{k-1}-d_{k+1}} \mbox{Res}(g_{k-1} h_{k-1}^{\delta_{k-1}} A_{k+1},A_k)\\
&= &
g_k^{d_{k-1}-d_{k+1}} (g_{k-1} h_{k-1}^{\delta_{k-1}})^{d_k}
\mbox{Res}(A_{k+1},A_k)
 \end{eqnarray*}
On en déduit que~:
\[ \frac{\mbox{Res}(A_{k-1},A_k)}{g_{k-1}^{d_k} h_{k-1}^{d_{k-1}-1}}
= g_k^{d_{k-1}-d_{k+1}-(\delta_{k-1}+1)d_k}  
h_{k-1}^{\delta_{k-1}{d_k}+1-d_{k-1}} \mbox{Res}(A_{k+1},A_k) \]
On observe que~:
\[ h_{k-1}^{\delta_{k-1}{d_k}+1-d_{k-1}} =h_{k-1}^{(\delta_{k-1}-1)(d_k-1)}
= \left( h_{k-1}^{\delta_{k-1}-1}\right) ^{d_k-1}
= \left( \frac{g_k^{\delta_{k-1}}}{h_{k}} \right) ^ {d_k-1}\]
donc~:
\begin{eqnarray*}
 \frac{\mbox{Res}(A_{k-1},A_k)}{g_{k-1}^{d_k} h_{k-1}^{d_{k-1}-1}}
&=& g_k^{d_{k-1}-d_{k+1}-(\delta_{k-1}+1)d_k}  
\left( \frac{g_k^{\delta_{k-1}}}{h_{k}} \right) ^ {d_k-1} 
\mbox{Res}(A_{k+1},A_k) \\
&=& 
g_k^{d_{k-1}-d_{k+1}-d_k-\delta_{k-1}}  
\left( \frac{1}{h_{k}} \right) ^ {d_k-1} 
\mbox{Res}(A_{k+1},A_k) \\
&=& \frac{ \mbox{Res}(A_{k+1},A_k) } { g_k^{d_{k+1}} h_{k}^ {d_k-1}}
\end{eqnarray*}
Donc en valeur absolue
\[ |\frac{\mbox{Res}(A_{0},A_1)}{g_{0}^{d_1} h_{0}^{d_{0}-1}}|
= |\frac{\mbox{Res}(A_{k-1},A_k)}{g_{k-1}^{d_k} h_{k-1}^{d_{k-1}-1}} |\]
En prenant le rang $k$ tel que $A_{k}$ est constant, on a $d_k=0$
et le résultant est égal à $g_k^{d_{k-1}}$, on obtient donc~:
\[ |\mbox{Res}(A_{0},A_1)|=|\frac{g_k^{d_{k-1}}}{ h_{k-1}^{d_{k-1}-1}} |
\]
Comme ici $\delta_{k-1}=d_{k-1}$, le terme de droite est $|h_k|$.

{\bf Remarque}\\
On peut calculer au fur et à mesure le signe du résultant en tenant 
compte des degrés de $A_k$ pour inverser l'ordre de $A_{k-1}$ et
$A_k$ dans le résultant.

{\bf Utilisation}\\
La valeur du r\'esultant est tr\`es utile pour savoir si 2 polyn\^omes
d\'ependant de param\`etres sont premiers entre eux en fonction
de la valeur des param\`etres. En effet, la fonction {\tt gcd} d'un
logiciel de calcul formel calculera le PGCD par rapport \`a toutes
les variables en incluant les param\`etres. En cherchant quand le r\'esultant
s'annule en fonction des param\`etres on obtient un autre type
d'information.

{\bf Exemple~:}\\ 
Chercher quand le polyn\^one $P=x^3+px+q$ poss\`ede
une racine multiple en fonction de $p$ et $q$. On calcule le
r\'esultant de $P$ et $P'$ et on trouve $4p^3+27q^2$, donc $P$
a une racine multiple si et seulement si $4p^3+27q^2=0$.

{\bf Remarque~:}\\
On peut montrer que le r\'esultant de $P$ et $P'$ est divisible
par le coefficient dominant de $P$, on appelle le quotient discriminant.

\section{Les suites de Sturm}
L'algorithme du sous-r\'esultant appliqu\'e \`a un polyn\^ome sans
racine multiple $P$ et \`a sa d\'eriv\'ee
permet, \`a condition de changer les signes dans la suite des restes, 
de connaitre le nombre de racines r\'eelles d'un polyn\^ome dans un 
intervalle. Ceci est tr\`e utile pour par exemple simplifier des valeurs
absolues de polyn\^omes dans un intervalle.

On d\'efinit donc la suite de polyn\^omes $A_0=P, A_1=P', ..., A_k,0$
par~:
\begin{equation} \label{eq:sturm}
 A_{i} = A_{i+1} Q_{i+2} - A_{i+2} 
\end{equation}
avec $A_k$, le dernier reste non nul, un polyn\^ome constant puisque
$P$ n'a pas de racine multiple. On utilise plutot l'algorithme du 
sous-r\'esultant que l'algorithme d'Euclide, il faut alors
s'assurer que les signes de $A_i$ et $A_{i+2}$ sont oppos\'es lorsque
$A_{i+1} $ s'annule quitte \`a changer le signe de $A_{i+2}$ en fonction
du signe du coefficient dominant de $A_{i+1}$, de la parit\'e de
la diff\'erence des degr\'es et du signe du coefficient $gh^{1-\delta}$.

On d\'efinit $s(a)$ comme \'etant le nombre de changements de signes
de la suite $A_i(a)$ en ignorant les 0.
Alors le nombre de racines r\'eelles de $A_0=P$ sur l'intervalle
$]a,b]$ est \'egal \`a $s(a)-s(b)$.

{\bf Preuve}\\
On consid\'ere la suite des signes en un point~: elle ne peut contenir
deux 0 successifs (sinon toute la suite vaudrait 0 en ce point en appliquant
(\ref{eq:sturm}), or $A_k$ est constant non nul). Elle ne peut pas
non plus contenir +,0,+ ni -,0,- \`a cause de la convention de signe
sur les restes de (\ref{eq:sturm}). Donc une racine $b$
de $A_i$ pour $0<i<k$, n'influe pas sur la valeur de $s$ au voisinage
de $b$ (il y a toujours un changement de signe entre les positions
$i-1$ et $i+1$). Comme $A_k$ est constant, seules les racines de $A_0=P$
sont susceptibles de faire varier $s$. Comme $A_1=P'$, le sens de
variations de $A_0$ au voisinage d'une racine de $A_0$ est d\'etermin\'e
par le signe de $A_1$, donc les possibilit\'es sont -,+ vers +,+
ou +,- vers -,-, ce qui diminue $s$ d'une unit\'e.


\pagebreak

\section{Exercices (PGCD, r\'esultant, ...)}

\subsection{Instructions}
Les instructions arithm\'etiques sont en g\'en\'eral dans
la librairie standard. 
Elles sont dans les menus
Math->Integer et Alg->Polynomes/Arit.polynomiale de \verb|Xcas|.
Certaines de ces instructions
sont dans la librairie \verb|numtheory| (en maple) ou 
\verb|numlib| (en MuPAD)
(utilisez \verb|?numtheory| ou \verb|?numlib| pour avoir la liste 
des fonctions de ces librairies), 
pour \'eviter de taper \verb|numlib::| ou \verb|numtheory::|
\`a chaque fois, on peut lancer en maple la commande 
\verb|with(numtheory);| ou en MuPAD 
\verb|export(numlib);|.

\subsubsection{Entiers}
\begin{itemize}
\item \verb|chrem| (en MuPAD \verb|numlib::ichrem|)~:
restes chinois (entier)
\item \verb|divisors|
(en maple \verb|numtheory::divisors|, en MuPAD 
\verb|numlib::divisors|)~:
liste des diviseurs d'un entier
\item \verb|gcd, lcm|~: PGCD et PPCM
\item \verb|igcdex|: Bézout pour des entiers
\item \verb|iquo| et \verb|irem| quotient et reste de la division 
euclidienne de deux entiers
\item \verb|isprime| test de primalit\'e. En maple et MuPAD, il
s'agit d'un test de pseudo-primalit\'e. En Xcas, utiliser
\verb|is_pseudoprime| pour effectuer un test plus rapide
de pseudo-primalit\'e.
\item \verb|mods|: reste euclidien symétrique
\item \verb|nextprime| et \verb|prevprime| 
(en MuPAD \verb|numlib::prevprime|): nombre premier suivant 
ou pr\'ec\'edent
\item \verb|powmod(a,b,n)| (Xcas), \verb|a &^ b mod n| (Maple),
\verb|powermod(a,b,n)| (Mupad): calcul de $a^b \pmod n$ par
l'algorithme de la puissance rapide
\end{itemize}

\subsubsection{Polyn\^omes}
On peut repr\'esenter les polyn\^omes par leur \'ecriture symbolique
(par exemple \verb|x^2+1|), ou par des listes (repr\'esentation dense
ou creuse, r\'ecursive ou distribu\'ee). Xcas, Maple et MuPAD
acceptent la repr\'esentation symbolique. Xcas propose deux types
de repr\'esentation, dense \`a une variable (\verb|poly1[ ]|), ou
distribu\'ee (\verb|%%%{ }%%%|) et des instructions de conversion
(\verb|poly2symb| et \verb|symb2poly|) entre repr\'esentations.
MuPAD propose \'egalement une repr\'esentation non symbolique, cf.
la documentation \verb|?poly|. L'int\'er\^et d'une repr\'esentation
non symbolique est l'efficacit\'e des op\'erations polynomiales, (et la
possibilit\'e de chronom\'etrer des op\'erations comme le produit
de 2 polyn\^omes).

Les instructions qui suivent
utilisent la repr\'esentation symbolique, certaines acceptent
les autres repr\'esentations.
\begin{itemize}
\item \verb|coeff| coefficient(s) d'un polyn\^ome, 
\item \verb|coeffs| liste des coefficients d'un polyn\^ome
(\`a d\'evelopper auparavant, en mupad on utilise \verb|coeff|)
\item \verb|content| contenu (pgcd des coefficients)
\item \verb|degree| degré
\item \verb|divide| division euclidienne, 
\item \verb|gcd, lcm| PGCD et PPCM
\item \verb|gcdex| B\'ezout, 
\item \verb|genpoly| (en MuPAD \verb|numlib::genpoly|): 
crée un polynôme à partir de la
représentation $z$-adique d'un entier (utile pour le PGCD heuristique) 
\item \verb|icontent|: contenu entier pour un polyn\^ome \`a plusieurs
variables
\item \verb|indets|: 
liste des noms de variables d'une expression
\item \verb|lcoeff|: coefficient dominant d'un polyn\^ome
\item \verb|ldegree|: valuation
\item (MuPAD) \verb|multcoeffs| 
multiplie les coefficients d'un polynôme
\item (MuPAD) \verb|pdivide| pseudo-division
\item (MuPAD) \verb|poly(expr,[var],coeff)| crée un polynôme à partir de
l'expression symbolique \verb|expr| par rapport une variable ou
à une liste de variables \verb|var|, on peut indiquer dans quel anneau 
vivent les coefficients (par exemple dans $\Z/13\Z$ avec comme 3ème argument
\verb|IntMod(13)|)
\item \verb|primpart|: partie primitive d'un polyn\^ome
\item \verb|quo|, \verb|rem| (xcas et Maple) quotient et reste euclidien
(en MuPAD utiliser les options Quo et Rem de \verb|divide|)
\item \verb|tcoeff|: coefficient de plus bas degr\'e d'un polyn\^ome
\item \verb|interp| (MuPAD \verb|interpolate|)~: interpolation de Lagrange
\item \verb|convert(.,sqrfree)| 
(MuPAD \verb|polylib::sqrfree|)~:
d\'ecomposition en facteurs n'ayant pas de racine multiples
\item \verb|convert(.,parfrac)| 
(MuPAD \verb|polylib::partfrac|)~: d\'ecomposition en \'el\'ements simples
\item \verb|resultant| (MuPAD \verb|polylib::resultant|)~: 
calcule le r\'esultant de 2 polyn\^omes par rapport \`a une variable.
\end{itemize}

Notez aussi que le menu \verb|Exemples->poly->pgcd.xws| de Xcas contient 
des exemples de programmes de calcul de pgcd de type Euclide.

\subsubsection{Calculs modulo $n$}
Pour travailler dans $\Z/n\Z[X]$~:
\begin{itemize}
\item avec \verb|Xcas| on utilise la notation \% comme en C, par
exemple {\tt gcd(P \% 3, Q \% 3)}. On peut aussi utiliser la notation
Maple en mode ``syntaxe Maple'' (cf. ci-dessous)
\item avec Maple,
on utilise les formes inertes des instructions (qui renvoient l'instruction
non \'evalu\'ee), dont le nom est le m\^eme que le nom de commande
habituel mais pr\'ec\'ed\'e par une majuscule, puis on indique
\verb|mod n|, par exemple \verb|Gcd(P,Q) mod 11|.
\item avec MuPAD, on d\'esigne le type des coefficients par exemple par 
\verb|IntMod(13)| puis on construit des objets ayant des coefficients
de ce type (par exemple des polyn\^omes, cf. infra). Par exemple
\verb|poly(x^2+1,[x],IntMod(13))|. 
\end{itemize}

\subsection{Exercices PGCD}
\begin{enumerate}

\item Calculez le pgcd de $x^{202}+x^{101}+1$
et sa dérivée modulo 3 et modulo 5. Conclusion?

\item $P=51x^3-35x^2+39x-115$ et $Q=17x^4-23x^3+34x^2+39x-115$.
Calculez le pgcd de $P$ et $Q$ modulo 5, 7 et 11. En déduire
le pgcd de $P$ et $Q$ par le théorème des restes chinois. Pourquoi
ne doit-on pas essayer modulo 17?

\item \'Ecrire un programme qui d\'etermine le degr\'e probable
du pgcd de 2 polyn\^omes en une variable en utilisant le pgcd modulaire 
(on consid\`ere le degr\'e probable d\'etermin\'e lorsqu'on trouve
deux nombres premiers r\'ealisant le minimum des degr\'es trouv\'es)

\item Détaillez l'algorithme du PGCD heuristique pour les
polynômes  $P=(x+1)^7-(x-1)^6$ et sa dérivée. Comparez avec l'algorithme
d'Euclide naïf.

\item \'Ecrire un programme mettant en oeuvre le pgcd heuristique
pour des polyn\^omes \`a une variable.

\item On veut comprendre comment un logiciel de calcul formel calcule
\[ \int \frac{x^6+2}{(x^3+1)^2} \ dx \]
On se ramène d'abord à une fraction propre (num\'erateur $N$ de degr\'e 
inf\'erieur au d\'enominateur),
Soit $P=X^3+1$, calculez le PGCD de $P$ et $P'$, puis
deux polyn\^omes $U$ et $V$ tels que:
\[ N=UP+VP' \]
On d\'ecompose alors l'int\'egrale en deux morceaux~:\\
\[ \int \frac{N}{P^2}=\int \frac{U}{P}  + \int V \frac{P'}{P^2}  \]
Faites une int\'egration par parties sur le deuxi\`eme terme
et en d\'eduire la valeur de l'int\'egrale du d\'epart.

\item \'Ecrire un programme mettant en oeuvre l'algorithme modulaire
de calcul du PGCD.

\item \'Ecrire un programme qui d\'etermine le degr\'e probable du PGCD 
par rapport \`a toutes les
variables de 2 polyn\^ome \`a plusieurs variables
en utilisant l'\'evaluation en toutes les variables
sauf une.

\item Calculer le pgcd par une m\'ethode modulaire de
$(xy-x+1)(xy+x^2+1)$ et $(xy-x-y)(xy-x+1)$

\end{enumerate}


\subsection{Exercices (r\'esultant)}

\begin{enumerate}
\item Pour quelles valeurs de $p$ le polyn\^ome $X^5+X^3-pX+1$ admet-il
une racine multiple?
\item R\'esoudre le syst\`eme en \'eliminant successivement les
variables gr\^ace au r\'esultant~:
\[
\left\{\begin{array}{rcl}
a^{3}+b^{3}+c^{3} & = & 8 \\
a^{2}+b^{2}+c^{2} & = & 6 \\
a+b+2c & = & 4
\end{array}\right.
\]
\item Donner le d\'etail des calculs avec B\'ezout de la d\'ecomposition
en \'el\'ements simples de~:
\[ \frac{1}{(x^2-1)^2(x+2)}\]
puis calculer le coefficient de $x^n$ du d\'eveloppement en s\'eries
enti\`eres de cette fraction en 0.
\item Calculer 
\[ \int \frac{1-x^2}{1+x^4} \ dx \]
en utilisant le r\'esultant pour calculer les logarithmes.
\item En utilisant uniquement l'instruction de calcul de PGCD
d\'eterminer la multiplicit\'e maximale d'un facteur irr\'eductible
de 
$x^{14}-x^{13}-14x^{12}+12x^{11}+78x^{10}-54x^9-224x^8+116x^7+361x^6-129x^5-330x^4+72x^3+160x^2-16x-32$
\end{enumerate}

\subsection{Exercice (Bézout modulaire)}
Soit $A$ et $B$ deux polynômes à coefficients entiers et premiers
entre eux. Soit $c \in \Z^* $ le résultant de $A$ et $B$,
on va calculer les polynômes $U$ et $V$ de l'identité de Bézout 
\begin{equation} \label{eq:bezoutmod}
 A U + B V = c , \quad \mbox{deg}(U)<\mbox{deg}(B), \mbox{deg}(V)<\mbox{deg}(A)
\end{equation}
par une méthode modulaire.
\begin{enumerate}
\item Montrer, en utilisant les formules de Cramer,
que les coefficients de $U$ et $V$ sont des entiers de
valeur absolue inférieure ou égale à la borne de Hadamard $h$ de
la matrice de Sylvester de $A$ et $B$ (dont le déterminant est $c$,
le résultant de $A$ et $B$). Calculer $h$ en fonction
de la norme euclidienne de $A$, $B$ et de leurs degr\'es. 
\item On calcule $c \in \Z^*$ puis on
résoud (\ref{eq:bezoutmod}) dans $\Z/p_i Z[X]$ pour
plusieurs nombres premiers $p_i$ (choisis si possible inférieurs 
à $\sqrt{2^{31}}$ pour des raisons d'efficacité), puis on calcule par le
théorème des restes chinois (\ref{eq:bezoutmod}) 
dans $\Z/\prod p_i Z[X]$. Donner une minoration de 
$\prod_i p_i$ faisant intervenir $h$ qui permette de garantir
que l'écriture en représentation symétrique de (\ref{eq:bezoutmod})
dans $\Z/\prod p_i Z[X]$ est identique \`a (\ref{eq:bezoutmod}) dans $\Z[X]$.
\item Application~: résoudre de cette manière l'équation de
Bézout pour 
\[ A=(X+1)^4(X-3), \quad B=(X-1)^4(X+2)\] 
(vous pouvez utiliser
sans justifications l'instruction de calcul de r\'esultant,
des coefficients de Bézout dans $\Z/p_iZ[X]$ et 
de reste chinois de votre logiciel).
\item \'Ecrire une fonction mettant en oeuvre cet algorithme.
\item Que pensez-vous de l'intérêt de cet algorithme par rapport à
l'algorithme d'Euclide étendu dans $\Z[X]$?
\end{enumerate}


\subsection{Exercice (G\'eom\'etrie et r\'esultants).}
On cherche une relation alg\'ebrique entre les coordonn\'ees de 4 points
$A,B,C,D$ qui traduise le fait que ces 4 points sont cocycliques. Cette
condition \'etant invariante par translation, on cherche une
relation entre les 6 coordonn\'ees des 3 vecteurs $v_1=(x_1,y_1)$, 
$v_2=(x_2,y_2)$ et $v_3=(x_3,y_3)$ 
d'origine $A$ et d'extr\'emit\'e $B$, $C$ et $D$.
On peut supposer quitte \`a translater que le centre du cercle est
l'origine, on a donc 5 param\`etres~: le rayon du cercle $R$ et les
4 angles des points sur le cercle $\theta_0$, $\theta_1$, $\theta_2$ et
$\theta_3$. La relation cherch\'ee va s'obtenir en \'eliminant les
5 param\`etres des expressions des 6 coordonn\'ees en fonction de
ces param\`etres.
\begin{enumerate}
\item Exprimer les 6 coordonn\'ees en fonction de 
$R$ et $a=\tan(\theta_0/2)$, $b=\tan(\theta_1/2)$, $c=\tan(\theta_2/2)$
et $d=\tan(\theta_3/2)$. On obtient ainsi 6 \'equations, par exemple les
deux premi\`eres sont de la forme
\[ x_1- F(R,a,b)= 0, \quad y_1- G(R,a,b)= 0 \]
o\`u $F$ et $G$ sont deux fractions rationnelles.
\item En r\'eduisant au m\^eme d\'enominateur, calculer 6 
polyn\^omes, fonction de
$x_1,y_1,x_2,y_2,x_3,y_3,R,a,b,c,d$, qui doivent s'annuler
pour que les points soient cocycliques
(Vous pouvez utiliser l'instruction \verb|numer| pour obtenir le
num\'erateur d'une fraction rationnelle).
\item \'Eliminer $b$ des polyn\^omes
contenant $x_1$ et $y_1$ et factoriser
le polyn\^ome obtenu, faire de m\^eme avec $c$, $x_2$ et $y_2$
et $d$, $x_3$ et $y_3$, en d\'eduire (en supposant que les points sont
tous distincts) 3 polyn\^omes en $x_1,y_1,x_2,y_2,x_3,y_3,R,a$ qui
s'annulent.
\item \'Eliminer $R$ et $a$, en d\'eduire la relation cherch\'ee.
\item V\'erifier que cette relation est \'equivalente \`a la nullit\'e
de la partie imaginaire du birapport des affixes $\alpha, \beta, \gamma,
\delta$ des 4 points~:
\[ \Im \left( \frac{\alpha-\beta}{\alpha-\gamma}
\frac{\delta-\gamma}{\delta-\beta} \right) = 0\]
\end{enumerate}

\subsection{Décalage entier entre racines.}
Soit $P$ un polynôme à coefficients entiers sans racines multiples. 
On dira que $P$ a la propriété ${\mathcal I}$ si
deux des racines de $P$ sont d\'ecal\'ees d'un entier. 
En d'autres termes, si $r_1,...,r_n$ d\'esignent
les racines complexes distinctes de $P$, $P$ poss\`ede la
propri\'et\'e ${\mathcal I}$
s'il existe 
au moins un entier parmi les différences $r_i-r_j$ pour $i \neq j$. 
\begin{enumerate}
\item Soit
\[ R(t)=\mbox{resultant}_x(P(x),P(x+t)) \]
Montrer que $R$ est à coefficients entiers.
Montrer que la propriété ${\mathcal I}$ est équivalente à
la propriété ``$R$ possède une racine entière non nulle''.
On va maintenant construire un algorithme d\'eterminant les racines
enti\`eres du polyn\^ome $R$.
\item Apr\`es division de $R$ par une puissance de $t$, on peut
supposer que $R$ a un coefficient constant non nul. Apr\`es division de
$R$ par son contenu, on peut aussi supposer
que le contenu de $R$ est 1. En effectuant ensuite une factorisation
square-free de $R$, on peut se ramener au cas o\`u $R$ et $R'$ sont
premiers entre eux.
Soit $a$ une racine de $R$.
\begin{enumerate}
\item Donner une majoration de $|a|$ 
en fonction du coefficient constant de $R$.
\item Soit $p$ un nombre premier ne divisant pas le coefficient dominant
de $R$ et tel que $R$ et $R'$ soient premiers entre eux modulo $p$. 
On peut calculer $a$ à partir d'une racine
de $R$ modulo $p$ en la ``remontant'' modulo $p^k$ pour $k$
assez grand (algorithme p-adique). Pour quelle valeur de $k$ peut-on
reconstruire toutes les racines enti\`eres de $R$~? 
\item Comparer l'algorithme ci-dessus avec les algorithmes suivants~:
la factorisation de $R$ sur $\Z$, 
la recherche num\'erique des racines complexes de $R$,
la recherche des racines enti\`eres de $R$ parmi les diviseurs 
entiers du coefficient constant de $R$ et leurs oppos\'es.
\end{enumerate}
\item Une fois les racines entières de $R$ connues, comment
peut-on en déduire les facteurs de $P$ dont les racines diffèrent
de cet(ces) entier(s)?
\item Soit 
\[P(x)=x^6+9x^5+29x^4+41x^3+37 x^2+59x+31\]
Montrer que $P$ a la propriété ${\mathcal I}$. Calculer
la ou les racines entières de $R$ et donner la factorisation
correspondante de $P$. 
\item \'Ecrire un programme qui effectue cet algorithme sur un
polyn\^ome quelconque. On pourra utiliser la fonction 
\verb|rationalroot| de Xcas pour d\'eterminer les racines
enti\`eres de $R$.
\item Application~: on cherche \`a calculer
\begin{equation} \label{eq}
 \sum_{k=1}^n \frac{-9x^2-27x-30}{P(x)}
\end{equation}
D\'ecomposer cette fraction
en \'el\'ements simples (donner le d\'etail des calculs en utilisant
la factorisation pr\'ec\'edente et l'identit\'e de Bezout 
\verb|abcuv| en Xcas). 
\item Calculer la somme pr\'ec\'edente (\ref{eq}).
On pourra remarquer que pour $k$ entier strictement positif,
$\frac{1}{f(x+k)}-\frac{1}{f(x)}$
s'exprime comme une somme de diff\'erences  
$\frac{1}{f(x+j+1)}-\frac{1}{f(x+j)}$.
\item \'Ecrire un programme effectuant ce calcul avec une fraction
quelconque, lorsque cela est possible.
\end{enumerate}

\pagebreak

\section{Factorisation}

On présente ici quelques algorithmes utilisés pour factoriser un polynôme 
à coefficients entiers. 
Pour un polynôme en une variable,
cele se fait en plusieurs étapes~: on commence
par se ramener à un polynôme $P$ dont tous les facteurs sont de multiplicité
un, ensuite on factorise $P$ dans $\Z/p\Z$ (par la méthode de Berlekamp
ou Cantor-Zassenhauss), puis on remonte à $\Z/p^k Z$
pour $k$ suffisamment grand (en fonction de la borne de Landau sur les
facteurs de $P$), et on recombine enfin les facteurs modulaires pour
trouver les facteurs de $P$. Lorsque $P$ à plusieurs variables, on utilise
une méthode analogue à celle permettant de trouver le pgcd de polynômes
à plusieurs variables. 
%On présentera ensuite une méthode simple permettant
%de calculer la factorisation d'un polynôme à coefficients dans une
%extension algébrique de $\Z$ (par exemple $\Z[i]$).

{\bf Rappel}\\
Le pgcd des coefficients d'un polynôme est appelé contenu de ce polynôme.
Un polynôme est dit primitif si son contenu est égal à 1.

\subsection{Les facteurs multiples}
\'Etant donné un polynôme $P$ à coefficients entiers, on cherche à 
écrire~:
\[ P=\Pi_{k=1}^n P_k^k \]
où les $P_k$ n'ont pas de facteurs multiples et sont premiers entre
eux deux à deux. Comme on est en
caractéristique 0, cela revient à dire que pgcd$(P_k,P_k')=1$
et pgcd$(P_k,P_j)=1$. Bien entendu
on va utiliser la dérivée de $P$ dans l'algorithme de recherche des $P_k$~:
\[ P'=\sum_{k=1}^n kP_k' P_k^{k-1} \Pi_{j\neq k} P_j^j \]
Soit $G$ le pgcd de $P$ et de $P'$. On a~:
\[ G=\Pi_{k=1}^n P_k^{k-1}, \]
en effet $G$ divise $P$ et $P'$~:
\[ W_1=\frac{P}{G}=\Pi_{k=1}^n P_k, \quad 
Z_1=\frac{P'}{G}=\sum_{k=1}^n kP_k'\Pi_{j\neq k} P_j \]
il s'agit de vérifier que $W_1$ et $Z_1$ sont premiers entre eux. Soit $F$ un
facteur irréductible du pgcd de $W_1$ et $Z_1$, alors $F$ divise l'un des 
$P_k$,
appelons $P_l$ ce facteur. Comme $F$ divise $\Pi_{j\neq k} P_j$ si $k\neq l$,
on en déduit que $F$ divise le dernier terme de la somme de $Z_1$, c'est-à-dire
que $F$ divise $lP_l'\Pi_{j\neq l} P_j$ donc $F$ divise $P_l'$ puisque
les $P_k$ sont premiers entre eux. Donc $P_l$ et $P_l'$ ont un facteur
en commun, ce qui est contraire aux hypothèses.

On pose alors~:
\[ Y_1=Z_1-W_1'=\sum_{k>1} (k-1)P_k' \Pi_{j\neq k} P_j \]
On définit alors par récurrence des suites de polynômes $W_n$, $Y_n$ et
$G_m$ par~:
\begin{itemize}
\item $G_m=\mbox{pgcd}(W_m,Y_m)$
\item $W_{m+1}=W_m/G_m$ et $Y_{m+1}=Y_m/G_m-W_m'$
\end{itemize}
On va montrer que $P_m=G_m$. Commençons au rang $n=1$, on voit que $P_1$
divise $Y_1$ (puisqu'il est commun à tous les $\Pi_{j\neq k} P_j$ car
$k>1$) et divise $W_1$. Et c'est le seul facteur commun, car tout autre
facteur irréductible serait un diviseur d'un $P_l$ pour $l>1$, donc diviserait
$(l-1)P_l'\Pi_{j\neq l,j>1} P_j$, donc diviserait $P_l'$.
Le raisonnement en un rang quelconque est identique, les polynômes sont
donnés par~:
\[ G_m=P_m, \ W_{m}=\Pi_{k>=m} P_k, \ 
Y_{m}=\sum{k>m} (k-m)P_k'\Pi_{j\geq m, j\neq k} P_j \]

Lorsqu'on programme cet algorithme, le test d'arrêt est $G_m=1$.

{\bf Square-free factorisation (Algorithme de Yun)}\\
Argument: un polynôme primitif $P$ à coefficients entiers (ou dans $\Z[i]$
ou dans un corps de caractéristique nulle).\\
Valeur renvoyée: une liste de polynômes $P_m$ telle que 
$P=\Pi_{k=1}^n P_k^k$.\\
\begin{enumerate}
\item Initialiser la liste résultat à liste vide.
\item Initialiser $W$ à $P$ et $Y$ à $P'$. Calculer le pgcd $G$ de $W$ et $Y$
et simplifier $W$ et $Y$ par leur pgcd puis poser $Y=Y-W'$.
\item Boucle infinie.
\item Calculer le pgcd $G$ de $W$ et $Y$. Si $G=1$, on renvoie la liste
résultat sinon ajouter $G$ à la liste résultat.
\item Simplifier $W$ et $Y$ par $G$, puis poser $Y=Y-W'$ et passer à 
l'itération suivante.
\end{enumerate}

Remarque~: lorsqu'on veut factoriser un polynôme à coefficients modulaires,
il faut aussi se ramener à un polynôme sans facteurs multiples mais
on ne peut pas utiliser cet algorithme tel quel car la caractéristique
du corps n'est pas nulle.

{\bf Exemple}~:\\ 
Factorisation sans facteurs multiples de 
$P(X)=(X^3-1)(X+2)^2(X^2+3)^3$.
En mode interactif avec un logiciel de calcul formel, effectuons l'étape
d'initialisation~:
\begin{verbatim}
W:=normal((x^3-1)*(x+2)^2*(x^2+3)^3);
Y:=diff(W,x);
G:=gcd(W,Y);
        x^5+2*x^4+6*x^3+12*x^2+9*x+18
W:=normal(W/G); 
        x^6+2*x^5+3*x^4+5*x^3+-2*x^2+-3*x-6
Y:=normal(Y/G);
Y:=normal(Y-diff(W,x));
        5*x^5+8*x^4+3*x^3+-5*x^2+-8*x-3
\end{verbatim}
On vérifie bien que $W=(x+2)*(x^3-1)*(x^2+3)$ est le produit 
des facteurs $P_i$. On entame maintenant la boucle~:
\begin{verbatim}
G:=gcd(W,Y);
        x^3-1   -> P1
Y:=normal(Y/G);
W:=normal(W/G);
Y:=normal(Y-diff(W,x));
        2*x^2+4*x
G:=gcd(W,Y);
        x+2     -> P2
Y:=normal(Y/G);
W:=normal(W/G);
Y:=normal(Y-diff(W,x));
        0
G:=gcd(W,Y);
        x^2+3   ->  P3
\end{verbatim}
puis $W=1$ et $Y=0$ et le prochain $G$ vaut 1, on a bien trouvé tous
les facteurs $P_i$.

\subsection{Factorisation en une variable}
On suppose maintenant qu'on veut factoriser un polynôme $P$ sans facteur
multiple (et primitif). En général on commence par simplifier $P$ par
ses facteurs linéaires (détectés avec l'algorithme présenté dans le
premier article de cette série). On commence par chercher un nombre premier $p$
tel que $P$ dans $\Z/p\Z$ conserve le même degré et reste sans facteur 
multiple (donc pgcd$(P,P')$=1 dans $\Z/p\Z$), ce qui est toujours
possible (il suffit de prendre $p$ plus grand que le plus grand entier 
apparaissant dans l'algorithme du sous-résultant pour calculer
le pgcd de $P$ et $P'$ dans $\Z$).

{\bf Convention}\\
Tous les polynômes ayant leurs coefficients dans un corps fini sont
supposés avoir comme coefficient dominant 1 lorsque le choix
existe (par exemple les facteurs d'un polynôme modulo $p$).

\subsubsection{Factorisation dans $\Z/p\Z[X]$}
On suppose qu'on a un polynôme $P$ à coefficients dans $\Z/p\Z$ sans
facteur multiple. Il s'agit de factoriser $P$ dans $\Z/p\Z[X]$.
Il existe essentiellement deux stratégies, l'une commence par factoriser par
groupes de facteurs de même degré puis casse les facteurs et l'autre 
plus directe à base d'algèbre linéaire modulaire (méthode de Berlekamp). 
Dans les deux cas, on utilise le fait que si $F$ est un polynôme, 
alors les polynômes à coefficients dans $\Z/p\Z$
modulo $F$ forment un anneau $A$ qui est aussi un espace vectoriel 
sur $\Z/p\Z$ de dimension le degré de $F$ 
(si $F$ est irréductible, alors $A$ est un corps).
On s'intéresse alors aux propriétés de l'application 
$\varphi: x \in A \mapsto x^p$.
On observe d'abord que cette application est une application {\em linéaire\/}.
Cela découle du petit théorème de Fermat pour $\varphi(\lambda x)=\lambda
\varphi(x)$ et de la formule de Newton et de la primalité de $p$ pour
$\varphi(x+y)=\varphi(x)+\varphi(y)$.

{\bf Calcul de $\varphi$}\\
Pour mettre en oeuvre ces algorithmes, on commence par déterminer la matrice
de l'endomorphisme $\varphi: x \mapsto x^p$ dans $\Z/p\Z[X] \pmod {P(X)}$
muni de sa base canonique $\{ 1, X,...,X^{\mbox{deg}(P)-1} \}$.

\subsubsection{Distinct degree factorization}
Cette méthode consiste à détecter les groupes de facteurs
ayant un degré donné (distinct degree factorization). Si nécessaire, 
on utilise ensuite un autre algorithme pour casser ces groupes.
On utilise ici les propriétés des itérées de l'application linéaire 
$\varphi$ sur des espaces vectoriels de corps de base $\Z/p\Z$.
On va déterminer le produit $P_k$ de tous les facteurs de $P$ de degré $k$
en calculant le pgcd de $P$ et de $X^{(p^k)}-X$ dans $\Z/p\Z[X]$.

Pour $k=1$, $X^p-X$ est le produit des $X-k$ pour tout $k\in \Z/p\Z$
par le petit théorème de Fermat ($k^p=k \pmod p$), donc le pgcd
de $P$ et de $X^{(p^1)}-X$ dans $\Z/p\Z[X]$ est le produit des facteurs
de $P$ de degré 1.

Pour $k>1$, le raisonnement se généralise de la manière suivante~: on
considère un facteur irréductible $F(X)$ de $P$ de degré $k$ et le corps
$K=(\Z/p\Z)[Y] \pmod{F(Y)}$. Le corps $K$ est un corps fini, c'est
aussi un espace vectoriel sur $\Z/p\Z$ de dimension $k$, donc $K$ possède
$p^k$ éléments et $K^*$ est un groupe multiplicatif à $p^k-1$ éléments,
donc tout élément de $K^*$ vérifie l'équation $x^{p^k-1}=1$ donc
tout élément de $K$ vérifie $x^{(p^k)}=x$. En particulier pour 
$x=Y \pmod {F(Y)}$ 
on trouve que $Y^{(p^k)}=Y \pmod {F(Y)}$ donc $F(X)$ divise $X^{(p^k)}-X$
dans $\Z/p\Z$.

Réciproquement, si on se donne un facteur irréductible $F$ qui divise
$X^{p^k}-X$, soit $K$ le corps correspondant à $F$, 
alors le noyau de l'application linéaire
\[ x \in K \mapsto x^{p^k}-x \in K \]
est $K$ tout entier, car $Y=Y^{p^k} \pmod F$
entraine $(Y^2)^{(p^k)}=Y^{2 p^k}=(Y^{p^k})^2=Y^2 \pmod F$ et de même
pour les autres puissances de $Y$ qui, avec $Y^0=1$ également dans le
noyau, forment une base de l'espace vectoriel $K$ sur $\Z/p\Z$. Donc le
nombre d'éléments de $K$ est inférieur ou égal au degré du polynôme
$X^{p^k}-X$ (puisque $X^{(p^k)}-X$ est divisible par
$X-x$ pour tout $x\in K$),
donc le degré de $F$ est inférieur ou égal à $k$.

Donc $P_k$ est égal au pgcd de $P/\Pi_{j<k} P_j$ avec $X^{p^k}-X$.

{\bf Algorithme distinct degree factorization}\\
Argument: un polynôme $P$ à coefficients entiers 
sans facteur multiple et primitif.\\
Valeur renvoyée: la liste $L$ des produits des facteurs irréductibles et du
degré correspondant de $P$ (ordonné par ordre croissant de degré).\\
On commence par initialiser $L$ à vide et un polynôme auxiliaire $Q$ à $X$
(il contiendra les valeurs de $X^{p^k}-X \pmod P$), on fait une boucle
indéfinie sur $k$ commençant à 1 et incrémenté de 1 à chaque itération
\begin{itemize}
\item Si $k$ est strictement plus grand que le degré de $P$ divisé par 2,
on rajoute le couple ($P$,degre($P$)) à $L$ et on renvoie $L$
\item On remplace $Q$ par $Q^p \pmod P$ en utilisant le calcul de $\varphi$
modulo $P$
\item On calcule le pgcd $G$ de $Q-X$ et de $P$. 
\item Si $G$ vaut 1, on passe à l'itération suivante
\item On rajoute le couple ($G$,$k$) à la liste $L$ et on remplace $P$
par le quotient de $P$ par $G$.
\end{itemize}

{\bf Exemple}~:\\
Factorisation en degré distincts de $(X^3+X+1)(X^4-X+1)$ dans
$\Z/5\Z$. On regarde d'abord si $P$ reste sans facteur multiple après
réduction modulo 5.
\begin{verbatim}
P:=normal((x^3+x+1)*(x^4-x+1) mod 5);
gcd(P,diff(P,x));
    1 mod 5  -> ok P est sans facteur multiple
P1:=gcd(P,(x^5-x)mod 5);
    (1 mod 5)*x -2 mod 5  -> P1
P:=normal(P/P1);
P2:=gcd(P,(x^(5^2)-x)mod 5);
    1 mod 5  -> pas de facteur de degre 2
P3:=gcd(P,(x^(5^3)-x)mod 5);
    (x^6+2*x^5+x^2+x+2) mod 5
\end{verbatim}
Donc $P$ admet 3 facteurs dans $\Z/5\Z$: un de degré 1 ($x-2$) et
deux de degré 3 (dont le produit est $x^6+2x^5+x^2+x+2$).

Le même calcul dans $\Z/7\Z$ donne
\begin{verbatim}
P:=normal((x^3+x+1)*(x^4-x+1) mod 7);
gcd(P,diff(P,x));
    1 mod 7  -> ok P est sans facteur multiple
P1:=gcd(P,(x^7-x)mod 7);
    1 mod 7
P2:=gcd(P,(x^(7^2)-x)mod 7);
    1 mod 7
P3:=gcd(P,(x^(7^3)-x)mod 7);
    (x^3+x+1) mod 7
\end{verbatim}
donc $P$ possède un facteur de degré 3 modulo 7, donc le facteur restant
de degré 4 est forcément irréductible.

On remarque sur cet exemple que 7 est plus intéressant que 5, car
la factorisation modulo 7 donne moins de facteurs (à recombiner pour
trouver la factorisation dans $\Z$) et la factorisation est
complète modulo 7 alors que modulo 5 il faut casser le facteur de
degré 6 en deux facteurs de degré 3. La plupart des algorithmes
de factorisation effectuent la factorisation en degré distinct
modulo plusieurs entiers (ce qui peut de plus être parallélisé)
et choisissent le meilleur.

\subsubsection{La méthode de Cantor-Zassenhaus}

Cet algorithme sert à casser des groupes de facteurs de même degré,
c'est une méthode probabiliste. On suppose donc qu'on a un produit $P$
d'au moins deux facteurs irréductibles de degré $d$ à casser.
Soit $D$ l'un des polynômes irréductibles de degré $d$ à coefficients
dans $\Z/p\Z$, et soit $K=\Z/p\Z[Y] \pmod {D(Y)}$, on a~:
\[X^{p^d}-X=\Pi_{\alpha \in K }(X-\alpha) \]
puisque le corps $K$ possède $p^d$ éléments tous racines
de l'équation $X^{p^d}=X$.

On considère un polynôme $T$ non constant, et le polynôme
$T^{p^d}-T$. En remplaçant $X$ par $T$ ci-dessus, on en déduit~:
\[T^{p^d}-T=\Pi_{\alpha \in K }(T-\alpha) \]
Donc pour tout élément $\beta \in K=\Z/p\Z[Y] \pmod {D(Y)}$, on a
\[(T^{p^d}-T)(\beta)=\Pi_{\alpha \in K }(T(\beta)-\alpha)=0\]
Donc $T^{p^d}-T$ est divisible par $X^{p^d}-X$ (puisque toutes les racines
du second sont racines du premier), donc est divisible par tout polynôme
irréductible de degré inférieur ou égal à $d$ à coefficients dans $Z/p\Z$.
Comme
\begin{equation} \label{eq:cantor}
T^{p^d}-T=T(T^{\frac{p^d-1}{2}}-1)(T^{\frac{p^d+1}{2}}-1)
\end{equation}
et que ces trois facteurs sont premiers entre eux, on en déduit que tout 
polynôme irréductible de degré inférieur ou égal à $d$ à coefficients dans 
$Z/p\Z$ divise l'un des trois facteurs ci-dessus. Pour casser $P$, l'idée
consiste alors à calculer le pgcd de $P$ et $T^{\frac{p^d-1}{2}}-1$
pour un polynôme pris au hasard. On sait que $P$ divise le produit des
3 termes de (\ref{eq:cantor}), et on espère que les facteurs irréductibles
de $P$ ne diviseront pas tous le même terme.

On va montrer que si $T$ est un polynôme de degré $\leq 2d-1$ choisi au hasard,
la probabilité que deux facteurs irréductibles de $P$ ne divisent pas 
$T^{p^d}-T$ est proche de 0.5. Soient donc $A$ et $B$ deux facteurs
irréductibles de $P$ de degré $d$. D'après l'identité de Bézout, tout 
polynôme $T$ de degré $\leq 2d-1$ s'écrit de manière unique sous la forme~:
\begin{equation} \label{eq:bezout2} 
T = A U + B V 
\end{equation}
avec degre($U \leq d-1$) et degre($V \leq d-1$) et réciproquement 
une combinaison linéaire de cette forme est un polynôme de degré $\leq 2d-1$.
Choisir $T$ au hasard revient donc à choisir un couple $(U,V)$ de polynômes
à coefficients dans $\Z/p\Z$ au hasard et
de manière indépendante. D'autre part, $A$ et $B$ étant de degré $d$, on
sait que dans $K=\Z/p\Z[Y] \pmod{D(Y)}$ ces polynômes admettent $d$ racines.
Soit donc $\alpha$ [respectivement $\beta$] une racine de $A$ [resp. $B$]
dans $K$. Alors $A$ divise $T^{\frac{p^d-1}{2}}-1$
si et seulement si $T(\alpha )^{\frac{p^d-1}{2}}=1$ (et de même pour
$B$ et $\beta$) car $T^{\frac{p^d-1}{2}}-1$ a ses coefficients dans
$\Z/p\Z$ (et non dans $K$). 
En appliquant (\ref{eq:bezout2}), $A$ divise $T^{\frac{p^d-1}{2}}-1$
si et seulement si~:
\[ B(\alpha )^{\frac{p^d-1}{2}}V(\alpha )^{\frac{p^d-1}{2}}=1 \]
Le premier terme de cette égalité est une constante égale à 1 ou -1, 
le second a une probabilité proche de 0.5 (égale à $\frac{p^d-1}{2p^d}$)
de valoir 1 ou -1 car, comme $A$ est irréductible,
$V(\alpha)$ décrit $K$ lorsque $V$ décrit les 
polynômes de degré $\leq d-1$.
De même, $B$ a une probabilité proche de 0.5 de diviser 
$T^{\frac{p^d-1}{2}}-1$, et ces 2 probabilités sont indépendantes
puisque $U$ et $V$ le sont, donc la probabilité que soit $A$ soit $B$ divise
divise $T^{\frac{p^d-1}{2}}-1$ est proche de 0.5.

{\bf Algorithme de Cantor-Zassenhaus}\\
Argument: Un polynôme $P$ à coefficients dans $\Z/p\Z$ de degré $k$
dont tous les facteurs irréductibles sont de degré $d$.\\
Valeur renvoyée: la liste des facteurs irréductibles de $P$.\\
\begin{itemize}
\item Si $k=d$ renvoyer une liste contenant $P$.
\item Déterminer un polynôme $T$ aléatoire de degré inférieur ou égal
à $2d-1$ et de coefficient dominant 1. Calculer le pgcd $D$ de $P$
et de $T^{(p^d-1)/2}-1$. Si le degré de $T$ est égal à 0 ou à $k$ 
recommencer cette étape.
\item Appeler récursivement cet algorithme avec $T$ et $P/T$ et
renvoyer la liste réunion des deux listes renvoyées.
\end{itemize}

{\bf Exemple}~:\\ 
Cassons le polynôme de degré 6 obtenu dans l'exemple précédent
(modulo 5). Donc $P:=(x^6+2*x^5+x^2+x+2) \pmod 5$ et $d=3$, $2d-1=5$,
$(p^{d}-1)/2=62$.
On choisit au hasard un polynôme de degré inférieur ou égal à 5, par exemple
$T=x^4-x^3+x+1$, puis on calcule $T^{62}$ modulo $P$ ce qui donne
$(x^5+x^3+x^2+1) \pmod 5$ puis le pgcd de $T^{62}-1$ et de $P$
qui vaut $x^3+x+1 \pmod 5$, on a donc cassé $P$ en deux. 
En prenant $T:=x^4-x^3+x+2$, on trouve $T^{62}=1 \pmod P$, donc
ce $T$ n'aurait pas permis de casser $P$.

\subsubsection{La méthode de Berlekamp}
Cette méthode permet de factoriser un polynôme sans facteurs multiples,
elle peut aussi servir à casser des groupes de facteurs de même degré.
Ici on travaille dans l'anneau des polynômes à coefficients dans $\Z/p\Z$
modulo le polynôme $P$ et on s'intéresse au noyau de $\varphi-Id$
(où $\varphi: x \mapsto x^p$). On
suppose que $P=\Pi_{j=1}^n F_j$ où les $F_j$ sont irréductibles et
premiers entre eux. On va montrer que le noyau de $\varphi-Id$ est
composé des polynômes $Q$ tels que $Q \pmod {F_j}$ est constant
(dans $\Z/p\Z$) pour tout $j$.

Si $Q \pmod {F_j}=s_j \in \Z/p\Z$, alors $Q^p \pmod {F_j}=s_j^p=s_j$, donc
par le théorème des restes chinois, $Q=Q^p \pmod P$. 

Réciproquement, si
$Q^p-Q=0 \pmod P$, en utilisant la factorisation~:
\[ X^p-X= \Pi_{j \in \Z/p\Z } (X-j)\]
on en tire $P$ divise $Q^p-Q=\Pi_{j \in \Z/p\Z } (Q(X)-j)$,
donc $F_j$ divise l'un des facteurs et $Q(X) \pmod {F_j} \in \Z/p\Z$.
Le noyau de $\varphi -Id$
est donc un espace vectoriel de dimension $n$, le nombre
de facteurs irréductibles de $P$ et possède donc $p^n$ éléments
(en effet pour tout $n$ uplet de $s_j$, on peut construire un polynôme
$Q$ du noyau par le théorème des restes chinois en posant $Q\pmod {F_j}=s_j$).

L'intérêt du noyau de $\varphi-Id$ est qu'on peut le calculer sans connaitre
les $F_j$. Une fois ce calcul fait, voyons comment on peut remonter 
aux $F_j$. On connait déjà la dimension du noyau donc le nombre de facteurs
irréductibles. De plus, on remarque que le polynome constant est un
élément du noyau qu'on appellera $T_1$, on note alors $T_2,...,T_n$ les
autres polynômes du noyau. Ensuite, on calcule le pgcd de $P$ avec $T_2-jT_1$
pour $j\in \Z/p\Z$. On sait que $T_2=s_{2,j} \pmod {F_j}$, donc ce pgcd
est égal au produit des facteurs $F_j$ tels que $s_{2,j}=jT_1$. L'un au moins
des pgcd calculés est non trivial car sinon $T_2=T_1 \pmod{F_j}$ pour
tout $j$ donc $T_2=T_1$. Si on a de la chance tous les $s_{2,j}$ seront
distincts et les pgcd non triviaux de $P$ avec $T_2-jT_1$ donneront les $F_k$.
Sinon il faudra continuer avec $T_3-jT_1$ etc.

{\bf Exemple}~:\\
Revenons sur la factorisation de $P:=(x^6+2x^5+x^2+x+2) \pmod 5$.
Commençons par calculer la matrice de $\varphi$ dans la base
$\{ 1,x,x^2,...,x^5\}$. On a évidemment $\varphi(1)=1$ et
$\varphi(x)=x^5$, puis $\varphi(x^2)=x^{10}=x^5+x^4-2x^3+x \pmod P$,
puis en multipliant par $x^5$ et en divisant par $P$,
$\varphi(x^3)=-x^4+2x^3$, de la même manière on obtient 
$\varphi(x^4)=-x^5+2x^4+x^3-x^2-2$ et $\varphi(x^5)=x^3+x^2-x$.
La matrice de $\varphi$ est donc~:
\[ M=\left( 
\begin{array}{cccccc}
1& 0& 0 &0 &-2&0\\
0& 0& 1 &0 &0 &-1\\
0& 0& 0 &0 &-1&1\\
0& 0& -2&2 & 1&1\\
0& 0& 1 &-1& 2&0\\
0& 1& 1 &0 &-1&0\\
\end{array}
\right)\]
On calcule ensuite le noyau de $\varphi-Id$ (comme matrice à coefficients
dans $\Z/5\Z$), on obtient une
base du noyau en prenant par exemple les vecteurs $(-1,0,0,0,0,0)$
et $(0,0,-1,-1,0,-1)$. Donc le polynôme $P$ possède 2 facteurs dans
$\Z/5\Z[X]$. Pour déterminer les facteurs, on calcule le pgcd de $P$
avec le polynôme $T_2-s$ où $T_2=-x^5-x^3-x^2$ correspond au 2ème
vecteur de la base du noyau. On obtient pour $s=0$ un pcgd non trivial
($x^3+x+1$), ce qui permet de calculer les 2 facteurs. Si on avait
essayé d'autres valeurs de $s$, pour $s=1$ on obtient comme pgcd 1, pour
$s=2$ on trouve le 2ème facteur $x^3+2x^2-x+2$.

\subsubsection{Remontée (Hensel)}
Il s'agit de passer d'une factorisation de $P$ dans $\Z/p\Z[X]$ à une
factorisation de $P$ dans $\Z/p^k Z[X]$, la méthode est analogue à celle
de l'algorithme EZGCD de calcul de pgcd de polynômes.

On suppose donc que
\[ P=\Pi_{j=1}^n P_j \pmod p \]
où les $P_j$ sont premiers entre eux deux à deux dans $\Z/p\Z$.
Il s'agit de trouver des polynômes $P_{j,k}=P_j \pmod p$ tels que
\[ P=\Pi_{j=1}^n P_{j,k} \pmod {p^k} \]
Commençons par le cas $k=2$. On pose
\[ P_{j,2}=P_j+pQ_j=P_j \pmod p \]
On a alors~:
\begin{eqnarray*}
 P&=&\Pi_{j=1}^n P_{j,2} \pmod {p^2} =\Pi_{j=1}^n (P_j+pQ_j) \pmod {p^2}\\
&=&\Pi_{j=1}^n P_j + p \sum_{j=1}^n Q_j \Pi_{k\neq j} P_k \pmod {p^2} 
\end{eqnarray*}
Donc~:
\[ \sum_{j=1}^n Q_j \Pi_{k\neq j} P_k= \frac{P-\Pi_{j=1}^n P_j}{p} \pmod p \]
On est ramené à résoudre une identité de Bézout généralisée.
On montrera dans l'appendice le~:
\begin{thm} (Identité de Bézout généralisée)
Soit $P_1$, ..., $P_n$ ($n\geq 2$) des polynômes premiers entre eux deux 
à deux modulo $p$. Alors pour tout polynôme $Q$, il existe des polynômes 
$Q_1$, ..., $Q_n$ tels que~:
\[ \sum_{j=1}^n Q_j \Pi_{k\neq j} P_k=Q \pmod p \]
\end{thm}


On a donc réussi à remonter l'égalité $P=\Pi P_j \pmod p$ à 
$P=\Pi P_{j,2} \pmod {p^2}$. Le passage de $P=\Pi P_{j,l} \pmod {p^l}$
à $P=\Pi P_{j,l+1} \pmod {p^{l+1}}$ est identique, on a~:
\[ P_{j,l+1}=P_{j,l}+p^{l}Q_j \]
où les $Q_j$ sont les solutions de l'identité de Bézout généralisée avec~:
\[ Q=\frac{P-\Pi_{j=1}^n P_{j,l}}{p^l}\]

Lorsqu'on programme cet algorithme (cf. l'appendice), 
on calcule une fois pour toutes les
solutions de l'identité de Bézout pour $Q=1$, et on multiplie par $Q$.

{\bf Algorithme de remontée de Hensel linéaire}\\
Arguments: Un polynôme $P$ à coefficients entiers, la liste $L=\{ P_j \}$ 
de ses facteurs dans $\Z/p\Z[X]$\\
Valeur renvoyée: la liste des facteurs de $P$ dans $\Z/p^l \Z[X]$\\
On calcule la borne de Landau-Mignotte\footnote{Rappelons qu'il s'agit d'une
majoration sur la valeur absolue des coefficients des facteurs de $P$} 
pour les facteurs de $P$, on multiplie
par le coefficient dominant de $P$ et on calcule $l$ tel que $p^l$ est
strictement plus grand que deux fois cette quantité. On calcule
aussi les polynômes $Q_j$ de l'identité de Bézout généralisée pour $Q=1$\\
Puis on fait une boucle pour $k$ variant de 2 à $l$:
\begin{itemize}
\item On détermine $P-\Pi_j P_j \pmod {p^{k}}$, on divise par $p^{k-1}$
et on place le résultat dans $Q$
\item On multiplie les polynômes $Q_j$ de l'identité de Bézout 
généralisée (correspondants au polynôme 1) par $Q$
et on détermine le reste de la division euclidienne de $Q Q_j$ par $P_j$,
on multiplie par $p^{k-1}$ et on ajoute le résultat à $P_j$.
\end{itemize}

Il existe une version quadratique de cette méthode. On passe alors de
$P=\Pi P_{j,l} \pmod {p^l}$ à $P=\Pi P_{j,2l} \pmod {p^{2l}}$. Pour
cela, il faut trouver les polynômes $Q_j$ solutions de l'équation~:
\[ \sum_{j=1}^n Q_j \Pi_{k\neq j} P_{k,l}=Q \pmod {p^l}\]
Pour $l=1$, c'est l'identité de Bézout généralisée, mais ce n'est plus le
cas pour $l>1$. En fait, on résout cette égalité en remontant l'identité
de Bézout quadratiquement, plus précisément pour trouver les $S_j$
solutions de
\[ \sum_{j=1}^n S_j \Pi_{k\neq j} P_{k,2l}=Q \pmod {p^{2l}}\]
on pose $S_j=Q_j+p^l R_j$, il s'agit donc de trouver les $R_j$ solutions de
\[ \sum_{j=1}^n (Q_j+p^l R_j) \Pi_{k\neq j} P_{k,2l}=Q \pmod {p^{2l}}\]
soit~:
\[ \sum_{j=1}^n R_j \Pi_{k\neq j} P_{k,l}
=\frac{Q-\sum_{j=1}^n Q_j \Pi_{k\neq j} P_{k,l} }{p^l} \pmod {p^l}\]
on en déduit les $R_j$.

{\bf Algorithme de remontée de Hensel quadratique}\\
Arguments et valeur renvoyée identiques à l'algorithme de remontée de Hensel
linéaire ci-dessus.\\
On commence comme dans le cas linéaire par calculer les coefficients
de l'identité de Bézout généralisée pour $Q=1$ et la valeur de $l$ telle
que $p^{2^l}$ soit supérieur à deux fois la borne de Landau des facteurs
de $P$ fois le coefficient dominant de $P$.\\
On fait une boucle sur $k$ variant de 1 à $l$:
\begin{itemize}
\item On calcule $P-\Pi_j P_j \pmod {p^{2^k}}$, on divise par $p^{2^{k-1}}$
et on place le résultat dans $Q$
\item On multiplie par $Q$ les polynômes $Q_j$ de l'identité de Bézout
généralisée (avec comme second membre le polynôme 1),
on calcule le reste euclidien du résultat par $P_j$ (modulo $p^{2^{k-1}}$), 
on multiplie par $p^{2^{k-1}}$ et on ajoute à $P_j$ (avec les notations
précédentes, on passe ainsi des $P_{j,2^{k-1}}$ aux $P_{j,2^k}$)
\item Si $k=l$ on renvoie la liste des $P_j$
\item On calcule $1-\sum_j Q_j \Pi_{k\neq j} P_k \pmod {p^{2^k}}$, on
divise par $p^{2^{k-1}}$ et on place le résultat dans $Q$
\item On multiplie par $Q$ les polynômes $Q_j$ de l'identité de Bézout,
généralisée et on calcule le reste euclidien du résultat par 
$P_j$ (modulo $p^{2^{k-1}}$), on multiplie par $p^{2^{k-1}}$ et 
on ajoute à $Q_j$ (ce qui ajuste les polynômes $Q_j$ qui vérifient
maintenant l'identité de Bézout modulo $p^{2^k}$)
\end{itemize}

{\bf Remarque}\\
Pendant l'étape de remontée de Hensel, une optimisation classique
consiste à tester la divisibilité dans $\Z$ du polynôme $P$ par le 
facteur lifté $P_j$ (\footnote{Plus exactement, on multiplie $P_j$ par le
coefficient dominant de $P$ modulo $p^l$})
lorsqu'il n'a pas subi de modification pendant 2 étapes successives
(autrement dit lorsque $P_j \pmod {p^l}=P_j \pmod {p^{l+1}}$ (ou
$\pmod {p^{2l}}$ pour le lift quadratique). Si la division
est exacte, on obtient un facteur irréductible de $P$ dans $\Z$.
On recalcule alors la borne de Landau de $P/P_j$ pour diminuer
le nombre d'itérations à effectuer dans cette étape.

{\bf Exemple}~:\\ 
Reprenons le polynôme $P(X)=(X^3+X+1)(X^4-X+1)$
et supposons qu'on ait choisi de le factoriser modulo 5 puis 
de remonter. On a 3 facteurs
$a=x-2$, $b=x^3+x+1$ et $c=x^3+2x^2-x+2$. Si on développe $P$, on trouve 6
coefficients non nuls de valeur absolue 1, 
on peut calculer la borne de Landau-Mignotte correspondante
sur les coefficients d'un facteur entier~: $2^{5} (\sqrt(6)+1)$
soit un peu plus de 110, il suffit donc d'effectuer 3 étapes de
remontée linéaire ($5^4=625>111/2$).
On commence par trouver 3 polynômes $A$, $B$, $C$ tels que
\begin{eqnarray*}
A(x^3+x+1)(x^3+2x^2-x+2)+B(x-2)(x^3+2x^2-x+2)+& & \\
+C(x-2)(x^3+x+1)&=&1 \pmod 5
\end{eqnarray*}
On commence par résoudre $D(x^3+2x^2-x+2)+C(x-2)(x^3+x+1)=1\pmod 5$,
on trouve $C=2x^2-2$ et $D=-2x^3-2x^2+2x+1$. Puis on calcule
$A$ et $B$ en résolvant $E(x^3+x+1)+F(x-2)=1$ qui donne $E=1$ et 
$F=-x^2-2x$ qu'on multiplie par $D$, donc $A=D$ et $B=2x^5+x^4+2x^3-2x$.
Ce qui donne l'identité de Bézout généralisée.

Passons aux calculs de remontée. On a $abc=x^7-4x^5+5x^4+-9x^3-x^2-4$
et $P=x^7+x^5+x^3-x^2+1$, donc $Q=(P-abc)/5=x^5-x^4+2x^3+1$. On pose
alors 
\begin{eqnarray*} 
a_1&=&a+5 \ (QA \pmod a)\pmod{25}, \\
b_1&=&b+5 \ (QB \pmod b) \pmod{25}, \\
c_1&=&c+5 \ (QC \pmod c) \pmod{25} 
\end{eqnarray*}
donc~:
\[ a_1= a+5 \times (-2), \quad b_1=b+5 \times 0, 
\quad c_1=c+5 \times (2x^2-x) \]
En principe, on continue encore 2 itérations de la même manière.
La 2ème itération donne~: 
\[ Q=(P-a_1 b_1 c_1)/25= 6x^5-3x^4+7x^3+3x^2-2x+1\] 
\begin{eqnarray*} 
a_2&=&a_1+25 \ (QA \pmod a) \pmod{125}, \\
b_2&=&b_1+25 \ (QB \pmod b) \pmod{125},\\
c_2&=&c_1+25 \ (QC \pmod c) \pmod{125}
\end{eqnarray*}
donc~:
\[ a_2=a_1 +25(-1)=x-37, \ b_2=b_1=b, \ c_2=c_1+25(x^2+1) 
=x^3+37x^2-6x+27 \]

On peut aussi observer que $b_1=b$, ceci laisse à penser que $b$ est 
un facteur de $P$ dans $\Z$ ce qu'on vérifie en effectuant la
division euclidienne de $P$ par $b=x^3+x+1$. Comme elle tombe
juste, on est ramené à factoriser $x^4-x+1$ et donc à remonter
la factorisation de $ac$. La borne de Landau diminue à $8(\sqrt{3}+1)$
puisque le degré est 4 et la norme euclidienne du polynôme est $\sqrt{3}$.
Il suffit alors de remonter dans $\Z/125 \Z$ au lieu de $\Z/625 \Z$
(on gagne ainsi une itération).

\subsubsection{Combinaison de facteurs}
Lorsqu'on a les facteurs de $P$ dans $\Z/p^k\Z[X]$ avec $p^k$ plus grand
que le produit du coefficient dominant de $P$ multiplié par la borne
de Landau-Mignotte sur les coefficients de $P$, on commence par
tester la divisibilité dans $\Z[X]$ de $P$ par chaque facteur trouvé
multiplié par le coefficient dominant de $P$. Si la division est
exacte, on a un facteur irréductible, mais si elle n'est pas exacte
il peut se produire qu'un facteur irréductible de $P$ dans $\Z[X]$ soit un
produit de deux, voir plusieurs, facteurs modulaires. Il faut
donc tester la divisibilité de $P$ dans $\Z[X]$ par toutes les combinaisons 
possibles de produits de facteurs modulaires (toujours multiplié par
le coefficient dominant de $P$). Cette étape peut être exponentiellement
longue si le nombre de facteurs modulaires est grand et si par
exemple $P$ est irréductible, bien que les cas soient très rares. 

{\bf Algorithme de recombinaison}\\
Arguments: un polynôme à coefficients entiers, primitif et sans facteur 
multiple $P$ de coefficient dominant $p_n$,
la liste $L$ des facteurs de $P$ dans $\Z/p^l Z[X]$ pour 
$l$ assez grand et $p^l$\\
Valeur de retour: la liste $F$ des facteurs de $P$ dans $\Z$.\\
Initialiser $F$ à vide, initialiser le nombre de facteurs à combine $c$ 
à 1, entamer une boucle infinie~:
\begin{itemize}
\item Si $c$ est strictement supérieur au cardinal de $L$ divisé par 2,
ajouter le quotient de $P$ par le produit des facteurs de $F$ à $F$ 
et retourner $F$
\item Initialiser un vecteur $v=(v_1,...,v_c)$ à $c$ composantes à
la valeur $(1,...,c$)
\item Boucle indéfinie intérieure~:
\begin{enumerate}
\item Faire le produit des facteurs de $F$ d'indice $v$, multiplier
par $p_n$ dans $\Z/p^l Z$, écrire le facteur en représentation symétrique,
le rendre primitif et tester si c'est un facteur de $P$ dans $\Z$.
\item Si on a trouvé un facteur, le rajouter à la liste $F$ et supprimer les
indices de $v$ de la liste $L$, terminer cette boucle intérieure.
\item Sinon, incrémenter $v$ de la manière suivante:\\
On fait une boucle sur un index $m$ initialisé à la taille de $v$,
diminuant de 1 à chaque itération: on ajoute 1 à l'élement de $v$
d'indice $m$, si l'élément obtenu est inférieur ou égal
au cardinal de $L+m-n$, on arrête cette boucle, sinon on passe
à l'itération suivante. Si $m=0$ à la fin de la boucle, $v$
ne peut pas être incrémenté. 
\item Si $v$ ne peut être incrémenté, on incrémente $c$ et on termine
la boucle intérieure.
\item Sinon on fait une boucle à nouveau
sur $m$ en partant de la valeur actuelle incrémentée de 1, et tant
que $m\leq n$ on pose $v_m=v_{m-1}+1$. Puis on passe à l'itération
suivante de la boucle intérieure.
\end{enumerate}
\end{itemize}

Il existe différentes méthodes
qui améliorent la complexité de cette étape~:
\begin{itemize}
\item La recherche des degré possibles de facteurs fondée sur
la factorisation en degrés distincts pour différents nombres premiers 
permet d'éviter des tests de division si une combinaison de facteurs
est d'un degré exclu par la factorisation pour d'autres nombres premiers.
\item Le test de divisibilité du coefficient dominant ou du coefficient
constant permet aussi d'éviter des divisions complètes de polynômes.
\end{itemize}
Mais ces astuces n'évitent pas l'énumération de toutes les combinaisons
possibles de facteurs et donc la complexité exponentielle. Lorsque
les combinaisons d'un petit nombre de facteurs (par exemple 3)
échouent, les systèmes récents utilisent
l'algorithme knapsack de Van Hoeij basé sur l'algorithme LLL
(recherche de base d'un réseau ayant des vecteurs de petite norme) 
qui permet d'eliminer complètement cette complexité exponentielle.

{\bf Exemple}~:\\ 
Toujours le même exemple, il nous restait deux
facteurs dans $\Z/125 \Z$, le facteur $x^3+x+1$ ayant été
détecté comme un facteur de $P=x^7+x^5+x^3-x^2+1$ dans $\Z$.
On teste chacun des facteurs  $a_2=x-37$ et $c_2=x^3+37x^2-6*x+27$
séparément, sans succès. On les multiplie alors modulo 125,
ce qui donne $x^4-x+1$ en représentation symétrique qui est bien
un facteur de $P$ (donc un facteur irréductible).

\subsection{Factorisation à plusieurs variables}
Comme pour le PGCD en plusieurs variables, on se ramène d'abord en
une variable, en général on évalue toutes les variables sauf celle
correspondant au degré partiel le plus faible. On factorise ensuite
en une variable puis on remonte. A chaque étape de remontée, il peut
être à nouveau nécessaire de combiner plusieurs facteurs. Différentes
stratégies existent, comme pour le PGCD~: factorisarion heuristique
(avec reconstruction $z$-adique), remontée variable par variable
ou toutes les variables en même temps comme dans EZGCD.
On va présenter ici plus en détails l'algorithme de factorisation heuristique.

Soit $P$ un polynôme en $X_1,...,X_n$ à coefficients entiers avec $n>1$,
on choisit une des variables par exemple $X_n$, qu'on notera $X$ dans la suite.
On considère $P$ comme un polynôme en $X_1,...,X_{n-1}$ à coefficients dans 
$\Z[X]$. On suppose que $P$ est primitif (quitte à extraire
son contenu qui est dans $\Z[X]$). On calcule ensuite
$P(z)$ pour un entier $z$ tel que\footnote{Ici $|P|$ désigne le plus grand
coefficient de $P$ en valeur absolue} $|z| \geq 2|P|+2$. On factorise $P(z)$
dans $\Z[X_1,...,X_{n-1}]$~:
\begin{equation} \label{eq:heu1}
 P(z)(X_1,...,X_{n-1})=c(z) \Pi_{j=1}^k p_j(X_1,...,X_{n-1})
\end{equation}
où $c$ est le contenu du polynôme $P(z)$ (comme polynôme en $n-1$ 
variables à coefficients entiers). Il s'agit de reconstruire les facteurs
de $P$ à partir des $p_j$ et de $c$. Deux problèmes se posent alors,
celui de la recombinaison possible de plusieurs facteurs $p_j$ pour
obtenir un facteur irréductible de $P$, et l'existence d'un facteur entier du
contenu $c$ à combiner avec un ou plusieurs $p_j$ pour obtenir ce
facteur irréductible. Plus précisément, si $P_k$ est un facteur 
irréductible de $P$, on a~:
\begin{equation} \label{eq:heu2}
 P_k(z)=d(z) \Pi_{\mbox{certains } j} p_j, \quad \mbox{où } 
d(z) \mbox{ divise } c(z)
\end{equation}

On a le~:
\begin{thm}
Soit $P(X_1,...,X_{n-1},X)$ un polynôme à coefficients 
entiers ayant au moins 2 variables. On suppose que $P$ est primitif
vu comme polynôme en les variables $X_1,...,X_{n-1}$
à coefficients dans $Z[X]$.
Il existe une majoration $C$ du contenu $|c(z)|$ de $P$ évalué en $X=z$
(plus précisément on peut trouver un entier $C$ tel que $c(z)$ divise
$C$).\\
Il existe un nombre fini de $z$ tels que l'un des facteurs irréductibles
$P_k$ de $P$ évalué en $X=z$ soit
réductible (c'est-à-dire tels que (\ref{eq:heu2}) admette 
plusieurs facteurs $p_j$ distincts)
\end{thm}

{\bf Preuve}\\
Pour déterminer $C$, on remarque que les facteurs du contenu de $P(z)$
sont des facteurs communs des coefficients de $P$ évalués en $z$
vu comme polynôme en $X_1,...,X_{n-1}$ à coefficients dans $\Z[X]$.
Donc $c(z)$ divise le générateur de l'idéal engendré par ces coefficients
(ce générateur est un polynôme de $\Z[X]$ qui est constant car on a supposé
$P$ primitif), on peut aussi dire que deux au moins des coefficients
dans $\Z[X]$ de $P$ sont premiers entre eux, alors $c(z)$ divise le
coefficient de l'identité de Bézout de ces 2 coefficients vu
comme polynômes en $X$.

Considérons maintenant un facteur irréductible $P_k$ de $P$ de degré $d$
par rapport à $X$. Pour $X_1,...,X_{n-1}$ fixés, on factorise $P_k$ sur $\C$~:
\[ P_k(X)=p_k \Pi_{j=1}^d (X-z_j) \]
On va maintenant se restreindre à un domaine des $X_1,...,X_{n-1}$ sur
lequel les $z_j$ ont une dépendance analytique par rapport à $X_1,...,X_{n-1}$.
Pour cela on veut appliquer le théorème des fonctions implicites pour 
déterminer $z_j$ au voisinage d'une solution donnée. On calcule donc
la dérivée $P'_k$ de $P_k$ par rapport à $X$. On sait que $P$ n'a pas
de facteurs multiples, donc $P_k$ et $P_k'$ sont premiers entre
eux, donc d'après l'identité de Bézout, il existe un polynôme non nul $D$
dépendant de $X_1,...,X_{n-1}$ et deux polynômes $U$ et $V$ dépendant
de $X_1,...,X_{n-1},X$ tels que~:
\[ U P_k + V P_k' = D \]
Si $D(X_1,...,X_{n-1})$ ne s'annule pas, on va pouvoir appliquer le théorème
des fonctions implicites. On se fixe $x_1,..,x_{n-1}$,
on calcule dans $\C$ les racines $z_j$ du polynôme $P(x_1,..,x_{n-1},X)$
pour une solution $z_j$ telle que $P(x_1,..,x_{n-1},z_j)=0$, 
comme $D$ est non nul, on a $P'(x_1,...,x_{n-1},z_j)\neq 0$, donc on peut 
écrire au voisinage de $(x_1,..,x_{n-1})$
\[ z_j=z_j(X_1,...,X_{n-1}), \quad P(X_1,...,X_{n-1},z_j)=0\] 
avec des fonctions $z_j$ analytiques. 
Si $D$ est constant, $D$ ne s'annule pas, 
sinon quitte à permuter les variables, on peut supposer que
le degré de $D$ par rapport à $X_1$ est non nul.
On peut alors se restreindre à une zone $X_1 >> X_2 >> .. >> X_{n-1} >> 1$
où $D$ sera non nul ce qui permet de suivre analytiquement les $z_j$.

Supposons maintenant qu'il existe un nombre infini de $z$ tels $P_k(z)$ 
soit réductible. Alors il existe un ensemble infini $Z$
de ces valeurs de $z$ pour lesquels l'un des facteurs à coefficients
entiers $f_j$ de $P_k(z)$ correspond à un même
sous-ensemble $R$ des racines $z_j$ de $P_k$ et à un même contenu
$c$ (puisqu'il y a un nombre fini de combinaisons possibles des
racines en facteur et un nombre fini de diviseurs possibles
du contenu de $P_k$). Pour $z \in Z$, on a~:
\[ f_j(X_1,...,X_n,z)=c \Pi_{l \in R} (z-z_j), \quad 
f_j \in \Z[X_1,...,X_{n-1}] \]
Soit $L(X)$ le polynôme obtenu par interpolation de Lagrange 
en cardinal$(R)+1$ points $z$ de $Z$, égal à $f_j$ en $X=z$.
Pour des raisons de degré, on a~:
\[ L=c \Pi_{l \in R} (X-z_j) \]
donc $L$ est un facteur de $P$.
De plus $L$ est un polynôme en $X_1,...,X_{n-1},X$ à coefficients
rationnels (par construction). Ceci vient en contradiction avec l'hypothèse 
$P_k$ irréductible, car on a construit un facteur de $P_k$ à coefficients
rationnels $L$ de degré strictement inférieur.

{\bf Corollaire}\\
Pour $z$ assez grand, la reconstruction $z$-adique de $c(z) p_j(z)$ est
un polynôme dont la partie primitive est un facteur irréductible de $P$.

{\bf Preuve du corollaire}\\
On prend $z$ assez grand pour que tous les facteurs irréductibles de $P$
évalués en $z$ aient un seul facteur polynomial (i.e. soient de la forme 
$d(z)p_j(z)$). Quitte à augmenter $z$, on peut supposer que 
$|z|> 2 C L $ où $C$ est la majoration de $|c(z)|$ et $L$ est la borne 
de Landau sur les facteurs de $P$. Alors la reconstruction $z$-adique
de $c(z)p_j(z)$ est $c(z)/d(z)P_j$, donc sa partie primitive est un
facteur irréductible de $P$.

{\bf Algorithme de factorisation heuristique à plusieurs variables}\\
Argument: un polynôme $P$ primitif en au moins 2 variables.\\
Valeur renvoyée: les facteurs irréductibles de $P$\\
Choisir la variable $X$ par rapport à laquelle $P$ est de plus bas degré puis
factoriser le contenu de $P$ vu comme polynôme à coefficients dans $\Z[X]$.
Initialiser un entier $z$ à $2|P|+2$ (où $|P|$ est le plus grand coefficient 
entier de $P$ en valeur absolue) et une liste $L$ à la factorisation de
du contenu de $P$.\\
Boucle indéfinie~:
\begin{itemize}
\item Si $P=1$ renvoyer la liste $L$ des facteurs de $P$.
\item Tant que pgcd$(P(z),P'(z))=0$ incrémenter $z$ de 1.
\item Factoriser $P(z)=c(z)\Pi p_j$
\item Pour tous les facteurs $p_j$, déterminer le polynôme $P_j$ tel que 
$c(z)p_j=P_j(z)$ par remontée
$z$-adique (avec les coefficients de $P_j$ écrit en représentation
symétrique, de valeur absolue plus petite que $|z|/2$). Tester si
la partie primitive de $P_j$ divise $P$. Si oui, rajouter un facteur
irréductible à la liste $L$, et diviser $P$ par ce facteur.
\item Augmenter $z$, par exemple remplacer $z$ par la partie entière de
$\sqrt{2}z$.
\end{itemize}

\subsection{Preuve de l'identité de Bézout généralisée}
Elle se fait par récurrence. Pour $n=2$, c'est l'identité de Bézout usuelle. 
Pour passer
du rang $n-1$ au rang $n$, on isole $P_n$ dans l'identité à résoudre~:
\[ \left( 
\sum_{j=1}^{n-1} Q_j (\Pi_{1 \leq k \leq n-1,k\neq j} P_k) \right) P_n + 
Q_n \Pi_{k\leq n-1} P_k =Q \pmod p\]
Comme $P_n$ est premier avec $\Pi_{k\leq n-1} P_k$, en appliquant Bézout,
on trouve deux polynômes $Q_n$ et $R_n$ tels que~:
\begin{equation} \label{eq:Qn}
 R_n P_n + Q_n \Pi_{k\leq n-1} P_k =Q \pmod p 
\end{equation}
Il reste à résoudre
\[ \sum_{j=1}^{n-1} Q_j \Pi_{1 \leq k \leq n-1,k\neq j} P_k=R_n \pmod p\]
ce que l'on peut faire par hypothèse de récurrence.

\subsection{Algorithme de Bézout généralisé}
Arguments: une liste $P_1,...,P_n$ de polynômes premiers entre eux 2 à 2  
et un polynôme $Q$ à coefficients dans $\Z/p\Z$\\
Valeur renvoyée: la liste de polynômes $Q_1,...,Q_n$ tels que
\[ \sum_{j=1}^n Q_j \Pi_{k\neq j} P_k=Q \pmod p \]
On peut commencer par calculer le produit de tous les $P_k$ puis faire une 
boucle sur $j$ pour calculer les produits des $P_k$ pour $k\neq j$ en divisant
le produit complet par $P_j$ (on fait ainsi $n-1$ multiplications et
$n$ divisions au lieu de $n(n-1)$ multiplications).\\
Boucle indéfinie sur $n$ décrémenté de 1 par itération~:
\begin{itemize}
\item Si $n=2$, on rajoute à la liste résultat les polynômes 
$Q_1$ et $Q_2$ de l'algorithme de Bézout usuel et on renvoie la liste
\item Sinon, on calcule les polynômes $R_n$ et $Q_n$ vérifiant (\ref{eq:Qn}),
on rajoute $Q_n$ en début de liste, on remplace $Q$ par $R_n$.
\end{itemize}
Remarquons que lorsque nous utiliserons cet algorithme, $Q$ sera la différence
entre deux polynômes de même degré (le degré de $P$) et de même coefficient
dominant 1, on peut donc
remplacer les $Q_i$ par le reste euclidien de $Q_i$ par $P_i$ sans
changer l'égalité.

\subsection{Pour en savoir plus}
Pour factoriser des polynômes ayant des coefficients dans des
extensions algébriques, il existe un algorithme assez simple, 
l'algorithme de Trager, qui n'est pas forcément le plus performant 
(la recherche est encore active dans ce domaine), cf. le livre de 
Henri Cohen pp. 142-144.

Pour factoriser sur des corps finis, on peut consulter la thèse
de Bernardin disponible sur le web (\verb|http://www.bernardin.lu|).

On peut aussi consulter le code source de Mupad, les routines
de factorisation se trouvent dans le répertoire \verb|lib/POLYLIB/FACLIB|
après avoir désarchivé la \verb|lib.tar|. Le point d'entrée pour factoriser
des polynômes à plusieurs variables sur $\Z$ est le fichier 
\verb|mfactor.mu|, on observera que l'algorithme utilisé par Mupad est
assez différent de celui qu'on a détaillé dans la section précédente.

\pagebreak

\subsection{Exercices (factorisation des polynômes)}
\begin{enumerate}
\item Déterminer le nombre de racines de $-x^7+x^4+12x-5$ comprises
entre 0 et 6 (en utilisant les suites de Sturm, on donnera les
d\'etails des calculs).
\item \'Ecrire un programme calculant la suite de Sturm d'un polynôme
supposé squarefree (on peut tester avec \verb|sqrfree|), en utilisant
l'algorithme d'Euclide.
\item Trouver les facteurs de degré 1 s'ils existent de
$3x^5+25x^4+67x^3+77x^2+55x+13$ en remontant ses racines
dans $\Z/pZ[X]$ pour $p$ premier bien choisi.
\item Factoriser le polynôme $x^5+x+1$ par la méthode 
de Berlekamp.
\item Calculer avec un logiciel les valeurs numériques des racines
complexes de $P(x)=x^5+x+1$. Trouver les combinaisons de racines
dont la somme est entière (aux arrondis près). En déduire la factorisation
en facteurs irréductibles sur $\Z$ de $P$.
\item Factorisation numérique sur $\C$. \'Ecrire un programme
qui calcule une racine d'un polynôme à coefficients complexes
en utilisant une méthode itérative de type méthode de Newton 
(avec éventuellement un préfacteur lorsqu'on débute la recherche).
Les polynômes seront représentés par la liste de leurs coefficients
et l'évaluation faite par la méthode de Horner.
Trouver ensuite toutes les racines du polynôme en éliminant la
racine trouvée (toujours avec Horner). Trouver les combinaisons
de racines correspondant à un facteur à coefficients entiers.
\item Même question pour les facteurs de degré 2 d'un polynôme à coefficients
réels sans racines réelles en utilisant la méthode de Bairstow décrite
ci-dessous.\\
On cherche un facteur $F=x^2+sx+p$ de $P$, on calcule le quotient et le reste
de la division $P=FQ+R$ par une méthode de type Horner, il s'agit de 
rendre $R$ (vu comme un vecteur à 2 composantes) nul. On calcule
donc $\partial_{s,p} R$ (en cherchant le quotient et le reste
de $xQ$ et $Q$ par $F$, pourquoi?) et on pose~:
\[(s,p)_{n+1}=(s,p)_n- \lambda (\partial_{s,p} R)^{-1} R (s,p)_n\]
où $\lambda$ est un préfacteur compris entre 0 et 1 et ajusté à 1 
lorsqu'on est proche du facteur.
\item Soit $p$ un entier premier et $P$ un polynôme \`a
coefficients dans $\Z/p\Z$. On a la relation
\[ gcd(X^{p^k}-X,P) = \prod_{ f | P, \mbox{\small deg}(f) | k} f, 
\quad f \mbox{ irréductible} \]
En utilisant cette relation, 
déterminer les degrés des facteurs de 
\[ (x^3+x+1)(x^4+x+1) \]
modulo 5 et 7 (sans utiliser la commande factor). 
Peut-on en déduire que $x^3+x+1$ et
$x^4+x+1$ sont irréductibles sur $\Z$?
\item Utiliser les options ``verbose'' de votre logiciel de calcul formel
pour factoriser $x^{202}+x^{101}+1$ et vérifiez que vous avez compris
la méthode utilisée.
\item Montrer que $2x+x^2y+x^3+2x^4+y^3+x^5$ est irréductible sur $\Z$
sans utiliser l'instruction factor à 2 variables (on pourra factoriser 
pour quelques valeurs de $x$ ou de $y$)

\item Que se passe-t-il lorsqu'on ex\'ecute l'algorithme de Yun
dans $\Z/n\Z$?

\item Déterminer les degrés des facteurs de $(x^3+x+1)(x^4+x+1)$ modulo 5
et 7 (sans utiliser la commande factor). Peut-on en déduire que $x^3+x+1$ et
$x^4+x+1$ sont irréductibles sur $\Z$?

\item Utiliser les options ``verbose'' de votre logiciel de calcul formel
pour factoriser $x^{202}+x^{101}+1$ et vérifiez que vous avez compris
la méthode utilisée.
\item Montrer que $2x+x^2y+x^3+2x^4+y^3+x^5$ est irréductible sur $\Z$
sans utiliser directement l'instruction factor 
(on pourra factoriser pour quelques
valeurs de $x$ ou de $y$)

\end{enumerate}

\pagebreak

\section{Int\'egration}
\subsection{Introduction}
Que peut-on espérer d'un système de calcul formel lorsqu'il s'agit
de calculer une primitive? Tout d'abord, on peut espérer qu'il
sache résoudre ce que l'on donne en exercice à nos étudiants!
Ceci suppose donc de connaitre quelques méthodes classiques, par
exemple: intégration de polynômes (!), polynômes multipliés par exponentielle
ou/et fonctions trigonométriques, de polynômes trigonométriques par
linéarisation, de fractions rationnelles,
de fractions trigonométriques, de fractions de racines carrées de 
polynômes du second ordre, de fonctions s'y ramenant par une ou plusieurs
intégrations par parties ou par
changement de fonction (par exemple reconnaissance de formes $F(u)u'\ $)
ou par changement de variables, etc.

Mais au-delà de ces méthodes (qui ont l'avantage de la rapidité mais
tiennent parfois plus de la
recette de cuisine que de l'algorithme...), on peut se demander 
si la primitive d'une fonction donnée peut ou non s'exprimer en terme 
des fonctions ``élémentaires''. Par exemple, tout le monde ``sait''
que la fonction $e^{x^2}$ n'admet pas de primitive ``simple'', encore
faut-il donner un sens mathématique précis à cette affirmation.
Ceci nécessite de donner une définition rigoureuse du terme fonction
élémentaire. On peut alors appliquer un algorithme développé
par Risch (pour les extensions dites transcendantes, obtenue par ajout
des fonctions exponentielle et logarithme)  
qui permet de répondre à la question~:
il s'agit vu de très loin d'une extension de l'algorithme d'intégration
des fractions rationnelles.

Cet article se décompose en deux parties principales~:
\begin{itemize}
\item la section \ref{sec:elem} présente les définitions de fonctions
élémentaires, de tour de variables, et donne deux théorèmes,
le théorème de structure de Risch qui permet d'écrire une fonction 
contenant des exponentielles et des logarithmes comme une fonction 
élémentaire par rapport à une tour de variable, et 
le théorème de Liouville qui donne la forme que peut prendre
une primitive d'une fonction élémentaire lorsqu'elle est aussi élémentaire.
\item la section \ref{sec:risch} décrit l'algorithme d'intégration de Risch
permettant de décider si une fonction élémentaire donnée possède
ou non une primitive élémentaire et de la calculer dans le premier
cas. Nous ne présentons ici l'algorithme de Risch que pour les extensions
transcendantes pures (ln et exp).
\end{itemize}
Le lecteur intéressé par le cas des extensions algébriques 
pourra consulter la thèse de Trager. Pour les extensions
plus g\'en\'erales (incluant en particulier les fonctions
tangente, arctangente), la r\'ef\'erence est le livre de Bronstein 
donnée en section \ref{sec:rischref}.

\subsection{Fonctions élémentaires} \label{sec:elem}

\subsubsection{Extensions transcendantes, tour de variables}
On se donne une expression $f(x)$ dépendant de la variable $x$ que l'on 
souhaite intégrer par rapport à $x$. L'algorithme de Risch s'applique à
cette expression si on peut l'écrire comme une fraction rationnelle à
plusieurs variables algébriquement indépendantes
\[ x, f_1(x), f_2(x,f_1(x)), ..., 
f_n(x,f_1(x),f_2(x,f_1(x)),...,f_{n-1}(x,f_1(x),...,f_{n-2}(x))) \]
où les $f_i$ sont soit l'exponentielle soit le logarithme d'une fraction
rationnelle (le corps de base appelé aussi corps de
constantes ici est soit $\C$, soit une extension algébrique de $\Q$ ou une
extension algébrique d'un corps de fractions rationnelles s'il
y a des paramètres). 
On appelle tour de variables
la suite des $x,f_1,...,f_n$ (chaque étage est donc une exponentielle
d'une fraction rationnelle ou le logarithme d'une fraction rationnelle
dépendant des étages précédents) 
et on dira que $f$ est une fonction élémentaire
par rapport à cette tour de variables.

L'intérêt de l'écriture d'une expression sous forme de tour est 
qu'elle est stable par dérivation~: 
si on dérive par rapport à $x$
une fonction élémentaire dépendant d'une tour de variables, on obtient encore 
une fonction élémentaire dépendant de la même tour de variables.
Autrement dit, l'ensemble des fonctions \'el\'ementaires pour une tour 
fix\'ee est un corps diff\'erentiel.

{\bf Exemples: }
\begin{itemize}
\item $e^{x^2}$ est bien dans ce cas, pour $n=1$, $f_1$
est l'exponentielle de $x^2$ qui est algébriquement indépendant
de $x$. Les fonctions $(2x^2-1)e^{x^2}$
ou $x/(e^{x^2}-1)$ sont aussi élémentaires par rapport à
la tour de variables $\{x,e^{x^2} \}$.  
\item $x \ln(x) \exp(x)$ est élémentaire par rapport à la tour
$\{ x, \ln(x), \exp(x)\}$, mais aussi par rapport à la tour
$\{ x, \exp(x), \ln(x)\}$.
\item $xe^{x \ln(x)}$ est élémentaire, en prenant $n=2$, $f_1=\ln(x)$
et $f_2=e^{x f_1}$.
\item $x^n=e^{n\ln(x)}$, o\`u $n$ est un param\`etre, convient avec
comme tour $\{x, \ln(x), e^{n \ln(x) }$
\item $e^{\ln(x)}$ ne convient pas car il n'est pas algébriquement
indépendant de $x,\ln(x)$ mais on peut le réécrire sous une forme
acceptable puisque $e^{\ln(x)}=x$.
\item $e^{\ln(x)/2}$ ne convient pas non plus car son carré est égal à $x$.
Une réécriture ne suffit pas, cet exemple est bien sûr une extension
algébrique et non transcendante.
\end{itemize}

Dans la suite, on va s'intéresser aux tours de variables dans lesquelles 
on a effectué des simplifications évidentes.
On élimine les $\ln \circ \exp$ de la manière suivante~:
si $f_k=\ln(g_k)$, on regarde si $g_k$ vu comme fraction 
en $f_1,...,f_{k-1}$ possède un facteur $f_j^m$ (avec $m \in \Z$)
lorsque $f_j=\exp(g_j)$ est une exponentielle.
Si c'est le cas, on a $f_k= m g_j + \ln(g_k/g_j^m)$. On change
alors de tour en remplaçant $f_k$ par $\tilde{f}_k=\ln(g_k/g_j^m)=f_k-mg_j$.
On élimine aussi les $\exp \circ \ln$, si
$f_k=\exp(g_k)$, pour $j<k$ si $f_j$ est un logarithme,
on regarde si $c_j=\partial_{f_j}g_k|_{f_j=0}$ est un entier, si
c'est le cas on remplace $f_k$ par $\tilde{f}_k=f_k/g_k^{c_j}$.

{\bf Exemples: }
\begin{eqnarray*}
 \ln(\frac{e^{x^2}+1}{e^{x^2}}) &\rightarrow &-x^2 + \ln(e^{x^2}+1) \\
e^{3 \ln(x)+\ln(x)^2+5} & \rightarrow & x^3 e^{\ln(x)^2+5} 
\end{eqnarray*}


\subsubsection{Théorème de structure de Risch}
On voit donc qu'il est nécessaire de disposer d'un algorithme
pour décider si des exponentielles et logarithmes sont
algébriquement indépendants. Cet algorithme est basé sur
un théorème de structure dû à Risch~:
\begin{thm}
Soit $f=\ln(g(x))$ le logarithme d'une fonction élémentaire
$g$ par rapport à une tour de variables $T$, alors soit $f$
est algébriquement indépendant des variables de $T$, soit $f$ est
élémentaire et plus précisément combinaison linéaire rationnelle
des logarithmes et des arguments des exponentielles de la tour $T$.

Soit $f=\exp(g)$ l'exponentielle d'une fonction élémentaire $g$
par rapport à une tour de variables $T$, alors soit $f$
est algébriquement indépendante des variables de $T$, soit
il existe $n$ tel que $f^n$ soit élémentaire par rapport à $T$ 
(on peut alors appliquer le cas précédent à $ng=\ln(f^n)$)
\end{thm}

{\bf Démonstration}~:\\
Commençons par le cas de l'exponentielle. On considère le polynôme minimal
de $f=\exp(g)$~:
\[ a_n f^n+...+a_0=0, \quad a_n \neq 0 , a_0 \neq 0\]
où les $a_i$ sont des fractions rationnelles en $T$. On dérive
et on applique $f'=g'f$~:
\[ (a_n'+n a_n g') f^n +   ... + ( a_{k}' + ka_k g')f^{k} +... =0\]
c'est un multiple du polynôme minimal donc il existe une fraction rationnelle
$C$ (par rapport à la tour de variables) telle que~:
\[ \forall k, \quad (a_k'+k a_k g') = C a_k\]
Comme $a_n\neq 0$, cela entraine $a_n'/a_n+ng'=C$. Le coefficient
constant $a_0$ est aussi non nul, donc $a_0'/a_0=C$ et 
\[ n g' = a_0'/a_0 - a_n'/a_n \Rightarrow ng=\ln(\frac{a_0}{a_n}) + k\]
où $k$ est constant, donc $f^n=\exp(ng)=e^k a_0/a_n$ est élémentaire.

Passons au cas du logarithme, supposons que $f=\ln(g)$ dépende
algébriquement de la tour $T$, on va commencer par montrer que
$f$ est élémentaire. On écrit~:
\[ a_n f^n+...+a_0=0\]
où les $a_i$ sont des fractions rationnelles en $T$. On dérive en
appliquant $f'=g'/g$~:
\[ a_n' f^n + (n a_n f' + a_{n-1}')f^{n-1}  ... + a_1 f'+a_0 '\]
Comme $f'$ est une fraction rationnelle en $T$, le polynôme
$a_n' X^n + (n a_n f'+a_{n-1}') X^{n-1}+...+ a_1 f'+a_0'$ qui annule $f$
doit être un multiple du polynôme minimal de $f$, il existe donc
une fraction rationnelle $C$ par rapport à $T$ telle que~:
\[ a_n' = C a_n \quad (n a_n f'+a_{n-1}') = C a_{n-1} \quad ... \]
On en déduit $f'$~:
\[ f'=\frac{\frac{a_n'}{a_n} a_{n-1}-a_{n-1}'}{n a_n} = 
\left(\frac{-a_{n-1}}{n a_n}\right)'\]
donc il existe une constante $c$ telle que~:
\[ f=\frac{-a_{n-1}}{n a_n}+c\]
donc $f$ est élémentaire par rapport à la même tour $T$ que $g$.

Montrons maintenant qu'un logarithme $f=\ln(g)$ qui est élémentaire
par rapport à une tour de variable $T$ est combinaison linéaire à
coefficients rationnelles des logarithmes et des arguments
des exponentielles de $T$\footnote{cette preuve peut être sautée en première
lecture}.
Soit $X$ la dernière variable de la tour $T$.
On factorise maintenant le numérateur et le dénominateur de $g$ en
$\prod_j P_j^j$ où les $P_j$ sont sans facteurs multiples et 
premiers entre eux 2 à 2 (par rapport à $X$), il existe
$C$ indépendant de $X$ tel que~:
\begin{equation} \label{eq:g}
 g=C\prod_{j \in \Z} P_j ^{j} \Rightarrow 
\ln(g)=\ln(C)+\sum_{j \in \Z} j \ln(P_j)
\end{equation}
Alors $f'=\ln(C)'+\sum_j j P_j'/P_j$ donc $\prod P_j f'$ est un 
polynôme en $X$. 
Soit $N/D$ la fraction irréductible représentant $f$, on a~:
\[ f'=\frac{N' D -N D'}{D^2}\]
on vient donc de montrer que~:
\begin{equation} \label{eq:prodpj}
\left(\prod_j P_j \right) \frac{N' D - N D'}{D^2} 
\mbox{ est un polynôme en $X$}
\end{equation}
Soit $P$ un facteur irréductible de $D$ de multiplicité
$k$ tel que $D=P^k Q$ (donc $P$ premier avec $Q$, mais $P$ est aussi
premier avec $N$ car $f=N/D$ est irréductible). Alors en simplifiant
numérateur et dénominateur par $P^{k-1}$, on a~:
\begin{equation} \label{eq:estpolynome}
 \left( \prod_j P_j \right) \frac{N' P Q - N (kP'Q+PQ')}{ P^{k+1} Q^2} 
\mbox{ est un polynôme en $X$.} 
\end{equation}
On en déduit, après simplification d'au plus un facteur $P$ au dénominateur 
avec l'un des $P_j$, que $P^{k}$ divise 
$N' P Q - N (kP'Q+PQ')$ donc $P$ divise $P'$. Ceci n'est possible
que si $P=1$ (et donc le dénominateur de $f$ est égal à 1) 
ou si la variable $X$ est une exponentielle et $P=X$.

Montrons que ce deuxième cas est en fait exclus:
en effet si $P=X=\exp(Y)$ est une exponentielle, on a alors 
$D=X^k$ et $Q=1$.
Comme $P'=Y'X$, (\ref{eq:estpolynome}) devient~:
\[ \left( \prod_j P_j \right) \frac{X (N' - k N Y' )}{X^{k+1}}
\mbox{ est un polynôme en $X$} \]
Comme $X$ ne divise pas $N$, $N$ possède donc un coefficient constant 
$a_0$ non nul. Le coefficient constant de $N'-kNY'$ est $a_0'-ka_0 Y'$. 
Si ce terme était nul alors $a_0'=ka_0 Y'$ donc $a_0=c \exp(kY)=cX^k$ 
or $a_0$ ne dépend pas de $X$ donc $c=0$ donc $a_0=0$, absurde. 
Donc $X$ ne divise pas $N'-kNY'$.
Comme $X^{k+1}$ divise $ \prod P_j X (N' - k N Y' )$, on en déduit que
$X^k$ divise un des $P_j$. Donc $k=1$ et $P_j=XQ_j$. 
Revenons maintenant à (\ref{eq:g}), on a~:
\[  f=\ln(g) = \ln(C)+j \ln(XQ_j)+ \sum_{l \neq j} l \ln(P_l) \]
on dérive~:
\[ f'=\ln(C)'+jY'+j\frac{Q_j'}{Q_j}+\sum_{l \neq j} l \frac{P_l'}{P_l}\]
on voit qu'il n'est plus nécessaire de multiplier $f'$ par $P_j$
pour avoir un polynôme, multiplier par $Q_j$ suffit, plus précisément
\[ 
\left( \prod_{l \neq j} P_l \right) Q_j \frac{N' D - N D'}{D^2} 
\mbox{ est un polynôme en $X$.} 
\]
donc $X^{k+1}$ divise  
$ \left(\prod_{l \neq j}P_l \right) Q_j X (N' - k N Y' )$ 
ce qui est impossible.

Donc $D=1$ dans tous les cas et on a $f=N$. Donc 
\[ f'=N'=\ln(C)'+\sum_j j P_j'/P_j 
\mbox{ est un polynôme par rapport à $X$} \]
On en déduit que les $P_j$ ne dépendent pas de $X$ sauf si
$X$ est une exponentielle et $P_j=X$. 
Dans les deux cas $N'$ ne
dépend pas de $X$ donc le polynôme $N$ est de degré 0 ou 1 en $X$
(si $X$ est une exponentielle, $N$ est forcément de degré 0)
\begin{itemize}
\item Si $X=\exp(Y)$ est une exponentielle (avec $Y$ élémentaire
ne dépendant pas de $X$), alors $f=N$ est indépendant de $X$.
On retire $jY$ à $f$ et on divise $g$ par $X^j$ 
(en posant $j=0$ si aucun des $P_j$ n'est égal à $X$), 
qui devient indépendant de $X$, on conserve ainsi l'égalité $f=\ln(g)$
mais avec une variable de moins dans la tour de variables par
rapport à laquelle $f$ et $g$ sont élémentaires.
\item Si $X$ n'est pas une exponentielle, $N=cX+d$ avec $c$
dans le corps de constantes, et $d$ indépendant de $X$.
Si $X=x$, on a $g=\exp(cx+d)$ qui n'est rationnel que si
$c=0$. On a alors $d$ donc $f$ et $g$ constants.
Si $X=\ln(Y)$ est un logarithme (avec $Y$ élémentaire
ne dépendant pas de $X$), alors $\forall j, P_j=1$ donc $g$ est élémentaire
indépendante de $X$. 
On a alors~:
\[ f=N=c\ln(Y)+d = \ln(g) \]
avec $c$ dans le corps des constantes, $d$ et $g$ élémentaires
indépendants de $X$. On cherche maintenant la fonction
élémentaire $d$. Cette fonction n'est pas le logarithme d'une
fonction élémentaire en général car $c$ n'est pas forcément entier,
mais $d'$ a les mêmes propriétés que la dérivée du logarithme
d'une fonction élémentaire.
On peut donc reprendre le même raisonnement mais avec une variable de moins
dans la tour de variables. Si la tour qu'on a choisie est normalisée,
alors $Y$ ne contient au numérateur et au dénominateur aucune puissance
d'une exponentielle d'une variable de la tour donc le polynôme $P_j$
du cas précédent ne peut provenir de $Y$ ce qui entraine que $j$
est bien entier dans le cas précédent (bien que $c$ ne le soit
pas forcément).
\end{itemize}

Après avoir fait une récurrence sur le nombre de variables de la tour,
on a donc $f$ qui s'exprime comme combinaison linéaire à coefficients
entiers des arguments $g_k$ des variables exponentielles $f_k=\exp(g_k)$
de la tour et à coefficients a priori quelconque des variables logarithmes
$f_l=\ln(g_l)$ de la tour~:
\[ f = \sum_k j_k g_k + \sum_l x_l \ln (g_l) = \ln (g) \]
Comme $g$ est élémentaire, $h=g/\prod_k \exp(g_k)^{j_k}$
est élémentaire de logarithme $\sum_l x_l \ln (g_l) $.
Montrons que si les arguments des $\ln$ sont des polynômes
sans facteurs multiples, alors
les $x_l$ sont entiers. Rappelons
que les $\ln (g_l)$ sont algébriquement indépendants, on peut donc
construire des polynômes irréductibles $I_l$ par rapport aux variables
de la tour tels que $I_l$ divise une fois $g_l$ mais ne divise pas les $g_k$
précédents. Soit $h=\prod_{j \in \Z} P_j^j$ la factorisation
sans facteurs multiples de $h$. On dérive alors $\ln(h)$ ce qui donne~:
\[ \sum_l x_l g_l'/g_l = \sum_j j P_j'/P_j \]
où $\prod_j P_j^j$ est la décomposition sans facteurs multiples
de $h$. Comme $I_l$ divise un et un seul des $P_j$ on en déduit
que $x_l$ est égal au $j$ correspondant et est donc entier.
(Remarque: si on n'impose pas aux arguments des logarithmes
d'être des polynômes sans facteurs carrés, 
on obtiendrait ici des coefficients rationnels).

{\bf En pratique}:\\
On peut effecter l'algorithme de la manière suivante~: 
\begin{itemize}
\item on cherche les variables généralisées de l'expression
qui dépendent de $x$.
\item On ajoute les variables généralisées en commençant par
la moins longue
\item Si c'est un logarithme, on extrait les puissances des
exponentielles précédentes dont il dépend.
On cherche des relations entre fonctions $\ln$ en les réécrivant
comme combinaison linéaire de $\ln$ indépendants. Pour avoir
des $\ln$ indépendants, on se ramène d'abord à des polynômes
sans facteurs multiples en utilisant la relation $\ln(a/b)=\ln(a)-\ln(b)$ 
et en écrivant la factorisation sans facteurs multiples 
de chaque polynôme argument, puis
on extrait le PGCD 2 à 2 des arguments de logarithmes jusqu'à
obtenir des arguments de $\ln$ premiers entre eux.
\item Si c'est une exponentielle, on teste
si son argument est combinaison linéaire à coefficients rationnels~:
\begin{itemize}
\item des arguments des exponentielles précédentes, 
\item des $\ln$ des logarithmes précédents,
\item de $\ln(x)$ et de $i*\pi$.
\end{itemize}
Pour cela on substitue les $\ln$ par des indéterminées,
et on dérive une fois par rapport à cette indéterminée, le
résultat doit être un rationnel, pour les variables exponentielles,
il faut réduire au même dénominateur et résoudre le système
linéaire obtenu en identifiant les coefficients du numérateur.
Si l'exponentielle est indépendante des précédentes, 
on extrait de l'exponentielle à rajouter la partie linéaire de la 
dépendance en les $\ln$ précédents si le coefficient correspondant est
entier. Par exemple, on réécrit~:
\[ xe^{2 \ln(x)+\ln(x)^2} = x^3 e^{\ln(x)^2} \]
\end{itemize}

{\bf Remarque}\\
On n'est pas obligé de se limiter aux seules fonctions logarithmes
et exponentielles, l'essentiel est de pouvoir tester l'indépendance
algébrique des expressions créées. Pour éviter d'avoir à introduire
des exponentielles et logarithmes complexes dans une expression
réelle, on peut autoriser
par exemple des extensions en tangente ou en arctangente.

\subsubsection{Théorème de Liouville}
On a vu que la d\'eriv\'ee d'une fonction élémentaire dépendant 
d'une tour de variables est une fonction élémentaire dépendant 
de la même tour de variables.
Réciproquement, supposons qu'une fonction élémentaire admette
une primitive qui soit élémentaire, c'est-à-dire qu'elle doit
être une fraction rationelle par rapport à une tour de variables
mais pas forcément identique à celle de départ. Alors, si une telle
écriture existe, à des termes logarithmiques près, elle
ne peut dépendre que de la même tour de variables, plus précisément
on a le théorème de Liouville~:
\begin{thm}
Soit $f$ une fonction élémentaire par rapport à une tour de variables $T$
et un corps de constantes $K$ admettant une primitive élémentaire $F$. Alors 
il existe un nombre fini de constantes $c_1,...,c_n$ et de fonctions
élémentaires $v_1,...,v_n$ par rapport à $T$ avec comme corps de constantes
une extension algébrique $K'$ de $K$ tel que $F - \sum_k c_k \ln(v_k) $
soit élémentaire par rapport à $T$ et $K$.
\end{thm}

{\bf Preuve:}\footnote{Peut être omise en première lecture}\\
Soit $f$ élémentaire de tour $T_1$ (corps $K$) et 
$F$ sa primitive supposée élémentaire de tour $T_2$ et de corps $K'$
une extension algébrique de $K$. 
On commence par rajouter après les élements de $T_1$ les 
élements nécessaires de $T_2$ pour obtenir une tour $T$ par rapport
à laquelle $f$ et $F$ sont élémentaires (plus précisément $F$ sera
élémentaire quitte à autoriser des puissances fractionnaires
des variables exponentielles de $T_1$). Le théorème de structure
de Risch permet de faire cela, en effet on regarde pour chaque
élément de $T_2$ s'il est algébriquement indépendant des éléments
de $T_1$ ou non. S'il l'est, on le rajoute à la tour $T$, s'il
ne l'est pas alors dans le cas d'un logarithme il est élémentaire
et dans le cas d'une exponentielle, une de ses puissances est
élémentaire. Donc $F$ est bien une fraction rationnelle par rapport
aux éléments logarithmiques de $T_1$, aux racines $n$-ième
des éléments exponentiels de $T_1$ et à des éléments de $T_2$
dans cet ordre (le corps des constantes étant $K'$).

{\bf Première étape:}\\
Commençons par les éléments restant de $T_2$. Soit $X_k$ l'élément
au sommet de la tour $T$. La dérivée $f$ de $F$ par rapport à $X_k$
ne dépend pas de $X_k$. Donc soit $F$ ne dépend pas de $X_k$ et
on passe à la variable suivante, soit $X_k=\ln(v_k)$ est un logarithme
et $F=c_k \ln(v_k)+d_k$ avec $c_k \in K'$ et $v_k$ et $d_k$ 
indépendants de $X_k$. S'il
n'y a pas d'autres éléments restants de $T_2$, on passe à la 2ème étape.
Sinon soit $X_{k-1}$ la variable suivante 
(juste en-dessous de $X_k$ dans la tour).
En dérivant, on a~:
\[ F'= c_k \frac{v_k'}{v_k} + d_k' = f\]
Supposons que $v_k$ dépende de $X_{k-1}$, on fait alors un raisonnement 
analogue à celui de la preuve du théorème de structure de Risch, en décomposant
$v_k$ en produit/quotient de facteurs sans multiplicités $v_k=\prod P_j^j$
et en écrivant $d_k=N/D$ on a~:
\[\left(\prod_j P_j \right) \frac{N' D - N D'}{D^2} \]
est un polynôme en $X_{k-1}$. On en déduit comme précédemment que
$D=1$, $N'=d_k'$ est indépendant de $X_{k-1}$. Comme on a supposé que
$v_k$ dépend de $X_{k-1}$, $X_{k-1}=\exp(Y_{k-1})$ est alors une 
exponentielle, $N=d_k$ ne dépend pas de $X_{k-1}$ et l'un des $P_j=X_{k-1}$
(sinon tous les $P_j$ seraient constants en $X_{k-1}$ donc $v_k$ aussi).
On élimine alors la variable $X_{k-1}$ en écrivant 
$\ln(v_k)=jY_{k-1}+\ln(w_k)$, avec $Y_{k-1}$ et $w_k$ élémentaires et
indépendants de $X_{k-1}$.

Si $v_k$ est indépendant de $X_{k-1}$, alors $d_k'$ aussi donc
soit $d_k$ est indépendant de $X_{k-1}$ et on passe à la variable
suivante, soit $X_{k-1}$ est un logarithme et 
$d_k=c_{k-1}\ln(v_{k-1})+d_{k-1}$.
En continuant pour toutes les variables restantes de $T_2$, on obtient
\[ F=\sum_k c_k \ln v_k +d \]
avec $d$ et $v_k$ élémentaires pour $T_1$ (avec exponentielles
modifiées en en prenant une racine $n$-ième) et $K'$.

{\bf Deuxième étape}
Il s'agit de montrer que pour les exponentielles, il n'est en fait pas
nécessaire de prendre de racines $n$-ième. La compréhension
de cette étape demande
un peu de familiarité avec l'algorithme de Risch (cf. infra).
On va faire la preuve pour la variable au sommet de la tour $T_1$ si
c'est une exponentielle. On verra dans le déroulement
de l'algorithme de Risch que pour les autres variables, il y a
appel récursif de l'algorithme d'intégration, donc traiter
la variable au sommet suffira.
Soit donc $\exp(Y)$ la variable au sommet de la tour $T_1$, on note
$X=\exp(Y/n)$ la racine $n$-ième de cette variable qui est utilisée
pour exprimer $F=\sum c_k \ln v_k + N/D$ comme une fraction
rationnelle en $X$ alors que $f=F'$ est une fraction rationnelle en $X^n$.
On a donc~:
\[ \sum c_k \frac{v_k'}{v_k} + \frac{N}{D}' 
=f=\mbox{fraction rationnelle en }(X^n) \]
Notons que le fait que $X$ soit une exponentielle est essentiel, 
car par exemple l'intégrale d'une fraction rationnelle dépendant de $x^n$ 
comme $x^3$ ou $1/(x^3-1)$ ne s'exprime pas en fonction de $x^3$.
On traite d'abord la partie polynomiale généralisée de $f$ en $X^n$:
\[ \sum_{j\in \Z} a_j (X^n)^j\]
Son intégrale est un polynôme généralisé, éventuellement dépendant
de $X$, soit $\sum_{j\in \Z} A_j X^j$. On dérive, et on obtient
pour $k$ non multiple de $n$, $A_k Y/n+A_k'=0$ dont $A_k=0$ est
solution. La partie polynôme généralisé ne dépend donc que de $X^n$.
On effectue aussi les intégrations par parties pour réduire le 
dénominateur de $f$ à un polynôme sans facteurs multiples (réduction
de Hermite), ce qui se fait en introduisant des fractions rationnelles 
en $X^n$ uniquement. Reste la partie logarithmique. On utilise le critère
du résultant, les coefficients des logarithmes sont les racines 
$c_k$ du polynôme en $t$
\[ \mbox{Res}_X (D,N-tD') \]
où ces racines doivent être indépendantes de $x$ (puisque $F$ existe)
et les $v_k$ correspondants sont égaux à
\[ \mbox{gcd}(D,N-c_k D') \]
Or comme $X$ est une exponentielle, $D'$ est un polynôme en
$X^n$, de même que $D$ et $N$, donc $v_k$ est un polynôme
en $X^n$.

{\bf Troisième étape}
Il reste enfin à montrer que seuls les $c_k$ et $v_k$ nécessitent
une extension algébrique de $K$. Ceci est encore une cons\'equence
de l'algorithme de Risch, la construction
de la partie polynomiale (éventuellement généralisée) et de la 
partie fractionnaire ne font en effet intervenir que des coefficients
dans le corps $K$.

\subsection{L'algorithme de Risch} \label{sec:risch}
On suppose dans la suite qu'on s'est ramené à une fraction rationnelle
par rapport à une tour de variables (où on a effectué les simplifications
évidentes $\ln \circ \exp$, ainsi que $\exp \circ \ln$, dans le
premier cas en extrayant les facteurs évidents en les variables
précédentes exponentielles, dans le deuxième cas en extrayant la
partie linéaire à coefficient entier en les variables logarithmes
précédentes).
On note $X$ la variable au sommet de la tour et $N_0/D_0$ l'écriture
de la fonction élémentaire comme fraction irréductible avec
$N_0$ et $D_0$ polynômes en $X$.

{\bf Exemples}\\
\begin{eqnarray*}
\int (2x^2+1) e^{x^2} & X=e^{x^2} & N_0=(2x^2+1) X, D_0=1 \\
\int \frac{x \ln(x)}{x+\ln(x)} & X=\ln(x) & N_0=xX, D_0=x+X
\end{eqnarray*}

La première étape va consister à se ramener à un dénominateur sans facteurs
multiples. Elle est analogue au cas des fractions
rationnelles de $x$ et est basée sur l'identité de Bézout entre
$P$ et $P'$ vu comme polynômes en la variable du haut de la tour. 
Il apparait toutefois une difficulté pour les
extensions exponentielles, à savoir que $X=e^f$ et $X'=f' X$
ne sont pas premiers entre eux comme polynômes en $X$, on devra
traiter le pôle 0 d'une fraction rationnelle en une exponentielle $X$ comme
on traite l'intégration d'un polynôme en $x$.
Si $P$ est sans facteurs multiples et premier avec $X$, alors
$P(X)$ et $P(X)'=f' X P'(X)$ vu comme
polynômes en $X$ n'ont pas de facteurs en commun.

On commence donc, si $X$ est une exponentielle et $D_0$ un
multiple de $X$, par appliquer Bézout pour décomposer la fraction $N_0/D_0$
en~:
\[ \frac{N_0}{D_0}
=\frac{N_1}{D_1} + \frac{P}{X^{k} } , \quad \mbox{gcd}(X,D_1)=1, D_0=X^k D_1\]
On isole aussi la partie polynômiale en effectuant
la division euclidienne de $N_0$ par $D_0$ (ou de $N_1$ par $D_1$ si $X$
est une exponentielle),
on obtient alors une écriture sous la forme~:
\[ \frac{N}{D} + \sum_j a_j X^j\]
où la somme sur $j$ est finie et porte sur des entiers positifs ou nul 
si $X$ n'est pas une exponentielle, ou sur des entiers relatifs si $X$
est une exponentielle.

On effectue la même écriture sur la partie fractionnaire de $F$,
et en identifiant les parties polynomiales et éventuellement la partie
polaire en 0 si $X$ est une exponentielle, on peut séparer l'intégration
en 2 parties: intégration de la partie polynomiale (généralisée)
et intégration de la partie fractionnaire propre.

{\bf Exemples}
\begin{itemize}
\item $ (2x^2+1) e^{x^2} = 0+(2x^2+1)X$ est un polynôme,
\item 
\[ \frac{x \ln(x)}{x+\ln(x)} = \frac{xX}{x+X}=-\frac{x^2}{x+X}+x\]
la partie polynomiale est $x$ (de degré 0 en $X$), la partie fractionnaire
est $-x^2/(x+X)$
\item 
\[ \frac{x(e^{2x}+1)}{e^x(e^x+1)^2}=\frac{x(X^2+1)}{X(X+1)^2}
= -\frac{2x}{(X+1)^2} + xX^{-1}\]
la partie polynôme généralisé est $xX^{-1}$
\end{itemize}

\subsubsection{Intégration d'une fraction propre}
\subsubsection{Réduction sans facteurs multiples}
On factorise $D$ en $\prod_i P_i^i$ avec $P_i$ sans facteurs multiples 
(et les $P_i$ premiers entre eux 2 \`a 2) et on décompose
en éléments simples relativement à cette factorisation (en appliquant
Bézout)~:
\[ \frac{N}{D} = \sum_{i>0} \frac{N_i}{P_i^i} \]
Pour chaque polynome $P_i$, on applique Bézout à $P_i$ et $P'_i$~:
\[ N_i = A_iP_i+B_iP'_i \Rightarrow \frac{N_i}{P_i^i}=\frac{A_i}{P_i^{i-1}}
+ \frac{B_iP_i'}{P_i^i}\]
on intègre par parties le second terme
\[ \int \frac{N_i}{P_i^i} = \int \frac{A_i}{P_i^{i-1}}
- \frac{B_i}{(i-1)P_i^{i-1}} + \int \frac{B_i'}{(i-1)P_i^{i-1}}  \]
on rassemble les deux int\'egrales ayant $P_i^{i-1}$ au dénominateur
et on recommence jusqu'à avoir une puissance 1 au dénominateur. Il reste
alors \`a int\'egrer une somme de fractions du type $N/D$ avec
$D$ et $D'$ premiers entre eux.

{\bf Exemple}\\
On reprend le dernier exemple de la section précédente pour
éliminer la puissance 2 au dénominateur:
$N_2=2x$ et $P_2=(X+1)$ avec $X=e^x$. On a $P_2'=X$, donc $A_2=2x$ et
$B_2=-2x$~:
\[ \int \frac{2x}{(X+1)^2} =\int \frac{2x}{P_2} + 
\int \frac{-2x P_2'}{P_2^2} = \int \frac{2x}{P_2} + \frac{2x}{P_2}
- \frac{2}{P_2}\]
il reste donc à intégrer $(2x-2)/(e^x+1)$.

\subsubsection{La partie logarithmique}
Comme on l'a vu lors de la preuve du théorème de structure de Risch,
si on dérive une fraction en $X$, le dénominateur de la dérivée ne
peut se décomposer qu'en produit de facteurs de multiplicité supérieure
ou égale à 2. Il en résulte que la fraction à intégrer résiduelle (encore
notée $f=N/D$) après l'étape de réduction ci-dessus ne peut provenir que de la
dérivation de $F=\sum_k c_k \ln (v_k)$~:
\[ f=\frac{N}{D}=F'= (\sum_k c_k \ln (v_k))'= \sum_k c_k \frac{v_k'}{v_k}\]
En identifiant les décompositions
en éléments simples de $F'$ et $f$, on montre également que 
les $v_k$ divisent $D$, plus précisément on peut imposer aux $v_k$
d'être premiers entre eux 2 à 2 et dans ce cas $D=\prod v_k$. 
Donc~:
\[ \sum_k c_k \frac{v_k'}{v_k} = \frac{N}{\prod_k v_k}=\frac{N}{D}\]
et~:
\[ N = \sum_k c_k v_k' \prod_{j\neq k} v_j \]
Soit $t$ un paramètre, formons le polynôme $N-tD'$~:
\[ N-tD' = \sum_k \left( (c_k -t) v_k' \prod_{j\neq k} v_j \right) \]
donc le pgcd en $X$ des polynômes $N-tD'$ et $D$ est~:
\begin{itemize}
\item si $t$ n'est égal à aucun des $c_k$, $N-tD'$ est premier
avec $v_k$ pour tout $k$ car $v_k$ divise
$\sum_{l \neq k} (c_l -t) v_l' \prod_{j\neq l} v_j$
et $v_k'\prod_{j\neq k} v_j $ est premier avec $v_k$. Donc
le pgcd est 1.
\item si $t$ est égal à l'un des $c_k$, alors le pgcd est le produit
des $v_k$ tels que $c_k=t$ (notons que dans ce cas on peut
rassembler ces $v_k$ à l'intérieur d'un même logarithme)
\end{itemize}
Considérons le polynôme $R$ de la variable $t$ égal au résultant par rapport
à $X$ des polynômes $D$ et $N-tD'$ (rappelons qu'il s'agit du
d\'eterminant du syst\`eme lin\'eaire $AD+B(N-tD')=1$
o\`u les inconnues sont les coefficients des polyn\^omes $A$ et $B$, 
ce d\'eterminant est nul si et seulement si le syst\`eme n'a pas
de solution donc si et seulement si $D$ et $N-tD'$ ne sont pas
premiers entre eux), alors ce polynôme en $t$
s'annule si et seulement si $t=c_k$. 
On cherche les racines $c_k$ en $t$ de ce polynôme,
elles doivent être indépendantes de $x$ si $F$ est élémentaire,
et dans ce cas la primitive $F$ de $f=N/D$ vaut
\[ F=\sum_{c_k \mbox{ racine de } R} c_k \ln(\mbox{gcd}(N-c_k D',D)) \]

{\bf Exemples}
\begin{itemize}
\item
\[ \frac{2x-2}{e^x+1}, \quad D=X+1, D'=e^x=X, \quad N-tD'=2x-2-tX \]
On calcule $R=-2*x-t+2$, l'unique racine est $t=2-2x$ qui n'est
pas constante donc cette fonction n'admet pas de primitive élémentaire.
\item 
\[ \frac{(2x^2-x-2)X-1}{X^2+(x+1)X+x}, \quad X=\exp(x^2+x)\]
On a $D'=2(2x+1)X^2+(1+(2x+1)(x+1))X+1$
\[ R=-(2\*x-1)\*(x+1)\*(2\*x+1)\*(x-1)^2\*(t+1)\*(t-1) \]
les racines en $t$ sont constantes et égales à 1 et -1, donc $c_1=1$
et $v_1=$gcd$(N-D',D)=X+1$ et $c_2=-1$, $v_2=$gcd$(N+D',D)=x+X$
donc~:
\[ \int \frac{(2x^2-x-2)X-1}{X^2+(x+1)X+x} = \ln(X+1)-\ln(x+X)\]
\end{itemize}

{\bf Remarque importante}\\
Pour les extensions exponentielles ou logarithmiques, 
la d\'eriv\'ee de la partie logarithmique
calcul\'ee comme ci-dessus contiendra en g\'en\'eral 
une partie enti\`ere constante par rapport \`a $X$, il faut
donc retirer cette partie enti\`ere \`a la partie polynomiale.

\subsubsection{La partie polynomiale (généralisée)}
On doit résoudre~:
\[ (\sum_j A_j X^j)'=\sum_j a_j X^j \]
avec une somme sur $j \in\Z$ si $X$ est une exponentielle et
$j\in \N$ sinon.

Si $X=x$, $j\geq 0$ et la résolution est immédiate: on prend $A_0=0$ et 
$A_{j+1}=a_{j}/(j+1)$.

\subsubsection{Extension logarithmique}
Si $X=\ln(Y)$ est un logarithme, $j \geq 0$ et on doit résoudre~:
\[ \sum_{j\geq 0} (A_j'+(j+1)A_{j+1} \frac{Y'}{Y}) X^j = \sum_j a_j X^j \]
Soit $k$ la plus grande puissance non nulle de $f$ ($a_j=0$ 
si $j>k$ et $a_k\neq 0$). Pour $j>k$, on a~:
\[ A_j'+(j+1)A_{j+1} \frac{Y'}{Y}  =0 \]
On résout pour des valeurs de $j$ décroissante, pour $j$ suffisamment
grand, on a $A_{j+1}=0$ car la somme sur $j$ est finie, donc $A_j$
est constant. Si $A_j \neq 0$, alors au rang $j-1$, on a 
$A_{j-1} ' = -j A_j Y'/Y $ qui n'admet pas de solutions car 
$A_{j-1}$ ne peut pas dépendre de $X=\ln(Y)$. On en déduit que pour
$j>k+1$, on a $A_j=0$ et $A_{k+1}$ est constant. En fait la
valeur constante de $A_{k+1}$ sera déterminée par une condition
de compatibilité en résolvant l'équation au rang du dessous.
On continue la résolution de 
\[ A_j'+(j+1)A_{j+1} \ln(Y)'  = a_j \]
par valeur décroissante de $j$, à chaque
rang on va déterminer $A_j$ à une constante près en résolvant
un problème d'intégration (par appel récursif de l'algorithme
de Risch, mais si $j \neq 0$ sans autoriser l'ajout de nouveaux 
logarithmes sauf $\ln(Y)$)
et la valeur de la constante de $A_{j+1}$ (on fait varier $A_{j+1}$
de la constante nécessaire pour absorber le terme en $\ln(Y)$
qui apparait lors de l'appel récursif de Risch).
Au rang 0, on est ramené à un problème d'intégration avec
une variable de moins (la constante
indéterminée dans $A_1$ peut par exemple être choisie comme
le coefficient constant de $\ln(Y)$ s'il en apparait un en intégrant).

{\bf Exemple}\\
$X=\ln(x^2+1)$ et on cherche l'intégrale de $X^2$. On a donc $A_3$
est constant,
\[ A_2' + 3 A_3 \ln(x^2+1)' = 1\]
La primitive de 1 est élémentaire et ne fait pas intervenir de $\ln$
donc $A_3=0$ et $A_2=x+C_2$. Au rang 1, on a~:
\[A_1' + 3 x \frac{2x}{x^2+1} + C_2 \ln(x^2+1)' = 0\]
On calcule la primitive de $6x^2/(x^2+1)$ qui doit être une fraction
rationnelle à un $C\ln(x^2+1)$ près, on voit que ce n'est pas le cas
donc $X^2$ n'admet pas de primitive élémentaire.
Remarque: si on avait voulu intégrer $X$ au lieu de $X^2$, la même
méthode montre que la primitive existe, car au rang 0 il n'y
a plus de contraintes sur les $\ln$ qu'on peut rajouter.

\subsubsection{Extension exponentielle}
Si $X=\exp(Y)$ est une exponentielle, on doit résoudre~:
\[ \sum_{j} (A_j'+j Y'A_{j}) X^j = \sum_j a_j X^j \]
Ceci va se faire degré par degré~:
\begin{equation} \label{eq:rischdiffeq}
 A_j'+j Y' A_{j} = a_j
\end{equation}
{\bf Exemple}\\
Pour calculer $\int a(x) \exp(x^2)$, on a $j=1$, et on doit résoudre
l'équation différentielle~:
\[ A_1'+2xA_1= a(x)\]

Pour $j=0$, il suffit de faire un appel récursif à l'algorithme de Risch,
mais pour $j\neq 0$, la situation se complique!
Notons $Z$ la variable situ\'ee juste en-dessous de $X$ dans la tour
de variables (dans l'exemple ci-dessus $Z=x$), il s'agit de r\'esoudre~: 
\begin{equation} \label{eq:rischdiffeq2}
y'+f y=g
\end{equation}
avec $f$, $g$ \'el\'ementaires par rapport \`a une tour dont le
variable au sommet est $Z$, on cherche $y$ \'el\'ementaire par rapport
\`a cette tour (ici $f=jY'$ est une d\'eriv\'ee mais dans certains
cas nous devrons r\'esoudre par appel r\'ecursif des \'equations
du type ci-dessus o\`u $f$ ne sera pas une d\'eriv\'ee).

{\bf \'Elimination des d\'enominateurs}\\
Soit $P$ un facteur irréductible du d\'enominateur de $y$, notons 
$\alpha<0$ la valuation de $y$ par rapport \`a $P$, 
$\beta$ celle de $f$, $\gamma$ celle de $g$. 
Si $P$ n'est pas une exponentielle,
la valuation de $y'$ est $\alpha-1$, celle de $ f y $ est $\alpha +\beta $. 
Si $\beta \neq -1$, 
il n'y a pas de simplification possible dans le membre de gauche
donc $\alpha + \min(\beta,-1) =\gamma$. Autrement dit, si 
$\beta \geq 0$ alors $\alpha=\gamma+1$ et si $\beta<-1$ 
alors $\alpha=\gamma-\beta$.
On observe que $\gamma<0$ donc
$P$ est un facteur du d\'enominateur $g_d$ de $g$. De plus, on va montrer
que la valuation $\alpha$ de $P$ dans $y$ est l'oppos\'e de celle
de $P$ dans~:
\begin{equation} \label{eq:defD}
D=\frac{\mbox{gcd}(g_d,\partial_Z g_d)}{\mbox{gcd}(c,\partial_Z c)}, 
\quad c=\mbox{gcd}(f_d,g_d)
\end{equation}
En effet, si $\beta \geq 0$, $P$ ne divise pas $f_d$ donc ne divise
pas $c$, donc la valuation de $P$ dans $D$ est $-\gamma-1$. Si $\beta < -1$,
alors $\alpha=\gamma - \beta <0$ entraine $-\gamma > -\beta$ donc la
valuation de $P$ dans $c$ est $-\beta$ et la valuation de $P$ dans $D$
est $-\gamma-1 - (-\beta-1)$.

Si $\beta=-1$, s'il n'y a pas de simplifications dans le membre
de gauche pour les termes de plus petite puissance en $P$, alors 
$\alpha=\gamma+1$. S'il y a simplification,
on d\'ecompose en \'el\'ements
simples (avec B\'ezout) puis on ordonne par puissances croissantes
de $P$~:
\[y= N_1 P^\alpha +..., f= N_2 P^{-1}+...,\]
avec $N_1,N_2$ de degré plus petit que $P$, puis on remplace dans 
(\ref{eq:rischdiffeq2}). On cherche les termes de valuation $\alpha-1$
en $P$ qui doivent se simplifier~:
\[ \alpha N_1 P' P^{\alpha-1} + N_2 P^{-1} N_1 P^\alpha =0 \]
donc~:
\[ N_2 = -\alpha P' \]
ce qui d\'etermine $\alpha$.

{\bf Récapitulons}\\
Si $f$ est une dérivée, alors $\beta=-1$ est exclus et on peut
appliquer (\ref{eq:defD}) pour déterminer $D$. Si $f$ n'est
pas une dérivée, on calcule les facteurs de degré 1 de $f_d$~:
\[ f_1=\frac{f_d}{\mbox{gcd}(f_d,\partial_Z f_d)} \]
on décompose $f$ par Bézout en isolant la partie $N/f_1$
les $\alpha$ possibles sont alors les racines entières (en $t$)
du résultant en $Z$ de $N-tf_1'$ et $f_1$, ils correspondent aux
facteurs gcd$(N-\alpha f_1',f_1)$ que l'on retire de $f_d$ pour
appliquer (\ref{eq:defD}).

{\bf Exemple}\\
Reprenons $y'+2xy=a(x)$. Si $a(x)=1$ (résolution de $\int \exp(x^2)$),
ou plus généralement si $a(x)$ est un polynôme,
alors $D=1$. Si $a(x)=1/x^2$, on trouve $D=x$ et on pose $y=xz$,
donc $x^2(xz'+z)+2x^4z=1$ soit $x^3z'+(2x^4+1)z=1$.

Reste le cas o\`u $Z$ est une exponentielle et $P=\exp(z)$. On reprend
le m\^eme raisonnement, $y'$ a pour valuation $-\alpha<0$, $fy$ a pour
valuation $-\beta-\alpha$, donc si $\beta > 0$,
$\alpha=\gamma$ et si $\beta<0$, $\alpha=\gamma-\beta$.
Si $\beta=0$, s'il n'y a pas de simplifications du terme de plus bas
degr\'e, on est ramen\'e au cas pr\'ec\'edent. 
Si $\beta=0$ et s'il y a simplification des termes de plus
bas degr\'e en $Z$, notons $f_0$ le coefficient constant de $f$ 
par rapport \`a $Z$ et $y_{\alpha}$ le coefficient de $Z^{\alpha}$
dans $y$, on a 
\[ y_\alpha ' + (\alpha z' + f_0) y_\alpha =0 \]
donc~:
\[ y_\alpha= \exp(-\alpha z-\int f_0)\]
Comme $y_\alpha$ est \'el\'ementaire et ind\'ependant de $Z$
on en d\'eduit par le th\'eor\`eme de structure de Risch
que $-\alpha z -\int f_0$ est combinaison lin\'eaire \`a coefficients
rationnels des logarithmes et des arguments des exponentielles de la tour,
de plus le coefficient de $z$ doit \^etre nul pour que $y_\alpha$ soit
ind\'ependant de $Z$, ce qui impose la valeur de $\alpha$ (apr\`es avoir
r\'esolu r\'ecursivement le probl\`eme d'int\'egration pour $f_0$)

{\bf Majoration du degr\'e du num\'erateur de $y$}\\
En multipliant $y$ par $D Z^{-\alpha}$, puis en réduisant au
même dénominateur,
on se ram\`ene alors à une équation différentielle à coefficients
polynomiaux par rapport \`a la variable $Z$ dont l'inconnue est un polynôme 
$N$~:
\begin{equation} \label{eq:rischdepol}
 R N' + S N = T
\end{equation}
On va chercher une majoration sur le degr\'e possible de $N$ puis
utiliser l'identit\'e de B\'ezout pour simplifier
cette \'equation. 

On \'ecrit maintenant $N=\sum_{k=0}^n N_k Z^k$ et on remplace, 
il y a \`a nouveau trois cas selon le type de $Z$.

{\bf Si $Z=x$: cas exponentielle rationnelle}\\
Donc $Z'=1$, le degré de $RN'$ est $r+n-1$ (si $N$ est non constant
c'est-à-dire si $T$ n'est pas un multiple de $S$), le degré de
$SN$ est $s+n$. Si $r-1\neq s$, on en déduit que~:
\[ n=t-\max(r-1,s)\]
Si $r-1=s$, on peut avoir
une simplification du terme de plus haut degré $s+n$ (sinon
on est dans le cas précédent) si $n R_r =S_s $
d'où on déduit le degré $n$ de $N$.

Par exemple, pour $y'+2xy=T$ ou pour $x^3z'+(2x^4+1)z=1$ on a $r=s-1$ donc
$n+s=t$, donc pas de solution dans le deuxième cas, dans le premier cas
il ne peut y avoir de solutions que si $t \geq s$, en particulier
il n'y a pas de solution pour $t=1$, on a donc démontré que $\int \exp(x^2)$
n'admet pas de primitive élémentaire.

{\bf Si $Z=\exp(z)$: cas exponentielle d'exponentielle}\\
Ici les $N_k$ peuvent ne pas être constants, on a~:
\[ N'=\sum_{k=0}^n (N_k'+kN_k z') Z^k\]
Comme on l'a déjà observé, $N_n'+n N_n z'\neq 0$, donc le
degré de $N'$ est égal au degré de $N$. On a donc trois cas~:
\begin{itemize} 
\item si $r\neq s$, alors $n=t-\max(r,s)$
\item si $r=s$ et les termes de plus haut degré du membre de gauche ne
se simplifient pas, alors, $n=t-r=t-s$.
\item si $r=s$ et s'il y a simplification, alors~:
\[ R_r(N_n'+nN_nz')+S_sN_n=0 \]
donc~:
\[ N_n' + (\frac{S_s}{R_r}+nz')N_n = 0\]
et~:
\[ N_n = C \exp(-nz-\int \frac{S_s}{R_r}) \]
On appelle alors l'algorithme de Risch avec une variable de moins ($S_s$
et $R_r$ ne dépendent plus de $Z$) pour calculer $I=\int S_s/R_r$. 
Il s'agit alors de trouver $n$ tel que l'exponentielle précédente
soit élémentaire et indépendante de la variable $Z$. Le théorème
de structure de Risch implique que $-nz-\int S_s/R_r$ est combinaison 
linéaire à coefficients rationnels des logarithmes et des arguments 
des exponentielles de autres variables de la tour (jusqu'à $z$ non compris).
Ceci permet de déterminer $n$ de manière unique (c'est le coefficient
rationnel de $\int S_s/R_r$ en $z$).
\end{itemize}

{\bf Si $Z=\ln(z)$: exponentielle de logarithme}\\
Ici aussi, les $N_k$ peuvent ne pas être constants, on a~:
\[ N'=\sum_{k=0}^n (N_k'Z^k+kN_k \frac{z'}{z} Z^{k-1})\]
Si $N_n$ n'est pas constant, le terme de plus haut degré de 
$RN'$ est $N_n' R_r Z^{n+r}$, si $N_n$ est constant, 
le terme de plus haut degré de $RN'$ est $R_r(nN_nz'/z+N_{n-1}') Z^{r-1}$ 
qui est non nul (sinon $z'/z=CN_{n-1}'$ et $z=\exp(CN_{n-1})$ serait 
une exponentielle).
Le terme de plus haut degré de $SN$ est $N_n S_s Z^{n+s}$.
\begin{itemize}
\item Si $r<s$ ou si $r=s$ sans simplifications,
alors $n=t-s$.
\item Si $r>s+1$ ou si $r=s+1$ sans simplifications,
alors deg$(N')=t-r$ donc $n=t-r$ ou $n=t-r+1$.
\item Si $r=s+1$, et s'il y a simplifications, alors $N_n$ est constant et~:
\[ R_r(nN_nz'/z+N_{n-1}')+ S_s N_n = 0 \]
alors $N_{n-1}=C (-\int N_n S_s/R_r -n N_n \ln(z))$
doit être élémentaire et indépendante de $Z$ donc $\int S_s/R_r$
est élémentaire, on détermine $n$ en éliminant le coefficient de 
$Z=\ln(z)$ provenant de $\int S_s/R_r$.
\item Si $r=s$, et s'il y a simplification des termes 
de plus haut degré du membre de gauche, 
alors $N_n' R_r+N_n S_s=0$ donc $N_n=\exp(-\int S_s/R_r)$
est élémentaire et indépendante de $Z$. On peut donc changer
d'inconnue $N=N_n M$ sans changer le fait que $M$ est un polynôme de
même degré que $N$. On se ramène alors à une équation du même type
\[ RM'+(S-R \frac{S_s}{R_r})M= \frac{T}{N_n}\]
mais avec $s$ diminué de 1 au moins.
\end{itemize}

{\bf R\'eduction (algorithme SPDE de Rothstein)}\\
On observe d'abord que si $R$ et $S$ ont un facteur
en commun, alors ce facteur divise $T$ car $N'$ et $N$ sont des polyn\^omes
en $Z$. On peut donc quitte \`a simplifier par gcd$(R,S)$ se ramener
au cas o\`u $R$ et $S$ sont premiers entre eux, il existe donc deux
polyn\^omes $U$ et $V$ tels que~:
\begin{equation} \label{eq:rischdebezout}
RU+SV=T, \quad \mbox{deg}(V)< \mbox{deg}(R)
\end{equation}
En soustrayant (\ref{eq:rischdebezout}) de (\ref{eq:rischdepol}), 
on montre que $R$ divise $N-V$. Soit $H=(N-V)/R$. Alors $N=RH+V$ donc
\[ R (RH'+R'H+V')+SRH+SV= T=RU+SV\]
donc apr\`es simplification par $SV$ et division par $R$, 
$H$ v\'erifie l'\'equation~:
\[ R H' + (S+R') H = U - V'\]
C'est une \'equation du m\^eme type mais avec deg$(H)$=deg$(N)$-deg$(R)$
ou $H=0$ (si $N=V$).
Donc si deg$(R)>0$, au bout d'un nombre fini d'\'etapes on doit 
tomber sur un second membre nul ou des simplifications de $R$ avec $S+R'$
telles que $R$ simplifié soit constant en $Z$.

{\bf R\'esolution}\\
Si $R$ est constant par rapport \`a $Z$, 
on simplifie par $R$ et on doit r\'esoudre 
\[ N'+SN=T \]
Si $S=0$, c'est un probl\`eme d'int\'egration. Supposons donc que
$S\neq 0$. Si $S$ est non constant par rapport \`a $Z$ ou si
$Z=x$, le degr\'e de $N'$ est strictement inf\'erieur 
au degr\'e de $SN$, on peut donc facilement r\'esoudre.
Reste le cas o\`u $S=b$ est constant non nul par rapport \`a $Z$ et $Z$ est
une exponentielle ou un logarithme.

{\bf Si $Z=\exp(z)$}\\
On a alors doit alors r\'esoudre 
\[ N_k'+ k N_k z' + b N_k=T_k \]
c'est une \'equation diff\'erentielle de Risch mais avec une variable de 
moins.

{\bf Si $Z=\ln(z)$}\\
On doit alors r\'esoudre 
\[ N_k'+ (k+1) N_{k+1} \frac{z'}{z} + b N_k =T_k \]
c'est aussi une \'equation diff\'erentielle de Risch avec une
variable de moins.

{\bf Exemple}\\
Voyons comment on intègre $x^n$ avec $n$ un paramètre par l'algorithme
de Risch (cela illustre les possibilités couvertes par l'algorithme
mais aussi l'efficacité des méthodes traditionnelles d'intégration
lorsqu'elles s'appliquent).
On écrit d'abord $x^n=e^{n \ln(x)}$, donc la tour de variables
est $\{ x, Z=\ln(x), X=e^{n \ln(x)}\}$, il s'agit donc d'intégrer
$X$ qui est un polynôme généralisé. On cherche donc $A_1$ solution
de l'équation différentielle de Risch 
\[ A_1'+ n /x A_1=1 \]
Par rapport à $Z=\ln(x)$ la fonction $f=n/x$ est un polynôme, donc on
applique le dernier cas ci-dessus, $A_1$ est aussi indépendant de $\ln(x)$
et on se ramène à résoudre la même équation mais avec comme variable
principale $x$ et non $Z$. Cette fois, il y a un dénominateur $x$ en $f$.
Si $A_1$ possède un dénominateur, il faut qu'il y ait annulation
du terme de plus bas degré en $x$ car le second membre n'a pas de
dénominateur, on obtient $n+\alpha=0$ qui n'a pas de solution, donc
$A_1$ est un polynôme en $x$ et l'équation se réécrit en~:
\[ xA_1'+nA_1=x\]
On majore alors le degré en $x$ de $A_1$ par 1, car il ne peut pas y avoir
d'annulation de terme de plus grand degré. Ensuite, on peut appliquer
l'algorithme SPDE de Rothstein pour réduire le degré, ou ici conclure
à la main, $x$ divise $nA_1$ donc $A_1=Cx$ qu'on remplace et $C=1/(n+1)$.
Finalement, $A_1=x/(n+1)$ et $\int x^n=x/(n+1) \* x^n$.

%\section{Cas des extensions plus générales}

\subsection{Quelques références} \label{sec:rischref}
\begin{itemize}
\item M. Bronstein:\\
Symbolic Integration I, Transcendental functions, Springer

\item M. Bronstein:\\
Integration tutorial, \\
\verb|http://www-sop.inria.fr/cafe/Manuel.Bronstein/publications/mb_papers.html|

\item J.H. Davenport, Y. Siret, E. Tournier:\\
Calcul formel: Syst\`emes et algorithmes 
de manipulations  alg\'ebriques

\item R. Risch: \\
les références des articles originaux de Risch sont dans
le ``Integration tutorial'' de Bronstein.

\item B. Trager:\\
PHD thesis MIT, 1984

\item On peut lire en clair le code source de l'implémentation en MuPAD
(sous Unix, désarchiver le fichier {\tt lib.tar} du répertoire
{\tt /usr/local/MuPAD/share/lib} et regarder dans le sous-répertoire
{\tt lib/INTLIB})

\end{itemize}

\section{Alg\`ebre lin\'eaire}
On présente ici des algorithmes autour de la résolution exacte
de systèmes (réduction des matrices sous forme échelonnée) 
et la recherche de valeurs propres et de vecteurs propres 
(diagonalisation et jordanisation des matrices).

\subsection{R\'esolution de syst\`emes, calcul de d\'eterminant.}

\subsubsection{La m\'ethode du pivot de Gau\ss.}
\begin{itemize}
\item Le pivot~: on détermine à partir d'une ligne $i$ 
la ligne $j$ où apparait le premier coefficient non nul $p$ dans
la colonne à réduire. On échange les lignes
$i$ et $j$. Puis pour $j>i$ (réduction sous-diagonale)
ou $j\neq i$ (réduction complète), on effectue l'opération
$L_j \leftarrow L_j - \frac{p_j}{p}L_i$.\\
Inconv\'enient~: avec des donn\'ees exactes de taille non born\'ee, 
la complexité des coefficients augmente plus vite qu'en choisissant 
le pivot le plus simple possible, (remarque, lorsque les donn\'ees 
sont approch\'ees, on n'utilise pas non plus cette méthode
pour des raisons de stabilit\'e num\'erique).
Le domaine d'utilisation naturel concerne donc les coefficients
dans un corps fini (par exemple $\Z/n\Z$).
\item Le pivot partiel. On choisit le meilleur coefficient non nul de la
colonne, où meilleur dépend du type de coefficient~: avec des données
exactes, on choisirait le coefficient de taille la plus petite possible,
avec des donn\'ees approximatives, on choisit
le coefficient de plus grande norme dans la colonne.
Le domaine d'utilisation naturel concerne les coefficients
approch\'es. Pour les coefficients exacts, on remplacerait la
réduction par $L_j \leftarrow pL_j -p_j L_i$ pour ne pas effectuer
de division. Mais avec cette méthode, la taille des coefficients
augmente de manière exponentielle. On peut améliorer
la taille des coefficients intermédiaires en divisant chaque
ligne par le PGCD de ses coefficients, mais comme pour le
calcul du PGCD par l'algorithme du sous-résultant, il existe
une méthode plus efficace présentée ci-dessous.
\item La m\'ethode de Bareiss~: on initialise un coefficient $b$ \`a 1.
On remplace l'\'etape de r\'eduction ci-dessus
par $L_j \leftarrow (pL_j -p_j L_i)/b$.
\`A la fin de l'\'etape de r\'eduction, on met le coefficient $b$
\`a la valeur du pivot $p$. L'intérêt de la méthode est que la division
se fait sans introduire de fraction (la preuve pour les deux premi\`eres
\'etapes se fait facilement \`a la main ou avec
un système de calcul formel (cf. infra), pour le cas g\'en\'eral, on v\'erifie
que le d\'eterminant de la matrice de d\'epart
est \'egal au dernier coefficient sur la diagonale obtenu par
cette m\'ethode de r\'eduction, ce dernier est donc entier, le
m\^eme raisonnement fait sur des sous-matrices dont on prend les
$k$ premi\`eres lignes et colonnes et une autre ligne et une autre
colonne montre que tous les coefficients des matrices interm\'ediaires
sont entiers).
On peut utiliser cette méthode aussi bien pour la réduction
sous-diagonale que pour la réduction complète (les lignes
intervenant dans la combinaison linéaire subissent des 
modifications identiques dans les deux cas).
\end{itemize}
Montrons avec MuPAD ou xcas en mode mupad (commande \verb|maple_mode(2)|)
qu'en effet, on n'introduit pas de dénominateur dans la méthode
de Bareiss. Sans
restreindre la généralité, il suffit de le montrer avec une
matrice 3x3 \`a coefficients symboliques génériques. 
\begin{verbatim}
pivot:=proc (M,n,m,r) // n ligne du pivot, m colonne, r ligne a modifier
      local col,i,a,b; 
       begin
         col:=ncols(M);
         a:=M[n,m];
         b:=M[r,m];
         for i from 1 to col do
           // print(i,a,b,n,m,r);
           M[r,i]:=a*M[r,i]-b*M[n,i];
         end_for;
         return(M);
       end_proc; /* End of pivot */
A:=matrix(3,3,[[a,b,c],[d,e,f],[g,h,j]]);
A:=pivot(A,1,1,2); A:=pivot(A,1,1,3); /* reduction 1ere colonne */
A:=pivot(A,2,2,3); A:=pivot(A,2,2,1); /* reduction 2eme colonne */
factor(A[3,3]);
\end{verbatim}
Ce qui met bien en évidence le facteur $a$ dans $A_{3,3}$.

\subsubsection{Le d\'eterminant.}
On peut bien sûr appliquer les m\'ethodes ci-dessus en tenant compte
des pivots utilisés et du produit des coefficients diagonaux. Dans le cas de 
la méthode de Bareiss, si on effectue la réduction sous-diagonale
uniquement, il n'est pas nécessaire de garder une trace des pivots
et de calculer le produit des coefficients diagonaux,
montrons que la valeur du d\'eterminant est égal au 
dernier coefficient diagonal~: en effet si $R$ désigne la matrice réduite et
que l'on pose $R_{0,0}=1$, alors la réduction par la méthode de
Bareiss de la colonne $i$ a pour effet de multiplier le déterminant 
de la matrice initiale $M$ par $(R_{i,i}/(R_{i-1,i-1})^{n-i}$. Donc~:
\begin{eqnarray*}
 \mbox{det}(R)&=&\mbox{det}(M) \ \prod_{i=1}^{n-1}
(R_{i,i}/(R_{i-1,i-1})^{n-i} \\
\prod_{i=1}^{n} R_{i,i}&=& \mbox{det}(M) \ \prod_{i=1}^{n-1} R_{i,i}  \\
R_{n,n} &=& \mbox{det}(M)
\end{eqnarray*}

Pour les matrices \`a coefficients entiers, on peut aussi utiliser une
m\'ethode modulaire~: on calcule une borne \`a priori sur le d\'eterminant
et on calcule le d\'eterminant modulo suffisamment de petits nombres
premiers pour le reconstruire par les restes chinois. L'avantage
de cet algorithme est qu'il est facile à paralléliser.

On utilise souvent la borne d'Hadamard sur le d\'eterminant~:
\[ |\det(M)| \leq \prod_{1\leq i \leq n} 
\sqrt{\sum_{1\leq j \leq n} |m_{i,j}|^2}\]
Preuve de la borne~: on majore le déterminant par le produit des
normes des vecteurs colonnes de $M$.

{\bf Remarque}~:\\
Si on veut juste prouver l'inversibilité d'une matrice \`a coefficients
entiers, il suffit
de trouver un nombre premier $p$ tel que le déterminant de cette matrice modulo
$p$ soit non nul.

{\bf Développement par rapport à une ligne ou une colonne}\\
On a tendance à oublier ce type de méthode car le développement
complet du déterminant (faisant intervenir une somme sur toutes les
permutations du groupe symétrique)
nécessite d'effectuer $n!$ produits
de $n$ coefficients et $n!$ additions ce qui est gigantesque. Or on peut
"factoriser" une partie des calculs et se ramener à $n.2^n$ opérations
élémentaires au lieu de $n.n!$. Remarquons aussi que le nombre
d'opérations élémentaires n'a guère de sens si on ne tient pas
compte de la complexité des expressions, l'avantage principal
de la méthode de développement étant d'éviter d'effectuer
des divisions.

{\bf Calcul du déterminant par développement de Laplace}\\
On calcule d'abord tous les mineurs 2x2 des colonnes 1 et 2
que l'on place dans une table de mineurs,
puis on calcule les mineurs 3x3 des colonnes 1 \`a 3 en développant
par rapport à la colonne 3 et en utilisant les mineurs pr\'ec\'edents,
puis les mineurs 4x4 avec les mineurs 3x3, etc.. 
On évite ainsi de recalculer plusieurs fois les mêmes mineurs.
Cf. par exemple l'implémentation en C++ dans giac/xcas
(\verb|www-fourier.ujf-grenoble.fr/~parisse/giac.html|)
qui utilise le type générique \verb|map<>| de la librairie standard C++ (STL)
pour stocker les tables de mineurs (fonction 
\verb|det_minor| du fichier {\tt vecteur.cc}).\\
Nombre d'opérations élémentaires~: il y a $(^n_2)$ mineurs d'ordre 2
à calculer nécessitant chacun 2 multiplications (et 1 addition),
puis $(^n_3)$ mineurs d'ordre 3 nécessitant 3 multiplications et
2 additions, etc. donc le nombre de multiplications est de
$2(^n_2)+3(^n_3)+...+n(^n_n)$, celui d'additions est
$(^n_2)+2(^n_3)+...+(n-1)(^n_n)$ soit un nombre d'opérations
élémentaires majoré par $n.2^n$.

On observe "expérimentalement" que cet algorithme est intéressant
lorsque le nombre de
paramètres dans le déterminant est grand et que la matrice est
plutôt creuse (majorité de coefficients nuls). Il existe des
heuristiques de permutation des lignes ou des colonnes visant
à optimiser la position des zéros (par exemple, les auteurs de GiNaC
(\verb|www.ginac.de|) suite à des expérimentations
privilégient la simplification des petits mineurs en mettant les colonnes 
contenant le maximum de z\'eros \`a gauche selon la description faite
ici). 

Pour se convaincre de l'int\'er\^et de cet algorithme, on peut effectuer
le test O1 de Lewis-Wester\\
\verb|http://www.bway.net/~lewis/calatex.html|\\
il s'agit de calculer un d\'eterminant de taille 15 avec 18 param\`etres.

\subsubsection{Syst\`emes lin\'eaires}
On peut appliquer la m\'ethode du pivot de Gau\ss\ ou les r\`egles
de Cramer. Pour les syst\`emes \`a coefficients entiers non singuliers, 
on peut aussi utiliser une m\'ethode $p$-adique asymptotiquement
plus efficace. On calcule d'abord une borne sur les
coefficients des fractions solutions de l'\'equation $Ax=b$
en utilisant les règles de Cramer et la borne d'Hadamard.
On calcule ensuite $C$, l'inverse de $A$ modulo $p$ (en changeant de $p$ si
$A$ n'est pas inversible modulo $p$), puis, si
\[ x=\sum_i x_i p^i, \quad A(\sum_{i<k} x_i p^i)=b \pmod{p^k} \]
on ajoute $x_k p^k $ et on obtient l'\'equation~:
\[ Ax_k = \frac{b-\sum_{i <k}  x_i p^i}{p^k} \pmod p \]
qui d\'etermine $x_k$.
On s'arr\^ete lorsque $k$ est suffisamment grand pour pouvoir reconstruire
les fractions \`a l'aide de l'identité de B\'ezout (cf. l'appendice),
ce qui est le cas si $p^k$ est
sup\'erieur \`a 4 fois la borne de Hadamard de $A$ au carr\'e.
Pour \'eviter de recalculer plusieurs fois $b-\sum_{i <k}  x_i p^i$,
on utilise la r\'ecurrence suivante
\[ y_0=b, \quad x_{k}=Cy_k \pmod p, \quad y_{k+1} =
\frac{y_k-Ax_{k}}{p}\]
Pour une matrice de taille $n$, il faut $O(n^3)$ op\'erations
pour calculer $C$, puis $kn^2 \ln(n)$ op\'erations 
pour calculer $x_k$ (le terme $\n(n)$ 
vient de la taille des coefficients
de $y_k$ dans le produit $Cy_k$),
donc pour pouvoir reconstruire $x$, il faut prendre $k$ de l'ordre
de $n\ln(n)$, ce qui n\'ecessite finalement $O(n^3\ln(n)^2)$ op\'erations.

{\bf Application au calcul de d\'eterminant de matrices 
\`a coefficient entiers}\\
Cette m\'ethode $p$-adique peut servir \`a acc\'el\'erer le calcul du
d\'eterminant d'une matrice \`a coefficients entiers de grande taille.
En effet, le PPCM $f$ des d\'enominateurs des composantes de $x$ est
un diviseur du d\'eterminant, et si $b$ est choisi avec des
coefficients al\'eatoires, on a une forte probabilit\'e d'obtenir
le dernier facteur invariant de la matrice $A$. Comme le d\'eterminant
de $A$ a une tr\`es faible probabilit\'e de contenir un gros facteur
carr\'e, ce dernier facteur invariant est tr\`es proche du
d\'eterminant. Ce dernier est pour une matrice $A$ al\'eatoire
lui-m\^eme \`a un facteur de l'ordre de $(2/\pi)^n$ proche
de la borne de Hadamard. Il suffit donc de tr\`es peu de nombres
premiers pour d\'eterminer det$(A)/f$ par le th\'eor\`eme
des restes chinois. En pratique pour des $n$ de l'ordre de 100
\`a 1000, cet algorithme est plus rapide que le calcul uniquement
par les restes chinois. Pour des $n$ plus grands, il faut se
rabattre sur des algorithmes probabilistes avec arr\^et pr\'ematur\'e
pour \^etre plus rapide (on s'arr\^ete lorsque le d\'eterminant
n'\'evolue plus par reconstruction par les restes chinois 
pour plusieurs nombres premiers successifs), 
et \'egalement utiliser des m\'ethodes
d'inversion ou de r\'eduction de type Strassen.

\subsubsection{Base du noyau}
On commence bien sûr par réduire la matrice (réduction complète
en-dehors de la diagonale), et on divise chaque ligne par son
premier coefficient non nul (appelé pivot). On insère alors
des lignes de 0 pour que les pivots (non nuls) se trouvent
sur la diagonale. Puis en fin de matrice, on ajoute ou on supprime des 
lignes de 0 pour avoir une matrice carrée de dimension le nombre de colonnes
de la matrice de départ.
On parcourt alors la matrice en diagonale. Si
le $i$-ième coefficient est non nul, on passe au suivant. 
S'il est nul, alors tous
les coefficients d'indice supérieur ou égal à $i$ du $i$-ième
vecteur colonne $v_i$ sont nuls (mais pas forcément pour les indices
inférieurs à $i$). Si on remplace le $i$-ième coefficient de $v_i$
par -1, il est facile de se convaincre que c'est un vecteur du noyau,
on le rajoute donc à la base du noyau. On voit facilement
que tous les vecteurs de ce type forment une famille libre de
la bonne taille, c'est donc bien une base du noyau.

\subsection{R\'eduction des endomorphismes}
\subsubsection{Le polyn\^ome minimal}
On prend un vecteur $v$ au hasard et on calcule la relation lin\'eaire
de degr\'e minimal entre $v$, $Av$, ..., $A^nv$ en cherchant
le premier vecteur $w$ du noyau de la matrice obtenue en écrivant
les vecteurs $v$, $Av$, etc. en colonne dans cet ordre. Les
coordonnées de $w$ donnent alors par ordre de degré croissant
un polynôme $P$ de degr\'e minimal tel que $P(A)v=0$ donc
$P$ divise le polynôme minimal $M$. Donc si $P$ est de
degré $n$, $P=M$. Sinon, il faut v\'erifier que le polynôme obtenu 
annule la matrice $A$. On peut aussi calculer en parallèle le polynôme $P$
précédent pour quelques vecteurs aléatoires et prendre le PPCM des
polynômes obtenus.

{\bf Exemple 1}\\
Polynôme minimal de $\left(\begin{array}{cc} 1 & -1 \\ 2 & 4
\end{array}\right) $. On prend $v=(1,0)$, la matrice à réduire est
alors~:
\[ \left(\begin{array}{ccc} 1 & -1 & -11 \\ 2 & 10 & 38
\end{array}\right) \rightarrow 
\left(\begin{array}{ccc} 1 & 0 & -6 \\ 0 & 1 & 5
\end{array}\right)
\]
Le noyau est engendré par $(-6,5,-1)$ donc $P=-x^2+5x-6$.

{\bf Exemple 2}\\
\[ A=\left(\begin{array}{ccc}
 3 & 2 & -2 \\
-1 &0 &1 \\
1 & 1 & 0 
\end{array}\right) \]
en prenant $v=(1,0,0)$ on obtient la matrice~:
\[ A=\left(\begin{array}{cccc}
1 & 3 & 5 & 7 \\
0 & -1 & -2 & -3 \\
0 & 1 & 2 & 3
\end{array}\right) \rightarrow
\left(\begin{array}{cccc}
1 & 0 & -1 & -2 \\
0 & 1 & 2 & 3 \\
0 & 0 & 0 & 0 
\end{array}\right) \]
le permier vecteur du noyau est $(-1,2,-1)$ d'où un polynôme divisant
le polynôme minimal $-x^2+2x-1$.

\subsubsection{Le polyn\^ome caract\'eristique}
Pour une matrice générique, le polynôme caractéristique est égal
au polynôme minimal, il est donc intéressant de chercher si le polynôme
annulateur de $A$ sur un vecteur aléatoire est de degré $n$, 
car le temps de calcul du polynôme caractéristique est alors en $O(n^3)$. 
Si cette méthode probabiliste échoue, on se
rabat sur une des méthode déterministe ci-dessous:
\begin{itemize}
\item on utilise la formule $\det(\lambda I -A)$ déterminé par
une des m\'ethodes de calcul de d\'eterminant ci-dessus. Cela
nécessite $O(n^3)$ opérations mais avec des coefficients 
polynômes en $\lambda$.
\item on fait une interpolation de Lagrange en donnant $n+1$ valeurs
distinctes \`a $\lambda$. Ce qui nécessite $O(n^4)$ opérations mais avec
des coefficients indépendants de $\lambda$, de plus cette m\'ethode 
est facile \`a programmer de mani\`ere parall\`ele.
\item si la matrice est \`a coefficients entiers
on peut utiliser la m\'ethode de Hessenberg (voir ci-dessous), on calcule
une borne \`a priori sur les coefficients du polyn\^ome caract\'eristique
(cf. Cohen p.58-59)~:
\[ |P_k| \leq \left( \begin{array}{c} n \\ n-k\end{array}\right) 
(n-k)^{(n-k)/2} |M|^{n-k} \ ,\]
on calcule le polyn\^ome caract\'eristique modulo suffisamment
de petits entiers puis on remonte par les restes chinois.
\end{itemize}

\subsubsection{La m\'ethode de Hessenberg}
Pour les matrices \`a coefficients de taille born\'ee (modulaires par exemple)
on préfère la m\'ethode de Hessenberg qui est plus
efficace, car elle n\'ecessite de l'ordre de $n^3$ op\'erations sur
les coefficients.

On se ram\'ene d'abord \`a une matrice triangulaire supérieure à
une diagonale près qui est semblable \`a la
matrice de d\'epart puis on
applique une formule de r\'ecurrence pour calculer les coefficients
du polyn\^ome caract\'eristique.

{\bf Algorithme de réduction de Hessenberg:}\\
Dans une colonne $m$ donnée de la matrice $H$, 
on cherche à partir de la ligne
$m+1$ un coefficient non nul. S'il n'y en a pas on passe à la colonne
suivante. S'il y en a un en ligne $i$, on échange les lignes $m+1$
et $i$ et les colonnes $m+1$ et $i$. Ensuite pour tout $i\geq m+2$,
soit $u=H_{i,m}/H_{m+1,m}$, on remplace alors la ligne $L_i$ de $H$
par $L_i-uL_{m+1}$ et la colonne $C_{m+1}$ par $C_{m+1}+uC_i$
ce qui revient ``à remplacer le vecteur $e_{m+1}$ de la base
par le vecteur $e_{m+1}+ue_i$'' ou plus pr\'ecis\'ement
\`a multiplier \`a gauche par $\left(\begin{array}{cc}
1 & 0 \\ -u & 1\end{array}\right)$ et \`a droite par la matrice inverse
$\left(\begin{array}{cc}
1 & 0 \\ u & 1\end{array}\right)$ (en utilisant les lignes et colonnes
$m+1$ et $i$ au lieu de 1 et 2 pour ces matrices). 
Ceci a pour effet d'annuler le coefficient $H_{i,m}$
dans la nouvelle matrice.

On obtient ainsi en $O(n^3)$ opérations
une matrice $H'$ semblable à $H$ de la forme~:
\[
\left(\begin{array}{cccccc}
H'_{1,1} & H'_{1,2} & ... & H'_{1,n-2} & H'_{1,n-1} & H'_{1,n}\\
H'_{2,1} & H'_{2,2} & ... & H'_{2,n-2} & H'_{2,n-1} & H'_{2,n} \\
0       & H'_{3,2} & ... & H'_{3,n-2} & H'_{3,n-1} & H'_{3,n} \\
0       & 0       & ... & H'_{4,n-2} & H'_{4,n-1} & H'_{4,n} \\
\vdots  & \vdots  & ... & \vdots & \vdots  &  \vdots \\
0       & 0       & ... & 0 & H'_{n,n-1} & H'_{n,n}
\end{array} \right)
\]
On calcule alors le polynôme caractéristique de $H'$ par une récurrence
qui s'obtient en développant le déterminant par rapport à la derni\`ere
colonne~:
\begin{eqnarray*}
 h_n(\lambda) = \mbox{det}(\lambda I_n-H)&=& 
(\lambda-H'_{n,n}) h_{n-1}(\lambda) -(-H'_{n-1,n}) (-H'_{n,n-1}) 
h_{n-2}(\lambda) + \\
& & 
    + (-H'_{n-2,n}) (-H'_{n,n-1}) (-H'_{n-1,n-2}) h_{n-3}(\lambda) - ...
\end{eqnarray*}
où les $h_i$ s'entendent en gardant les $i$ premières lignes/colonnes de $H'$.
On peut \'ecrire cette formule pour $m\leq n$~:
\[ h_m(\lambda)= (\lambda - H'_{m,m}) h_{m-1}(\lambda)
-\sum_{i=1}^{m-1} H'_{m-i,m} \prod_{j=1}^{i-1} H'_{m-j+1,m-j} h_{i-1}(\lambda)\]
Pour effectuer cette r\'ecurrence de mani\`ere efficace, on conserve
les $h_m(\lambda)$ dans un tableau de polyn\^omes et on utilise une 
variable produit contenant successivement les $\prod H'_{m-j+1,m-j}$.

\subsubsection{La m\'ethode de Leverrier-Faddeev-Souriau}
Cette m\'ethode permet le calcul simultan\'e des coefficients 
$p_i \ (i=0..n)$ du polyn\^ome caract\'eristique 
$P(\lambda)=\det(\lambda I-A)$  et des coefficients matriciels
$B_i \ (i=0..n-1)$ du polyn\^ome en $\lambda$ donnant la matrice adjointe
(ou comatrice) $B(\lambda)$ de $\lambda I -A$~:
\begin{equation} \label{eq:Bp}
 (\lambda I -A)B(\lambda)=(\lambda I -A) \sum_{k\leq n-1} B_k \lambda^k
= (\sum_{k\leq n} p_k \lambda^k)I =P(\lambda)I
\end{equation}
Remarquons que cette équation donne une démonstration assez simple
de Cayley-Hamilton puisque le reste de la division euclidienne
du polynôme $P(\lambda)I$ par $\lambda I -A $ est $P(A)$.

Pour déterminer simultanément les $p_k$ et $B_k$,
on a les relations de récurrence~:
\begin{equation}
\label{eq:Bp1} B_{n-1}=p_n I=I, \quad B_k-AB_{k+1}=p_{k+1} I
\end{equation}
Il nous manque une relation entre les $p_k$ et $B_k$ pour pouvoir
faire le calcul par valeurs décroissantes de $k$, on va montrer le~:
\begin{thm}
La d\'eriv\'ee  du polyn\^ome caract\'eristique $P'(\lambda)$,
est \'egale \`a la trace de la matrice adjointe 
de $\lambda I-A$
\[ \mbox{tr}(B)=P'(\lambda) \]
\end{thm}
Le théorème nous donne $\mbox{tr}(B_k) = (k+1)p_{k+1} $.
Si on prend la trace de (\ref{eq:Bp1}), on a~:
\[ \mbox{tr}(B_{n-1})=n p_n, \quad (k+1)p_{k+1} -\mbox{tr}(AB_{k+1})
=np_{k+1} \]
donc on calcule $p_{k+1}$ en fonction de $B_{k+1}$ puis $B_k$~:
\[ p_{k+1}=\frac{\mbox{tr}(AB_{k+1})}{k+1-n}, 
\quad B_k=AB_{k+1}+p_{k+1} I \]
{\bf D\'emonstration du théorème:}\\
Soient $V_1(\lambda),...V_n(\lambda)$ les vecteurs colonnes 
de $\lambda I-A$ et $b_{i,j}(\lambda)$ les coefficients de $B$, on a~:
\begin{eqnarray*}
P'(\lambda_0) &=& \det(V_1(\lambda),V_2(\lambda),...,V_n(\lambda) )'
_{|\lambda=\lambda_0}\\
&=&\det(V'_1(\lambda_0),V_2(\lambda_0),...,V_n(\lambda_0) )+
\det(V_1(\lambda_0),V'_2(\lambda_0),...,V_n(\lambda_0) )+ \\
& & +...+\det(V_1(\lambda_0),V_2(\lambda_0),...,V'_n(\lambda_0) )
\end{eqnarray*}
Il suffit alors de remarquer que
$V'_i(\lambda_0)$ est le $i$-ième vecteur de la base canonique donc~:
\[ \det(V_1(\lambda_0),V_2(\lambda_0),...,V'_i(\lambda_0),...,V_n(\lambda_0) )
=b_{i,i}(\lambda_0) \]
Finalement~:
\[P'(\lambda_0)=\sum_{i=1}^n b_{i,i}(\lambda_0)=\tr(B(\lambda_0)) \]

{\bf Remarque}~:\\
En réindexant les coefficients de $P$ et $B$ de la manière suivante~:
\begin{eqnarray*}
P(\lambda) &=& \lambda^n+p_1\lambda^{n-1}+p_2\lambda^{n-2}...+p_n \\
B(\lambda) &=& \lambda^{n-1}I+\lambda^{n-2}B_1+...+B_{n-1}
\end{eqnarray*}
on a montré que~:
\[ \left\{
\begin{array}{ccc}
A_1=A, & p_1=-\mbox{tr}(A), & B_1=A_1+p_1I \\  
A_2=AB_1, & p_2=-\frac{1}{2}\mbox{tr}(A_2), & B_2=A_2+p_2I \\ 
\vdots & \vdots & \vdots \\
A_k=AB_{k-1}, & p_k=-\frac{1}{k}\mbox{tr}(A_k), & B_k=A_k+p_kI
\end{array}
\right.\]
On peut alors vérifier que $B_n=A_n+p_nI=0$.
D'où ce petit programme à utiliser avec xcas en mode mupad 
(\verb|maple_mode(2);|), ou avec MuPAD, ou à adapter
avec un autre système~:
\begin{verbatim}
iequalj:=(j,k)->if j=k then return(1); else return(0); end_if;
faddeev:=proc(A) // renvoie la liste des matrices B et le polynome P
local Aj,AAj,Id,coef,n,pcara,lmat;
begin
 n:=ncols(A);
 Id:=matrix(n,n,iequalj);     // matrice identite
 Aj:=Id;
 lmat:=[];                    // B initialise a liste vide
 pcara:=[1];                  // coefficient de plus grand degre de P
 for j from 1 to n do
  lmat:=append(lmat,Aj);      // rajoute Aj a la liste de matrices
  AAj:=Aj*A;
  coef:=-trace(AAj)/j;        // mupad linalg::tr
  pcara:=append(pcara,coef);  // rajoute coef au polynome caracteristique
  Aj:=AAj+coef*Id;
 end_for;
 lmat,pcara;                  // resultat
end_proc;
\end{verbatim}

\subsubsection{Les vecteurs propres simples.}
On suppose ici qu'on peut factoriser le polyn\^ome caract\'eristique
(ou calculer dans une extension alg\'ebrique d'un corps).
Lorsqu'on a une valeur propre simple $\lambda_0$, en \'ecrivant
la relation $(A-\lambda_0 I)B(\lambda_0)=P(\lambda_0)I=0$,
on voit que les vecteurs colonnes de la matrice $B(\lambda_0)$
sont vecteurs propres.
Remarquer que $B(\lambda_0) \neq 0$ sinon on pourrait factoriser
$\lambda-\lambda_0$ dans $B(\lambda)$ et apre\`s simplifications on aurait~:
\[(A-\lambda_0 I)\frac{B}{\lambda-\lambda_0}(\lambda_0)=
\frac{P}{\lambda-\lambda_0}(\lambda_0)I \]
or le 2\`eme membre est inversible en $\lambda_0$ ce qui n'est pas le
cas du premier.
Pour avoir une base des vecteurs propres associ\'es \`a $\lambda_0$, on
calcule $B(\lambda_0) $ par la m\'ethode de Horner appliqu\'ee au
polyn\^ome $B(\lambda)$ en $\lambda=\lambda_0$, et on r\'eduit en
colonnes la matrice obtenue.

\subsubsection{La forme normale de Jordan} \label{sec:jordan}
Pour les valeurs propres de multiplicit\'e plus grande que 1, on souhaiterait 
g\'en\'eraliser la m\'ethode ci-dessus pour obtenir une base
de l'espace caractéristique, sous forme de cycles de Jordan.
Soit $\lambda _i$, $n_i$ les valeurs propres compt\'ees avec leur 
multiplicit\'e. On fait un d\'eveloppement de Taylor en
$\lambda _i$:
\begin{eqnarray*} 
-P(\lambda )I&=&(A-\lambda I)\left(
B(\lambda_i )+ B'(\lambda _i)(\lambda -\lambda _i)
% + ... + \frac{B^{(n_i)}(\lambda_i )}{n_i!} (\lambda -\lambda _i)^{n_i}
+ ... +  \frac{B^{(n-1)}(\lambda_i )}{(n-1)!} 
(\lambda -\lambda _i)^{n-1} \right) \\
&=& -(\lambda -\lambda _i)^{n_i}
\prod _{j\neq i} (\lambda -\lambda _j)^{n_j} I 
\end{eqnarray*}
Comme $A-\lambda I=A-\lambda _i I - (\lambda -\lambda _i)I$, on obtient
pour les $n_i$ premi\`eres puissances de $\lambda -\lambda _i$:
\begin{eqnarray} \label{eq:jordan1}
(A-\lambda _i I) B(\lambda _i)&=&0\\
(A-\lambda _i I) B'(\lambda _i)&=&B(\lambda_i )\\
& ... & \\
(A-\lambda _i I) \frac{B^{(n_i-1)}(\lambda _i)}{(n_i-1)!} &=& 
\frac{B^{(n_i-2)}(\lambda _i)}{(n_i-2)!} \label{eq:jordan3} \\
(A-\lambda _i I)\frac{B^{(n_i)}(\lambda_i)}{n_i!} -  
\frac{B^{(n_i-1)}(\lambda_i)}{(n_i-1)!}
&= &-\prod_{j\neq i}(\lambda _i-\lambda _j)^{n_j} I \label{eq:jordan4}
\end{eqnarray}
Le calcul des matrices $B^{(n)}(\lambda _i)/n!$ pour $n<n_i$ se fait en
appliquant $n_i$ fois l'algorithme de Horner (avec reste).

\begin{thm} \label{th:jordan}
L'espace caract\'eristique de $\lambda _i$ est égal à
l'image de $B^{(n_i-1)}(\lambda _i)/(n_i-1)!$.
\end{thm}
{\bf Preuve~:}\\
On montre d'abord que Im$B^{(n_i-1)}(\lambda _i)/(n_i-1)!$ est inclus
dans l'espace caractéristique correspondant à $\lambda_i$ en
appliquant l'\'equation (\ref{eq:jordan3}) et les \'equations précédentes.
Réciproquement on veut prouver que tout vecteur caract\'eristique $v$ est dans 
l'image de $B^{(n_i-1)}(\lambda _i)/(n_i-1)!$. Prouvons le par r\'ecurrence
sur le plus petit entier $m$ tel que
$(A-\lambda _i)^{m}v=0$. Le cas $m=0$ est clair puisque $v=0$.
Supposons le cas $m$ vrai, prouvons le cas $m+1$. On applique l'\'equation
(\ref{eq:jordan4}) \`a $v$, il suffit alors de prouver que
\[ w=(A-\lambda _i)\frac{B^{(n_i)}(\lambda_i)}{n_i!} v\]
appartient \`a l'image de
$B^{(n_i-1)}(\lambda _i)/(n_i-1)!$.
Comme $B^{(n_i)}(\lambda_i)$
commute avec $A$ (car c'est un polyn\^ome en $A$ ou en appliquant
le fait que $B(\lambda)$ inverse de $A-\lambda I$):
\[ (A-\lambda _i)^m w=\frac{B^{(n_i)}(\lambda_i)}{n_i!} 
(A-\lambda _i)^{m+1}v=0 \]
et on applique l'hypoth\`ese de r\'ecurrence \`a $w$.

Pour calculer les cycles de Jordan, nous allons effectuer une
r\'eduction par le pivot de Gau\ss\ simultan\'ement sur les colonnes
des matrices $B^{(k)}(\lambda _i)/k!$ o\`u $k<n_i$. 
La simultan\'eit\'e a pour but de conserver les
relations (\ref{eq:jordan1}) \`a (\ref{eq:jordan3}) pour les matrices
r\'eduites. Pour visualiser l'algorithme, on se repr\'esente les
matrices les unes au-dessus des autres, colonnes align\'ees.
On commence par r\'eduire la matrice $B(\lambda _i)$ jusqu'\`a ce
que l'on obtienne une matrice r\'eduite {\bf en recopiant} les op\'erations
\'el\'ementaires de colonnes faites sur $B(\lambda _i)$ sur toutes les matrices
$B^{(k)}(\lambda _i)/k!$. On va continuer avec la liste des matrices
r\'eduites issues de $B'(\lambda _i)$, ..., 
$B^{(n_i-1)}(\lambda _i)/(n_i-1)!$, 
mais en d\'eplacant les colonnes non nulles de $B(\lambda _i)$ 
d'une matrice vers le bas
(pour une colonne non nulle de la matrice r\'eduite $B(\lambda )$
les colonnes correspondantes de $B^{(k)}(\lambda _i)$ r\'eduite 
sont remplac\'ees par les colonnes correspondantes de $B^{(k-1)}(\lambda _i)$
r\'eduite pour $k$ d\'ecroissant de $n_i-1$ vers 1).
\`A chaque \'etape, on obtient une famille (\'eventuellement vide)
de cycles de Jordan, ce sont les vecteurs colonnes correspondants 
aux colonnes non nulles de la matrice r\'eduite du haut de la colonne.
On \'elimine bien s\^ur les colonnes correspondant aux fins de cycles
d\'ej\`a trouv\'es.

Par exemple, si $B(\lambda _i)\neq 0$, son rang est 1 et on a
une colonne non nulle, et un cycle de Jordan de longueur
$n_i$ fait des $n_i$ vecteurs colonnes des matrices
$B^{(k)}(\lambda _i)/k!$ r\'eduites. 
Plus g\'en\'eralement, on obtiendra plus qu'un cycle de Jordan
(et dans ce cas $B(\lambda _i)= 0$).


\subsubsection{Exemple 1} \label{sec:ex1}

\[ A=\left(\begin{array}{ccc}
 3 & -1 & 1 \\
2 &0 &1 \\
1 & -1 & 2 
\end{array}\right) \]
$\lambda =2$ est valeur propre de multiplicit\'e 2, on obtient~:
\[ B(\lambda )= \lambda ^2 I + \lambda \left(\begin{array}{ccc}
 -2 & -1 & 1 \\
2 & -5 &1 \\
1 & -1 & -3 
\end{array}\right) 
+ \left(\begin{array}{ccc}
 1 & 1 & -1 \\
-3 & 5 &-1 \\
-2 & 2 & 2 
\end{array}\right) \]
on applique l'algorithme de Horner~:
\begin{eqnarray*} 
B(2)&=&\left(\begin{array}{ccc}
 1 & -1 & 1 \\
1& -1 &1 \\
0 & 0 & 0 
\end{array}\right) ,\\
B'(2)&=&\left(\begin{array}{ccc}
 2 & -1 & 1 \\
2 & -1 &1 \\
1 & -1 & 1 
\end{array}\right) 
\end{eqnarray*}
Comme $B(2)\neq 0$, on pourrait arr\^eter les calculs en utilisant
une colonne non nulle et le cycle de Jordan associ\'e
$(2,2,1)\rightarrow (1,1,0) \rightarrow (0,0,0) $. Expliquons tout
de m\^eme l'algorithme g\'en\'eral sur cet exemple. La r\'eduction
de $B(2)$ s'obtient en effectuant les manipulations de colonnes
$C_2+C_1 \rightarrow C_2$ et $C_3-C_1 \rightarrow C_3$. 
On effectue les m\^emes op\'erations sur $B'(2)$ 
et on obtient~:
\begin{eqnarray*} \left(\begin{array}{ccc}
 1 & 0 & 0 \\
1& 0 &0 \\
0 & 0 & 0 
\end{array}\right), \\
\left(\begin{array}{ccc}
 2 & 1 & -1 \\
2 & 1 & -1\\
1 & 0 & 0 
\end{array}\right)
\end{eqnarray*}
L'\'etape suivante consiste \`a d\'eplacer vers le bas d'une matrice les
colonnes non nulles de la matrice du haut, on obtient~:
\[ \left(\begin{array}{ccc}
 1 & 1 & -1 \\
1 & 1 & -1\\
0 & 0 & 0 
\end{array}\right) \]
qui se r\'eduit en~:
\[ \left(\begin{array}{ccc}
 1 & 0 & 0 \\
1 & 0 & 0\\
0 & 0 & 0 
\end{array}\right) \]
on chercherait alors dans les colonnes 2 et 3 de nouveaux cycles (puisque
la colonne 1 a d\'eja \'et\'e utilis\'ee pour fournir un cycle).

\subsubsection{Exemple 2} \label{sec:ex2}
\[ A=\left(\begin{array}{ccc}
 3 & 2 & -2 \\
-1 &0 &1 \\
1 & 1 & 0 
\end{array}\right) \]
$\lambda =1$ est valeur propre de multiplicit\'e 3.
On trouve~:
\begin{eqnarray*}
B(1)&=&
\left(\begin{array}{ccc}
0 & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & 0 
\end{array}\right), \\
B'(1)&=&\left(\begin{array}{ccc}
2 & 2&-2 \\
-1 & -1 & 1 \\
1 & 1 & -1 
\end{array}\right), \\
\frac{ B'{'}(1)}{2}
&=& \left(\begin{array}{ccc}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1 
\end{array}\right)
\end{eqnarray*}
Le processus de r\'eduction commence avec $B'(1)$ en haut de la liste
de matrices, on effectue les op\'erations \'el\'ementaires de
colonne $C_2-C_1\rightarrow C_2$
et $C_3+C_1 \rightarrow C_3$ et on obtient:
\begin{eqnarray*}
\left(\begin{array}{ccc}
2 & 0&0 \\
-1 & 0 & 0 \\
1 & 0 & 0 
\end{array}\right), \\
 \left(\begin{array}{ccc}
1 & -1 & 1 \\
0 & 1 & 0 \\
0 & 0 & 1 
\end{array}\right)
\end{eqnarray*}
La premi\`ere colonne donne le premier cycle de Jordan
 $(1,0,0) \rightarrow (2,-1,1)$.
On d\'eplace les premi\`eres colonnes d'une matrice vers le bas~:
\[ \left(\begin{array}{ccc}
2 & -1 & 1 \\
-1 & 1 & 0 \\
1 & 0 & 1 
\end{array}\right) \]
qu'on r\'eduit par les op\'erations $2C_2 +C_1 \rightarrow C_2$ et
$2C_3-C_1\rightarrow C_3$ en~:
\[ \left(\begin{array}{ccc}
2 & 0 & 0 \\
-1 & 1 & 1 \\
1 & 1 & 1 
\end{array}\right) \]
Puis on effectue $C_3-C_2 \rightarrow C_3$ et la deuxi\`eme colonne
nous donne le deuxi\`eme cycle de Jordan, r\'eduit ici \`a un
seul vecteur propre $(0,1,1)$.

\subsubsection{Le polyn\^ome minimal par Faddeev}
On v\'erifie ais\'ement que le degr\'e du facteur 
$(\lambda-\lambda_i)$ dans le polyn\^ome minimal de $A$ est \'egal
\`a $n_i-k$ o\`u $k$ est le plus grand entier tel que~:
\[ \forall j<k, \quad B^{(j)}(\lambda_i)=0 \]

\subsubsection{Formes normales rationnelles}
On se place ici dans une probl\'ematique diff\'erente~: trouver une matrice
semblable la plus simple possible sans avoir \`a introduire d'extension
alg\'ebrique pour factoriser le polyn\^ome caract\'eristique.
Quitte \`a ``compl\'eter'' plus tard la factorisation et la jordanisation \`a
partir de la forme simplifi\'ee. Il existe diverses formes associées
à une matrice et plusieurs algorithmes permettant de les relier entre elles,
forme de Smith, de Frobenius, forme normale de Jordan rationnelle.

On va pr\'esenter une m\'ethode directe de calcul d'une forme normale
contenant le maximum de z\'eros (dont la forme dite normale de Jordan
rationnelle peut se d\'eduire) en utilisant le m\^eme algorithme que pour 
la forme
normale de Jordan. Soit $Q(\lambda)=q_0+...+q_d \lambda^d$ 
un facteur irr\'eductible
de degr\'e $d$ et de multiplicit\'e $q$ 
du polyn\^ome caract\'eristique $P$. Il
s'agit de construire un sous-espace de dimension $dq$ form\'e de ``cycles
de Jordan rationnels''.
On part toujours de la relation 
$(\lambda I -A) \sum_{k\leq n-1} B_k \lambda^k=P(\lambda)I$.
On observe que $Q(\lambda)I-Q(A)$ est divisible par $(\lambda I -A) $
donc il existe une matrice $M(\lambda)$ telle que~:
\[ (Q(\lambda) I -Q(A)) (\sum_{k\leq n-1} B_k \lambda^k)
=Q(\lambda)^q M(\lambda) \]
On observe aussi que $Q$ a pour coefficient dominant 1 puisqu'il divise
$P$, on peut donc effectuer des divisions euclidiennes de polyn\^omes
donc de polyn\^omes \`a coefficients matriciels par $Q$ sans avoir
\`a diviser des coefficients. Ce qui nous
permet de d\'ecomposer $B(\lambda)=\sum_{k\leq n-1} B_k \lambda^k$ en 
puissances croissantes de $Q$~:
\[ B(\lambda)=\sum_k C_k(\lambda) Q(\lambda)^k, \quad \mbox{deg}(C_k)<q \]
On remplace et on \'ecrit que les coefficients des puissances inf\'erieures
\`a $q$ de $Q$ sont nulles (la $k$-i\`eme \'etant non nulle
car $M(\lambda)$ n'est pas divisible par $Q$ pour les m\^emes raisons
que pour la forme normale de Jordan). On a donc les relations~:
\[ Q(A)C_0 = 0, \quad C_k = Q(A) C_{k+1} \]
ce qui donne une colonne de matrice 
$C_{q-1} \rightarrow C_{q-2} ... \rightarrow C_0 \rightarrow 0$
qui sont images l'une de l'autre en appliquant $Q(A)$. On peut alors
faire l'algorithme de r\'eduction simultan\'ee sur les colonnes des $C_j$. 
On observe
ensuite que le nombre de cycles de Jordan de $Q(A)$ de longueur donn\'ee 
est un multiple de $d$, en effet il suffit de multiplier
un cycle par $A$, ..., $A^{d-1}$ pour cr\'eer un autre cycle, de plus ces
cycles forment des familles libres car on a suppos\'e $Q$ irr\'eductible.
On peut donc choisir pour un cycle de longueur $k$ des bases de la forme
$(v_{k-1},Av_{k-1}...,A^{d-1}v_{k-1}) \rightarrow ... 
\rightarrow (v_{0},Av_{0}...,A^{d-1}v_{0}) \rightarrow (0,...,0) $
o\`u la fl\`eche $\rightarrow$ d\'esigne l'image par $Q(A)$.
Si on \'ecrit la matrice de $A$ dans la base 
$v_{0},Av_{0}...,A^{d-1}v_{0},...,v_{k-1},Av_{k-1}...,A^{d-1}v_{k-1}$
on obtient un ``quasi-bloc de Jordan rationnel'' de taille $kd$ 
multiple de $d$~:
\[ 
\left( \begin{array}{cccccccccc}
0 & 0 & ... & -q_0 &             \ & 0 & 0 & ... & 1 & ... \\
1 & 0 & ... & -q_1 &             \ & 0 & 0 & ... & 0 & ...\\
0 & 1 & ... & -q_2 &             \ & 0 & 0 & ... & 0 & ...\\
\vdots & \vdots & ... & \vdots & \ & \vdots & \vdots & ... & \vdots & ...\\
0 & 0 & ... & -q_{d-1} &         \ & 0 & 0 & ... & 0 & ... \\ 
\\
0 & 0 & ... & 0   &              \ & 0 & 0 & ... & -q_{0} & ... \\
0 & 0 & ... & 0   &              \ & 1 & 0 & ... & -q_{1} & ... \\
\vdots & \vdots & ... & \vdots & \ & \vdots & \vdots & ... & \vdots & ...
\end{array}
\right)
\]

{\bf Exemple}\\
Soit la matrice
\[ A=\left(\begin{array}{cccccc}
1 & -2 & 4 & -2 & 5 & -4 \\
0 & 1 & \frac{5}{2} & \frac{-7}{2} & 2 & \frac{-5}{2} \\
1 & \frac{-5}{2} & 2 & \frac{-1}{2} & \frac{5}{2} & -3 \\
0 & -1 & \frac{9}{2} & \frac{-7}{2} & 3 & \frac{-7}{2} \\
0 & 0 & 2 & -2 & 3 & -1 \\
1 & \frac{-3}{2} & \frac{-1}{2} & 1 & \frac{3}{2} & \frac{1}{2}
\end{array}\right) \]
Son polyn\^ome caract\'eristique est $(x-2)^2(x^2-2)^2$ et on va d\'eterminer
la partie bloc de Jordan rationnel correspondant au facteur irr\'eductible
sur les entiers $Q(x)=(x^2-2)$ de multiplicit\'e $q=2$. 
On calcule $B(x)$ et l'\'ecriture de $B$ comme
somme de puissances de $Q$ (ici avec \verb|xcas| en mode \verb|xcas|)~:
\begin{verbatim}
A:=[[1,-2,4,-2,5,-4],[0,1,5/2,(-7)/2,2,(-5)/2],[1,(-5)/2,2,1/(-2),5/2,-3],
    [0,-1,9/2,(-7)/2,3,(-7)/2],[0,0,2,-2,3,-1],[1,(-3)/2,1/(-2),1,3/2,1/2]];
P:=det(A-x*idn(6));
B:=normal(P*inv(A-x*idn(6))); // preferer un appel a faddeev bien sur!
ecriture(B,Q,q):={
  local j,k,l,n,C,D,E;
  C:=B;
  D:=B;
  E:=NULL;
  n:=coldim(B);
  for (j:=0;j<q;j++){ 
    for (k:=0;k<n;k++){
      for (l:=0;l<n;l++){
        D[k,l]:=rem(C[k,l],Q,x);
        C[k,l]:=quo(C[k,l],Q,x);
      }
    }
    E:=E,D;
  }
  return E;
};
E:=ecriture(B,x^2-2,2);
QA:=A*A-2*idn(6);
\end{verbatim}
On v\'erifie bien que \verb|normal(QA*E(0))| et
\verb|normal(QA*E(1))-E(0))| sont nuls. On sait qu'on a un bloc de
taille 2 de cycles de Jordan de longueur 2, donc il n'est pas n\'ecessaire
de faire des r\'eductions ici, il suffit de prendre une colonne non nulle
de $E(0)$, par exemple la première colonne en $x=0$
et la colonne correspondante de $E(1)$ et leurs images par $A$, ici
cela donne $(4,24,12,32,8,-4)$ correspondant \`a $(0,4,-4,8,4,-4)$,
on calcule les images par $A$, la matrice de l'endomorphisme
restreint à ce sous-espace est alors le bloc de taille 4~:
\[ \left( \begin{array}{cccc}
0 & 2 & 0 & 1 \\
1 & 0 & 0 & 0 \\
0 & 0 & 0 & 2 \\
0 & 0 & 1 & 0
\end{array} \right) \]

Cette forme normale minimise le nombre de coefficients non nuls,
mais présente un inconvénient, la partie nilpotente ne commute pas
avec la partie bloc-diagonale, contrairement à la forme normale
rationnelle de Jordan qui contient des blocs identités au-dessus
de la diagonale de blocs.
Pour créer la forme normale rationnelle de Jordan, on doit donc remplacer
les blocs $\left( \begin{array}{ccc} ... & 0 & 1 \\ ... & 0 & 0 
\\ ... \end{array} \right)$
par des matrices identit\'es. Supposons constitués les $j$ premiers blocs de
taille $d$ numérotés de 0 à $j-1$ avec comme base de vecteurs
$(v_{0,0},...,v_{0,d-1},...,v_{j-1,d-1})$. 
Il s'agit de trouver un vecteur $v_{j,0}$ pour commencer le bloc
suivant. On définit alors $v_{j,l}$ en fonction de $v_{j,l-1}$
en appliquant la relation $Av_{j,l-1}=v_{j,l}+v_{j-1,l-1}$.
Il faut donc chercher $v_{j,0}$ tel que 
\begin{equation} \label{eq:jordanrat1}
 Av_{j,d-1}=-q_0 v_{j,0}-...-q_{d-1} v_{j,d-1}+v_{j-1,d-1} 
\end{equation}
En utilisant les relations de récurrence précédentes, on voit que
cela revient à fixer $Q(A)v_{j,0}$ en fonction des $v_{j',l}$ avec
$j'<j$ ($l$ quelconque). Ce qui est toujours possible en utilisant
la colonne de matrices $C_{j'}$ qui s'obtiennent en
fonction des $C_{j'+1}$ en appliquant $Q(A)$.

Plus pr\'ecis\'ement, calculons les $v_{j,l}$ en fonction de $v_{j,0}$
et des $v_{j',l'}$ ($j'<j$). On utilise les coefficients binomiaux 
$\left( ^l_m\right)$ calcul\'es par la r\`egle du triangle de Pascal et
on montre par r\'ecurrence que~:
\begin{equation} \label{eq:jordanrat3}
v_{j,l} = A^l v_{j,0} - \sum_{m=1}^{\mbox{\small inf}(l,j)} 
\left( ^l _m\right) v_{j-m,l-m}
\end{equation}
On remplace dans (\ref{eq:jordanrat1}) d'o\`u~:
\[ A^d v_{j,0} - \sum_{m=1}^{\mbox{\small inf}(d,j)} 
\left( ^d _m\right)v_{j-m,l-m}
+ \sum_{l=0}^d 
q_l (A^l v_{j,0} - \sum_{m=1}^{\mbox{\small inf}(l,j)} \left( ^l _m\right) 
v_{j-m,l-m} )=0
\]
finalement~:
\begin{equation} \label{eq:jordanrat}
 Q(A) v_{j,0}= \sum_{l=1}^d 
q_l \sum_{m=1}^{\mbox{\small inf}(l,j)} \left( ^l _m\right) v_{j-m,l-m} 
\end{equation}

{\bf Application \`a l'exemple~:}\\
Ici $v_{0,0}=(4,24,12,32,8,-4)$ et $v_{0,1}=Av_{j,0}$ dont une pr\'eimage
par $Q(A)$ est $w_{1,0}=(0,4,-4,8,4,-4)$ et $w_{1,1}=Aw_{1,0}$.
On applique (\ref{eq:jordanrat}), comme $q_1=0$ et $q_2=1$
on doit avoir~:
\[ Q(A) v_{1,0} = \sum_{l=1}^2
q_l \sum_{m=1}^{\mbox{\small inf}(l,1)} \left( ^l _m\right) v_{1-m,l-m} 
 =2v_{0,1} \]
donc ~:
\[\begin{array}{ccccc}
 v_{1,0}&=&2A(0,4,-4,8,4,-4)&=&(-8,-32,0,-48,-16,16) \\
 v_{1,1}&=&Av_{1,0}-v_{0,0}&=&(4,40,-4,64,24,-20) 
\end{array}
\]
On v\'erifie bien que $Av_{1,1}=2v_{1,0}+v_{0,1}$.

\subsubsection{Fonctions analytiques}
Soit $f$ une fonction analytique et $M$ une matrice. Pour calculer
$f(M)$, on calcule la forme normale de Jordan de 
$M=P(D+N)P^{-1}$ o\`u $D=$diag$(d_1,...,d_m)$ est diagonale et $N$ nilpotente
d'ordre $n$. On calcule
aussi le d\'eveloppement de Taylor formel de $f$ en $x$ \`a l'ordre
$n-1$, on a alors~:
\[ f(N)=P \left(\sum_{j=0}^{n-1} \frac{\mbox{diag}(f^{(j)}(d_1),...,
f^{(j)}(d_m))}{j!} N^j \right) P^{-1}\]

\subsection{Quelques autres algorithmes utiles}
Pour calculer le produit de matrices, on peut utiliser
l'algorithme de Strassen, on pr\'esente ici la variante
de Winograd. Soit \`a calculer~:
\[ \left(\begin{array}{cc} a_{1,1} & a_{1,2} \\
a_{2,1} & a_{2,2} \end{array}\right) 
\left(\begin{array}{cc} b_{1,1} & b_{1,2} \\
b_{2,1} & b_{2,2} \end{array}\right)
=\left(\begin{array}{cc} c_{1,1} & c_{1,2} \\
c_{2,1} & c_{2,2} \end{array}\right)
\]
On calcule~:
\begin{eqnarray*} 
s_1=a_{2,1}+a_{2,2}, \quad s_2=s_1-a_{1,1}, \quad 
s_3=a_{1,1}- a_{2,1}, \quad s_4=a_{1,2}-s_2
\\
t_1=b_{1,2}-b_{1,1}, \quad t_2=b_{2,2}-t_1,
\quad t_3=b_{2,2}-b_{1,2}, \quad t_4=b_{2,1}-t_2
\end{eqnarray*}
puis~:
\begin{eqnarray*}
 p_1=a_{1,1} b_{1,1}, \quad
p_2=a_{1,2}b_{2,1}, \quad
p_3=s_1 t_1, \quad p_4=s_2 t_2 \\
p_5=s_3 t_3, \quad p_6=s_4 b_{2,2},
\quad p_7=a_{2,2} t_4 \\
u_1= p_1+p_2 \quad u_2=p_1+p_4,
\quad u_3=u_2+p_5, \quad u_4=u_3+p_7\\
u_5=u_3+p_3, \quad
u_6=u_2+p_3, \quad u_7=u_6+p_6
\end{eqnarray*}
Alors $c_{1,1}=u_1, c_{1,2}=u_7, c_{2,1}=u_4, c_{2,2}=u_5$.\\
Cet algorithme utilise 7 multiplications et 15 additions
ce qui \'economise 1 multiplication et permet en appliquant
r\'ecursivement cet algorithme pour des matrices blocs
de r\'eduire la complexit\'e d'un produit de grandes matrices
normalement en $O(n^3)$ \`a $O(n^{\ln(7)})$ (la preuve
est analogue \`a celle de la multiplication des polyn\^omes
par l'algorithme de Karatsuba).

La plupart des algorithmes d'alg\`ebre lin\'eaire ``num\'erique''
ont une utilit\'e en calcul exact~: par exemple la factorisation
$LU$ (avec les variations d\'ecrites dans la section r\'eduction
de Gau\ss), la factorisation $QR$ (et donc la m\'ethode de Gram-Schmidt,
ici pour des raisons d'efficacit\'e on orthogonalise d'abord la
base de d\'epart et on la normalise à la fin seulement),
Cholesky,.... On peut aussi facilement programmer la recherche de la
d\'ecomposition $^tP D P$ d'une matrice sym\'etrique et en
d\'eduire la signature d'une forme quadratique.
Citons enfin l'algorithme $LLL$ (cf. Cohen) qui est utile
dans de nombreux domaines (il permet de trouver des vecteurs assez
courts dans un r\'eseau, ce ne sont pas les plus courts, mais
en contrepartie on les trouve très vite).

\subsection{Quelques r\'ef\'erences} \label{sec:ref}

\begin{itemize}
\item Comme toujours on renvoie à l'excellent livre de Henri Cohen:
A Course in Computational Algebraic Number Theory

\item Gantmacher: Th\'eorie des matrices

\item Pour une impl\'ementation des algorithmes de forme normale
de Smith ou de Frobenius, cf. le source de MuPAD ou\\
\verb|http://www.mapleapps.com/maplelinks/share/normform.html|

\item 
Ferrard, Lemberg: Math\'ematiques Concr\`etes, Illustr\'ees par la TI 92 
et la TI 89 \\
Présente aussi des algorithmes plus numériques, et le lien avec
la diagonalisation numérique de matrices. 

\item Press et al.: Numerical recipies in Fortran/C/Pascal.\\
Pour des algorithmes numériques (sur les matrices et autres).

\end{itemize}


\subsection{B\'ezout et les $p$-adiques.}
Soit $n$ et $a/b$ une fraction irr\'eductible d'entiers tels que 
$b$ est premier avec $n$ et $|a| < \sqrt{n}/2$ et $ 0 \leq b \leq \sqrt{n}/2$.
Il s'agit de reconstruire $a$ et $b$ connaissant 
$x=a \times (b^{-1}) \pmod n$ avec $x\in [0,n[$.

{\bf Unicit\'e}\\
S'il existe une solution $(a,b)$ vérifiant $|a| < \sqrt{n}/2$ et 
$ 0 \leq b \leq \sqrt{n}/2$, soit $(a',b')$ une solution
de $x=a \times (b^{-1}) \pmod n$ et 
vérifiant $|a'| < \sqrt{n}$ et $ 0 \leq b' \leq \sqrt{n}$, alors~:
\[ a b'=a' b \pmod n \]
Comme $|ab'| < n/2$, $|a'b| <n/2$, 
on en d\'eduit que $ab'=a'b$. Donc $a/b=a'/b'$
donc $a=a'$ et $b=b'$ car $a/b$ et $a'/b'$ sont suppos\'ees irr\'eductibles.

{\bf Reconstruction lorsqu'on sait qu'il y a une solution}\\
On suit l'algorithme de calcul des coefficients de B\'ezout
pour les entiers $n$ et $x$. On pose~:
\[ \alpha_k n + \beta_k x= r_k \]
o\`u les $r_k$ sont les restes successifs de l'algorithme d'Euclide,
avec la condition initiale~:
\[ \alpha_0=1, \beta_0=0, \alpha_1=0, \beta_1=1, r_0=n, r_1=x \]
et la relation de r\'ecurrence~:
\[ \beta_{k+2}=\beta_k - q_{k+2} \beta_{k+1}, \quad
q_{k+2}=\frac{r_{k}-r_{k+2}}{r_{k+1}}\]

On a $ \beta_k x= r_k \pmod n$ pour tout rang mais il faut v\'erifier
les conditions de taille sur $\beta_k$ et $r_k$ pour trouver le couple
$(a,b)$.
Montrons par r\'ecurrence que~:
\begin{equation} \label{eq:rec}
 \beta_{k+1} r_k - r_{k+1} \beta_k = (-1)^k n 
\end{equation}
Au rang $k=0$, on v\'erifie l'\'egalit\'e, on l'admet au rang $k$, 
alors au rang $k+1$, on a~:
\begin{eqnarray*}
 \beta_{k+2} r_{k+1} - r_{k+2} \beta_{k+1} 
& = & \beta_k r_{k+1} - q_{k+2} r_{k+1} \beta_{k+1}  - r_{k+2} \beta_{k+1} \\
& = & \beta_k r_{k+1} - (r_{k}-r_{k+2}) \beta_{k+1}  - r_{k+2} \beta_{k+1} \\
& = & \beta_k r_{k+1} - r_{k} \beta_{k+1} \\
& = & - (-1)^k n
\end{eqnarray*}
On v\'erifie aussi que le signe de $\beta_k$ est positif si $k$ est impair
et n\'egatif si $k$ est pair, on d\'eduit donc de (\ref{eq:rec})~:
\[ |\beta_{k+1}| r_k < n \]
(avec \'egalit\'e si $r_{k+1}=0$)

Consid\'erons la taille des restes successifs, il existe un rang $k$
tel que $r_k \geq \sqrt{n}$ et $r_{k+1}<\sqrt{n}$. On a alors
$|\beta_{k+1}|  < n/r_k \leq \sqrt{n}$.

Donc l'algorithme de Bézout permet de reconstruire l'unique couple
solution s'il existe.

{\bf Exemple}\\
On prend $n=101$, $a=2$, $b=3$, $a/b=68 \pmod {101}$.
Puis on effectue Bézout pour $68$ et $101$ en affichant les étapes 
intermédiaires (par exemple avec \verb|IEGCD| sur une HP49 ou exercice
avec votre système de calcul formel)~:
\begin{verbatim}
   = alpha*101+beta*68
101    1        0
 68    0        1  L1 - 1*L2
 33    1       -1  L2 - 2*L3
  2   -2        3  ...
\end{verbatim}
On s'arrête à la première ligne telle que le coefficient de la 1ère colonne
est inférieur à $\sqrt{101}$, on retrouve bien $2$ et $3$.
Quand on programme l'algorithme de
reconstruction, on ne calcule bien sûr pas la colonne des $\alpha$,
ce qui donne par exemple le programme xcas ou mupad suivant~:
\begin{verbatim}
// Renvoie a/b tel que a/b=x mod n et |a|,|b|<sqrt(n)
padictofrac:=proc (n,x)
  local r0,beta0,r1,beta1,r2,q2,beta2;
begin
  r0:=n;
  beta0:=0;
  r1:=x;
  beta1:=1;
  sqrtn:=float(sqrt(n));
  while r1>sqrtn do
    r2:= irem(r0,r1); 
    q2:=(r0-r2)/r1;
    beta2:=beta0-q2*beta1;
    beta0:=beta1; r0:=r1; beta1:=beta2; r1:=r2;
  end_while;
  return(r1/beta1);
end_proc;
\end{verbatim}

\pagebreak

\subsection{Exercices (alg\`ebre lin\'eaire)}
\subsubsection{Instructions}
\begin{itemize}
\item Les commandes d'alg\`ebre lin\'eaire de Xcas sont
regroup\'ees dans le menu {\tt Math->Alglin}.
En maple et mupad, la commande {\tt ?linalg} affiche
la liste des commandes d'algèbre linéaire. 
\item En maple il est conseillé d'exécuter {\tt with(linalg);},
en mupad {\tt export(linalg);}, sinon il faut précéder
chaque commande de {\tt linalg::}.
\item En maple, attention
il faut utiliser le caractère {\tt \&} avant la multiplication
et il faut souvent utiliser {\tt evalm} dans les programmes
utilisant des matrices et vecteurs. 
\item Pour travailler avec des
coefficients modulaires, en Xcas
on fait suivre les coefficients ou matrices de {\tt \% n},
en maple on utilise les noms de commandes
avec une majuscule (forme inerte) suivi de {\tt mod n},  en mupad
on définit les coefficients dans l'anneau, par exemple\\
\verb|Z19:=Dom::IntegerMod(19): MatZ19 := Dom::Matrix(Z19):|\\
\verb|A:=MatZ19([[1, 2], [2]]); Z19(5)*A;|
\end{itemize}


\subsubsection{Exercices}
\begin{enumerate}
\item En utilisant un logiciel de calcul formel,
comparez le temps de calcul d'un d\'eterminant de matrice
al\'eatoire \`a coefficients entiers de tailles 50 et 100, 
d'une matrice de taille 6 et 12 avec comme coefficients symboliques
ligne $j$ colonne $k$, $x_{j+k}$ lorsque $j+k$ est pair
et 0 sinon. Peut-on en déduire une indication sur l'algorithme
utilisé?
\item \'Ecrire un programme calculant la borne de Hadamard d'un
déterminant à coefficients réels (rappel~: c'est la borne obtenue en faisant
le produit des normes euclidiennes des vecteurs colonnes).
\item Créez une matrice 4x4 aléatoire avec des coefficients entiers
compris entre -100 et 100, calculer la borne de Hadamard de son déterminant
avec le programme précédent, calculer ce déterminant modulo
quelques nombres premiers choisis en fonction de la borne de Hadamard
et vérifiez le résultat de la reconstruction modulaire du déterminant.
\item Créez une matrice 100x100 aléatoire à coefficients entiers
et calculez son déterminant
modulo quelques nombres premiers. Dans quels cas peut-on
conclure que la matrice est inversible dans $\R$? dans $\Z$?
\item \'Ecrire un programme calculant par interpolation de Lagrange
le polyn\^ome caract\'eristique d'une matrice (en donnant \`a $\lambda$
de $\det(\lambda I -A)$, $n+1$ valeurs distinctes).
\item (Long) \'Ecrire un programme qui calcule un d\'eterminant de matrice
en calculant les mineurs 2x2 puis 3x3 etc. (m\'ethode de Laplace)
\item Recherche du polynôme minimal. On prend un vecteur aléatoire
à coefficients entiers et on calcule $v$, $Av$, ..., $A^nv$ puis
on cherche une relation linéaire minimale entre ces vecteurs, en
calculant le noyau de la matrice ayant ces vecteurs colonnes. Si le
noyau est de dimension 1, alors le polynôme minimal est égal au
polynome caractéristique et correspond à un vecteur de la base du noyau.
Sinon, il faut choisir un vecteur du noyau correspondant au degré
le plus petit possible puis faire le PPCM avec les polynomes obtenurs
avec d'autres vecteurs pour obtenir le polynôme minimal avec une grande
probabilité.
Essayez avec la matrice $A$ de taille 3 ayant des 0 sur la diagonale et 
des 1 ailleurs.
\'Ecrire un programme mettant en oeuvre cette recherche, testez-le avec
une matrice al\'eatoire de taille 30.
\item Testez l'algorithme méthode de Fadeev pour la matrice $A$ ci-dessus.
Même question pour 
\[ A=\left(\begin{array}{ccc}
 3 & -1 & 1 \\
2 &0 &1 \\
1 & -1 & 2 
\end{array}\right), \quad 
A=\left(\begin{array}{ccc}
 3 & 2 & -2 \\
-1 &0 &1 \\
1 & 1 & 0 
\end{array}\right) 
 \]
\item \'Ecrire un programme calculant par une méthode itérative
la valeur propre de module maximal d'une matrice à coefficients
complexes. Dans le cas réel, modifier le programme pour pouvoir
traiter le cas d'un couple de complexes conjugués de module maximal.
Dans le cas hermitien ou réel symétrique, éliminer le couple valeur
propre/vecteur propre et continuer la diagonalisation numérique.
\item Soient $|a|,|b|<\sqrt{n/2}$
\'Ecrire une fonction ayant comme arguments $a/b \pmod n$ 
qui calcule $a$ et $b$.\\
Utiliser ce programme pour résoudre un système 4,4 à coefficients entiers
par une méthode $p$-adique.
\end{enumerate}

\pagebreak

\subsection{L'algorithme du simplexe}

\section{Interpolation}
\'Etant donn\'e la facilit\'e de manipulation qu'apportent les
polynomes, on peut chercher \`a approcher une fonction par un
polyn\^ome. De plus l'interpolation est un outil tr\`es utilis\'e
pour calculer des polyn\^omes en calcul formel.

\subsection{Lagrange}
La m\'ethode la plus naturelle consiste \`a chercher
un polyn\^ome de degr\'e le plus petit possible
\'egal \`a la fonction en certains points $x_0,...,x_n$
et \`a trouver une majoration de la diff\'erence entre la fonction
et le polyn\^ome.
Le polynome interpolateur de Lagrange r\'epond \`a cette question.

Soit donc $x_0,...,x_n$ des r\'eels distincts et $y_0,...,y_n$
les valeurs de la fonction \`a approcher en ces points (on posera
$y_j=f(x_j)$ pour approcher la fonction $f$). On cherche
donc $P$ tel que $P(x_j)=y_i$ pour $j \in [0,n]$.

Commencons par voir s'il y a beaucoup de solutions. Soit $P$ et $Q$
deux solutions distinctes du probl\`eme, alors $P-Q$ est non nul
et va s'annuler en $x_0, ...,x_n$ donc poss\`ede $n+1$ racines donc
est de degr\'e $n+1$ au moins. R\'eciproquement, si on ajoute
\`a $P$ un multiple du polynome $A=\prod_{j=0}^n (X-x_j)$, on obtient
une autre solution. Toutes les solutions se d\'eduisent donc
d'une solution particuli\`ere en y ajoutant un polynome de degr\'e
au moins $n+1$ multiple de $A$. 

Nous allons maintenant construire
une solution particuli\`ere de degr\'e au plus $n$.
Si $n=0$, on prend $P=x_0$ constant. On proc\`ede ensuite par
r\'ecurrence. Pour construire le polyn\^ome correspondant
\`a $x_0,...,x_{n+1}$ on part du polyno\^ome $P_n$ correspondant \`a
$x_0,...,x_{n}$ et on lui ajoute un multiple r\'eel de $A$
\[ P_{n+1}=P_n+a\prod_{j=0}^n (X-x_j) \]
Ainsi on a toujours $P_{n+1}(x_j)=y_j$ pour $j=0,..n$, on calcule
maintenant $a$ pour que $P_{n+1}(x_{n+1})=y_{n+1}$.
En remplacant avec l'expression de $P_{n+1}$ ci-dessus, on obtient
\[ P_n(x_{n+1})+a\prod_{j=0}^n (x_{n+1}-x_j) = y_{n+1} \]
Comme tous les $x_j$ sont distincts, il existe une solution unique $a$~:
\[ a=\frac{y_{n+1}-P_n(x_{n+1})}{\prod_{j=0}^n (x_{n+1}-x_j)}\]

On a donc prouv\'e le~:
\begin{thm} \index{lagrange} \index{interpolation}
Soit $n+1$ r\'eels distincts $x_0,...,x_n$ et $n+1$
r\'eels quelconques $y_0,...,y_n$.
Il existe un unique polyn\^ome $P$ de degr\'e inf\'erieur ou \'egal \`a
$n$, appel\'e polynome de Lagrange, tel que~:
\[ P(x_i)=y_i\]
\end{thm}

Exemple~: d\'eterminons le polynome de degr\'e inf\'erieur ou \'egal
\`a 2 tel que $P(0)=1, P(1)=2, P(2)=1$. On commence par $P_0=1$.
Puis on pose $P_1=P_0+aX=1+aX$. Comme $P(1)=2=1+a$ on en tire $a=1$
donc $P_1=1+X$. Puis on pose $P_2=P_1+aX(X-1)$, on a $P_2(2)=3+2a=1$
donc $a=-1$, finalement $P_2=1+X-X(X-1)$.

On peut calculer le polynome de Lagrange comme indiqu\'e ci-dessus,
la m\'ethode dite des diff\'erences divis\'ees permettant de le faire
de la mani\`ere la plus efficace possible (cf. par exemple Demailly).

Reste \`a estimer l'\'ecart entre une fonction et son polynome
interpolateur, on a le~:
\begin{thm} \index{lagrange}
Soit $f$ une fonction $n+1$ fois d\'erivable sur un intervalle $I=[a,b]$
de $\R$, $x_0,...,x_n$ des r\'eels distincts de $I$. 
Soit $P$ le polynome de Lagrange donn\'e par les $x_j$ et $y_j=f(x_j)$.
Pour tout r\'eel $x \in I$,
il existe un r\'eel $\xi_x \in [a,b]$ (qui d\'epend de $x$) tel
que~:
\begin{equation} \label{eq:lagrange}
 f(x)-P(x) = \frac{f^{[n+1]}(\xi_x)}{(n+1)!} \prod_{j=0}^n(x-x_j) 
\end{equation}
\end{thm}
Ainsi l'erreur commise d\'epend d'une majoration de la taille
de la d\'eriv\'ee $n+1$-i\`eme sur l'intervalle, mais aussi
de la disposition des points $x_j$ par rapport \`a $x$. Par exemple
si les points $x_j$ sont \'equidistribu\'es, le terme
$|\prod_{j=0}^n(x-x_j)|$ sera plus grand pr\`es du bord de $I$ qu'au
centre de $I$.

Preuve du th\'eor\`eme~: Si $x$ est l'un des $x_j$ l'égalité est vraie. Soit 
\[ C=(f(x)-P(x))/\prod_{j=0}^n(x-x_j) \]
on considère maintenant la fonction~:
\[ g(t)=f(t)-P(t) - C \prod_{j=0}^n(t-x_j) \]
elle s'annule en $x_j$ pour $j$ variant de 0 à $n$ ainsi qu'en $x$
suite au choix de la constante $C$, donc $g$ s'annule au moins $n+2$ fois
sur l'intervalle contenant les $x_j$ et $x$, donc $g'$ s'annule au moins
$n+1$ fois sur ce même intervalle, donc $g'{'}$ s'annule au moins
$n$ fois, etc. et finalement $g^{[n+1]}$ s'annule une fois
au moins sur cet intervalle. Or 
\[ g^{[n+1]} = f^{[n+1]} - C (n+1)!\]
car $P$ est de degré inférieur ou égal à $n$ 
et $ \prod_{j=0}^n(x-x_j) - x^{n+1}$ est de degré
inférieur ou égal à $n$. Donc il existe bien un réel $\xi_x$ dans
l'intervalle contenant les $x_j$ et $x$ tel que
\[ C=\frac{f^{[n+1]}(\xi_x)}{(n+1)!} \]

\subsection{Différences divisées}
Le calcul pratique du polynôme de Lagrange se fait efficacement 
dans la base $\{ 1,x-x_0,...,(x-x_0)...(x-x_{n-1})\}$ par
la méthode des différences divisées.
On définit de manière récursive les coefficients
\[ [Y]= Y, \quad
[Y_0,...,Y_n]= \frac{[Y_1,...,Y_n]-[Y_0,...,Y_{n-1}]}{Y_n-Y_0} \]
Le polynome d'interpolation est alors donné par~:
\[ P(x)=[y_0]+[y_0,y_1](x-x_0)+[y_0,y_1,y_2](x-x_0)(x-x_1)
+ ... + [y_0,...,y_n](x-x_0)..(x-x_{n-1}) \]
Pour la preuve, cf. par exemple Demailly.

\subsection{Les splines}
Il s'agit de fonctions définies par des polynomes de degré borné
sur des intervalles, dont on fixe la valeur
aux extrémités des intervalles (comme pour le polynome de Lagrange)
ce qui rend la fonction continue, de plus on exige un
degré de régularité plus grand, par exemple etre de classe $C^2$.
Enfin, on fixe des conditions aux bornes de la réunion des 
intervalles, par exemple avoir certaines dérivées nulles. 

Par exemple supposons qu'on se donne $n$ intervalles, donc $n+1$
points $x_0,...,x_n$, on se fixe une régularité $C^{d-1}$. Ceci
entraine $(n-1)d$ conditions de recollement, on y ajoute $n+1$
conditions de valeur en $x_0,...,x_n$, on a donc $nd+1$ conditions,
la borne sur le degré des polynomes doit donc etre $d$ (ou plus,
mais $d$ suffit) ce qui donne $n(d+1)$ degrés de liberté, on
peut donc ajouter $d-1$ conditions, par exemple pour les splines
naturelles, on impose que les dérivées d'ordre $d/2$ à $d-1$
soient nulles en $x_0$ et $x_n$ (si $d$ est pair, on commence à
la dérivée $d/2+1$-ième nulle en $x_n$).

Pour trouver les polynomes, on doit donc résoudre un grand système
linéaire. Une méthode permettant de diminuer la taille du système
linéaire à résoudre dans le cas des splines naturelles
consiste à se fixer $n$ inconnues $z_0,..,z_{n-1}$
représentant les dérivées $d$-ième de la spline $f$ en
$x_0$ sur $[x_0,x_1]$ à $x_{n-1}$ sur $[x_{n-1},x_n]$, 
et $(d-1)/2$ inconnues $f_j$, représentant
la valeur de la dérivée de $f$ en $x_0$ pour $j$ variant
de 1 à $(d-1)/2$. On peut alors écrire le polynome sur l'intervalle
$[x_0,x_1]$ car on connait son développement de Taylor en $x_0$.
On effectue un changement d'origine (par application répétée
de Horner) en $x_1$. On obtient alors le polynome sur $[x_1,x_2]$
en remplaçant uniquement la dérivée $d$-ième par $z_1$.
On continue ainsi jusqu'en $x_{n-1}$. Le système s'obtient en
calculant la valeur du polynome en $x_0,...,x_n$ et la nullité
des dérivées d'ordre $(d-1)/2$ à $d/2$ en $x_n$. On résoud
le système et on remplace pour avoir les valeurs numériques
des coefficients du polynome.

\end{document}
